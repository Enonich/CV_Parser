# CV Parser - Project Structure

## ğŸ“ Directory Organization

```
CV_Parser/
â”œâ”€â”€ backend/                    # Backend application code
â”‚   â”œâ”€â”€ api/                   # FastAPI endpoints and routing
â”‚   â”‚   â”œâ”€â”€ workflow.py       # Main API endpoints
â”‚   â”‚   â””â”€â”€ run_webapp.py     # Application startup script
â”‚   â”œâ”€â”€ core/                  # Core business logic
â”‚   â”‚   â”œâ”€â”€ auth.py           # Authentication & authorization
â”‚   â”‚   â”œâ”€â”€ users_db.py       # User management
â”‚   â”‚   â”œâ”€â”€ reranker.py       # CV reranking logic
â”‚   â”‚   â”œâ”€â”€ score_cv.py       # Scoring algorithms
â”‚   â”‚   â”œâ”€â”€ fetch_top_k.py    # Vector search retrieval
â”‚   â”‚   â”œâ”€â”€ identifiers.py    # Naming and ID utilities
â”‚   â”‚   â””â”€â”€ ollama_bge_reranker.py
â”‚   â”œâ”€â”€ database/              # Database connections
â”‚   â”‚   â”œâ”€â”€ mongodb.py        # MongoDB for CVs
â”‚   â”‚   â””â”€â”€ mongodb_jd.py     # MongoDB for Job Descriptions
â”‚   â”œâ”€â”€ extractors/            # Text extraction modules
â”‚   â”‚   â”œâ”€â”€ cv_extractor.py   # CV text extraction
â”‚   â”‚   â”œâ”€â”€ jd_extractor.py   # JD text extraction
â”‚   â”‚   â”œâ”€â”€ extraction.py     # Generic extraction
â”‚   â”‚   â”œâ”€â”€ docstrange_extractor.py
â”‚   â”‚   â”œâ”€â”€ llama_extractor.py
â”‚   â”‚   â”œâ”€â”€ resume_parser.py
â”‚   â”‚   â””â”€â”€ prof_years_extractor.py
â”‚   â””â”€â”€ embedders/             # Vector embedding generation
â”‚       â”œâ”€â”€ cv_chroma_embedder.py
â”‚       â””â”€â”€ jd_embedder.py
â”œâ”€â”€ static/                     # Frontend files (HTML, CSS, JS)
â”‚   â”œâ”€â”€ index.html            # User interface
â”‚   â”œâ”€â”€ admin.html            # Admin interface
â”‚   â”œâ”€â”€ login.html            # Login page
â”‚   â”œâ”€â”€ app.js                # User dashboard logic
â”‚   â”œâ”€â”€ admin.js              # Admin dashboard logic
â”‚   â”œâ”€â”€ login.js              # Authentication logic
â”‚   â”œâ”€â”€ styles.css            # Styling
â”‚   â”œâ”€â”€ cvs/                  # Uploaded CV files
â”‚   â”œâ”€â”€ jds/                  # Uploaded JD files
â”‚   â””â”€â”€ extracted_files/      # Processed outputs
â”œâ”€â”€ data/                       # Data files and databases
â”‚   â”œâ”€â”€ chroma_db/            # ChromaDB vector stores
â”‚   â”œâ”€â”€ chroma_db_cv/
â”‚   â”œâ”€â”€ chroma_db_jd/
â”‚   â”œâ”€â”€ jd_chroma_db/
â”‚   â”œâ”€â”€ CVs/                  # CV storage
â”‚   â”œâ”€â”€ extracted_files/      # Extracted data
â”‚   â””â”€â”€ *.txt, *.json, *.docx # Sample data files
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”‚   â”œâ”€â”€ CV_Parsing.ipynb
â”‚   â”œâ”€â”€ docstrange_extractor.ipynb
â”‚   â”œâ”€â”€ extractor.ipynb
â”‚   â”œâ”€â”€ professional_exp_calc.ipynb
â”‚   â”œâ”€â”€ reranker.ipynb
â”‚   â””â”€â”€ test.ipynb
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ check_admin.py        # Admin verification
â”‚   â”œâ”€â”€ check_collections.py  # Database checks
â”‚   â”œâ”€â”€ migrate_admin.py      # Migration scripts
â”‚   â”œâ”€â”€ test_env.py          # Environment testing
â”‚   â””â”€â”€ test_flagembedder.py
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ README.md             # Main documentation
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md  # This file
â”‚   â”œâ”€â”€ BUG_FIXES.md
â”‚   â”œâ”€â”€ ADMIN_FEATURES.md
â”‚   â”œâ”€â”€ ADMIN_PAGE_COMPLETE.md
â”‚   â”œâ”€â”€ ADMIN_VS_USER_DASHBOARD.md
â”‚   â””â”€â”€ USER_INTERFACE_CHANGES.md
â”œâ”€â”€ main.py                     # Main entry point
â”œâ”€â”€ config.yaml                 # Configuration file
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # Environment variables
â””â”€â”€ .gitignore

```

## ğŸš€ Running the Application

### Option 1: Using main.py (Recommended)
```bash
python main.py
```

### Option 2: Using the backend script
```bash
python backend/api/run_webapp.py
```

### Option 3: Direct uvicorn
```bash
uvicorn backend.api.workflow:app --reload --host 0.0.0.0 --port 8000
```

## ğŸ“¦ Module Organization

### Backend Structure

**API Layer** (`backend/api/`)
- Handles HTTP requests/responses
- Defines FastAPI routes
- Manages file uploads

**Core Layer** (`backend/core/`)
- Authentication & authorization
- Scoring and ranking algorithms
- Business logic utilities

**Database Layer** (`backend/database/`)
- MongoDB connections
- Data persistence
- CRUD operations

**Extractors** (`backend/extractors/`)
- PDF/DOCX text extraction
- Structured data parsing
- Content preprocessing

**Embedders** (`backend/embedders/`)
- Vector embedding generation
- ChromaDB integration
- Semantic search preparation

### Frontend Structure

**Static Files** (`static/`)
- Pure HTML/CSS/JavaScript
- No build process required
- Tailwind CSS via CDN

## ğŸ”§ Configuration

All configuration is centralized in `config.yaml`:
- Database connection strings
- Model settings
- Vector search parameters
- Reranking options

## ğŸ“Š Data Flow

1. **Upload** â†’ Files saved to `static/cvs/` or `static/jds/`
2. **Extract** â†’ Text extracted by `extractors/`
3. **Embed** â†’ Vectors generated by `embedders/`
4. **Store** â†’ Data saved to MongoDB + ChromaDB in `data/`
5. **Search** â†’ Vector search via `fetch_top_k.py`
6. **Rerank** â†’ Cross-encoder reranking via `reranker.py`
7. **Display** â†’ Results shown in frontend

## ğŸ› ï¸ Development

- **Add new endpoint**: Edit `backend/api/workflow.py`
- **Add new extractor**: Create in `backend/extractors/`
- **Modify UI**: Edit files in `static/`
- **Run tests**: Use scripts in `scripts/`
- **Experiment**: Use notebooks in `notebooks/`

## ğŸ“ Notes

- All Python modules are properly packaged with `__init__.py`
- Import statements use `backend.module.file` format
- Paths are relative to project root
- Configuration loaded from root `config.yaml`
