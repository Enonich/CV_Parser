{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "627e97e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading Chroma collection: 'cv_sections' from ./chroma_db\n",
      "‚úÖ Retrieved 10 records from 'cv_sections'\n",
      "\n",
      "--- Record 1 ---\n",
      "üÜî ID: 2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484_email_0\n",
      "üìÑ Text: aidooenochkwadwo@gmail.com \n",
      "üìë Metadata: {\n",
      "  \"chunk_id\": 0,\n",
      "  \"embed_date\": \"2025-10-08T14:41:04.270518+00:00\",\n",
      "  \"section\": \"email\",\n",
      "  \"cv_id\": \"2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484\"\n",
      "}\n",
      "\n",
      "--- Record 2 ---\n",
      "üÜî ID: 2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484_summary_0\n",
      "üìÑ Text: A Data Analyst with about two years of professional experience specialized in transforming complex datasets into strategic business solutions. I've consistently delivered actionable insights that have ...\n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T14:41:04.270518+00:00\",\n",
      "  \"cv_id\": \"2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"section\": \"summary\"\n",
      "}\n",
      "\n",
      "--- Record 3 ---\n",
      "üÜî ID: 2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484_work_experience_0\n",
      "üìÑ Text: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_date': 'November 2023', 'end_date': 'October 2024', 'responsibilities': ['Conducted Shapelet Analysis  ...\n",
      "üìë Metadata: {\n",
      "  \"cv_id\": \"2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484\",\n",
      "  \"section\": \"work_experience\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"embed_date\": \"2025-10-08T14:41:04.271521+00:00\"\n",
      "}\n",
      "\n",
      "--- Record 4 ---\n",
      "üÜî ID: 2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484_work_experience_1\n",
      "üìÑ Text: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart disease diagnosis, integrated into a user-friendly web application to support clinical decision-making ...\n",
      "üìë Metadata: {\n",
      "  \"chunk_id\": 1,\n",
      "  \"cv_id\": \"2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484\",\n",
      "  \"section\": \"work_experience\",\n",
      "  \"embed_date\": \"2025-10-08T14:41:04.271521+00:00\"\n",
      "}\n",
      "\n",
      "--- Record 5 ---\n",
      "üÜî ID: 2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484_work_experience_2\n",
      "üìÑ Text: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optimize customer pricing strategies for a tourist agency.']} \n",
      "üìë Metadata: {\n",
      "  \"section\": \"work_experience\",\n",
      "  \"cv_id\": \"2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484\",\n",
      "  \"chunk_id\": 2,\n",
      "  \"embed_date\": \"2025-10-08T14:41:04.271521+00:00\"\n",
      "}\n",
      "\n",
      "--- Record 6 ---\n",
      "üÜî ID: 2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484_education_0\n",
      "üìÑ Text: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'location': 'Ghana', 'start_date': '', 'end_date': '2023'} \n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T14:41:04.271521+00:00\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"cv_id\": \"2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484\",\n",
      "  \"section\": \"education\"\n",
      "}\n",
      "\n",
      "--- Record 7 ---\n",
      "üÜî ID: 2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484_skills_0\n",
      "üìÑ Text: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn | Matplotlib | Pytorch | Data Analysis | Classification Modeling | Deep Neural Networks | Regression ...\n",
      "üìë Metadata: {\n",
      "  \"cv_id\": \"2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"embed_date\": \"2025-10-08T14:41:04.271521+00:00\",\n",
      "  \"section\": \"skills\"\n",
      "}\n",
      "\n",
      "--- Record 8 ---\n",
      "üÜî ID: 2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484_soft_skills_0\n",
      "üìÑ Text: Curiosity | Problem Solving | System Understanding | Technical Skills | Analytical Thinking | Problem Solving Skills | Teamwork | Initiative and Self-motivation | Discipline and Resilient \n",
      "üìë Metadata: {\n",
      "  \"section\": \"soft_skills\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"cv_id\": \"2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484\",\n",
      "  \"embed_date\": \"2025-10-08T14:41:04.271521+00:00\"\n",
      "}\n",
      "\n",
      "--- Record 9 ---\n",
      "üÜî ID: 2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484_certifications_0\n",
      "üìÑ Text: {'name': 'Coursera Crash Course on Python', 'issuing_organization': 'Coursera', 'date': 'Oct 2021'} | {'name': 'AWS Machine Learning Foundation', 'issuing_organization': 'AWS', 'date': 'Oct 2021'} | { ...\n",
      "üìë Metadata: {\n",
      "  \"chunk_id\": 0,\n",
      "  \"cv_id\": \"2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484\",\n",
      "  \"section\": \"certifications\",\n",
      "  \"embed_date\": \"2025-10-08T14:41:04.271521+00:00\"\n",
      "}\n",
      "\n",
      "--- Record 10 ---\n",
      "üÜî ID: 2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484_certifications_1\n",
      "üìÑ Text: 'Stanford University', 'date': 'Present'} | {'name': 'Google Data Analytics Professional Certificate', 'issuing_organization': 'Google', 'date': 'May 2023'} | {'name': 'ALX Data Science', 'issuing_org ...\n",
      "üìë Metadata: {\n",
      "  \"section\": \"certifications\",\n",
      "  \"chunk_id\": 1,\n",
      "  \"embed_date\": \"2025-10-08T14:41:04.271521+00:00\",\n",
      "  \"cv_id\": \"2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484\"\n",
      "}\n",
      "\n",
      "üì¶ Loading Chroma collection: 'job_descriptions' from ./chroma_db\n",
      "‚úÖ Retrieved 5 records from 'job_descriptions'\n",
      "\n",
      "--- Record 1 ---\n",
      "üÜî ID: f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486_job_title_0\n",
      "üìÑ Text: Data Analyst \n",
      "üìë Metadata: {\n",
      "  \"chunk_id\": 0,\n",
      "  \"jd_id\": \"f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486\",\n",
      "  \"embed_date\": \"2025-10-08T14:39:37.414392+00:00\",\n",
      "  \"section\": \"job_title\"\n",
      "}\n",
      "\n",
      "--- Record 2 ---\n",
      "üÜî ID: f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486_required_skills_0\n",
      "üìÑ Text: Strong problem-solving abilities with attention to detail | Experience with experimental design and statistical inference | Ability to work with ambiguous requirements and define analytical approaches ...\n",
      "üìë Metadata: {\n",
      "  \"section\": \"required_skills\",\n",
      "  \"embed_date\": \"2025-10-08T14:39:37.415724+00:00\",\n",
      "  \"jd_id\": \"f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486\",\n",
      "  \"chunk_id\": 0\n",
      "}\n",
      "\n",
      "--- Record 3 ---\n",
      "üÜî ID: f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486_preferred_skills_0\n",
      "üìÑ Text: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machine learning concepts and applications | Familiarity with API integration and data extraction | Experi ...\n",
      "üìë Metadata: {\n",
      "  \"section\": \"preferred_skills\",\n",
      "  \"jd_id\": \"f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486\",\n",
      "  \"embed_date\": \"2025-10-08T14:39:37.415724+00:00\",\n",
      "  \"chunk_id\": 0\n",
      "}\n",
      "\n",
      "--- Record 4 ---\n",
      "üÜî ID: f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486_required_qualifications_0\n",
      "üìÑ Text: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical field | 2-4 years of experience in data analysis, business intelligence, or related role | Experienc ...\n",
      "üìë Metadata: {\n",
      "  \"section\": \"required_qualifications\",\n",
      "  \"embed_date\": \"2025-10-08T14:39:37.415724+00:00\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"jd_id\": \"f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486\"\n",
      "}\n",
      "\n",
      "--- Record 5 ---\n",
      "üÜî ID: f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486_required_qualifications_1\n",
      "üìÑ Text: tools - Tableau, Power BI, or similar platforms | Statistical analysis - hypothesis testing, regression analysis, A/B testing | Excel/Google Sheets - advanced formulas, pivot tables, and data modeling ...\n",
      "üìë Metadata: {\n",
      "  \"jd_id\": \"f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486\",\n",
      "  \"chunk_id\": 1,\n",
      "  \"section\": \"required_qualifications\",\n",
      "  \"embed_date\": \"2025-10-08T14:39:37.415724+00:00\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import json\n",
    "import os\n",
    "\n",
    "def fetch_chroma_data(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"cv_sections\",   # or \"job_descriptions\"\n",
    "    limit=30\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch and display documents, metadata, and embeddings from a Chroma collection.\n",
    "\n",
    "    Args:\n",
    "        persist_directory (str): Path where ChromaDB was persisted.\n",
    "        collection_name (str): Name of the collection to inspect.\n",
    "        limit (int): Number of records to fetch.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"üì¶ Loading Chroma collection: '{collection_name}' from {persist_directory}\")\n",
    "\n",
    "    # Recreate embeddings function (required by Chroma)\n",
    "    embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "\n",
    "    # Connect to existing Chroma collection\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "\n",
    "    # Fetch all records\n",
    "    try:\n",
    "        data = vectorstore.get(limit=limit)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to fetch from Chroma: {e}\")\n",
    "        return\n",
    "\n",
    "    # Display basic info\n",
    "    num_docs = len(data.get(\"documents\", []))\n",
    "    print(f\"‚úÖ Retrieved {num_docs} records from '{collection_name}'\\n\")\n",
    "\n",
    "    # Print a few sample records\n",
    "    for i in range(min(num_docs, limit)):\n",
    "        print(f\"--- Record {i+1} ---\")\n",
    "        print(\"üÜî ID:\", data[\"ids\"][i])\n",
    "        print(\"üìÑ Text:\", data[\"documents\"][i][:200], \"...\" if len(data[\"documents\"][i]) > 200 else \"\")\n",
    "        print(\"üìë Metadata:\", json.dumps(data[\"metadatas\"][i], indent=2))\n",
    "        print()\n",
    "\n",
    "    # Optional: return for programmatic use\n",
    "    return data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    # Fetch CV embeddings\n",
    "    fetch_chroma_data(collection_name=\"cv_sections\", limit=10)\n",
    "\n",
    "    # Fetch JD embeddings\n",
    "    fetch_chroma_data(collection_name=\"job_descriptions\", limit=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d1c80e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading Chroma collection: 'cv_sections' from ./chroma_db\n",
      "‚úÖ Retrieved 36 records from 'cv_sections'\n",
      "\n",
      "--- Record 1 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_email_0\n",
      "üìÑ Text: aidooenoch@gmail.com \n",
      "üìë Metadata: {\n",
      "  \"section\": \"email\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.599399+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0004, 0.0005, ..., -0.0273 ]\n",
      "\n",
      "--- Record 2 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_summary_0\n",
      "üìÑ Text: A Data Analyst with about two years of professional experience specialized in transforming complex datasets into strategic business solutions. I've consistently delivered actionable insights that have ...\n",
      "üìë Metadata: {\n",
      "  \"chunk_id\": 0,\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\",\n",
      "  \"section\": \"summary\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.599399+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0113, 0.0270, ..., 0.0567 ]\n",
      "\n",
      "--- Record 3 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_work_experience_0\n",
      "üìÑ Text: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_date': 'November 2023', 'end_date': 'October 2024', 'responsibilities': ['Conducted Shapelet Analysis  ...\n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.600388+00:00\",\n",
      "  \"section\": \"work_experience\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0045, -0.0046, ..., -0.0075 ]\n",
      "\n",
      "--- Record 4 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_work_experience_1\n",
      "üìÑ Text: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart disease diagnosis, integrated into a user-friendly web application to support clinical decision-making ...\n",
      "üìë Metadata: {\n",
      "  \"section\": \"work_experience\",\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\",\n",
      "  \"chunk_id\": 1,\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.600388+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0142, 0.0258, ..., 0.0140 ]\n",
      "\n",
      "--- Record 5 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_work_experience_2\n",
      "üìÑ Text: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optimize customer pricing strategies for a tourist agency.']} \n",
      "üìë Metadata: {\n",
      "  \"section\": \"work_experience\",\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\",\n",
      "  \"chunk_id\": 2,\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.600388+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0093, 0.0580, ..., 0.0241 ]\n",
      "\n",
      "--- Record 6 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_education_0\n",
      "üìÑ Text: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'location': 'Ghana', 'start_date': '', 'end_date': '2023'} \n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.600388+00:00\",\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"section\": \"education\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0163, -0.0555, ..., 0.0558 ]\n",
      "\n",
      "--- Record 7 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_skills_0\n",
      "üìÑ Text: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn | Matplotlib | Pytorch | Data Analysis | Classification Modeling | Deep Neural Networks | Regression ...\n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.600388+00:00\",\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\",\n",
      "  \"section\": \"skills\",\n",
      "  \"chunk_id\": 0\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0037, -0.0173, ..., 0.0416 ]\n",
      "\n",
      "--- Record 8 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_soft_skills_0\n",
      "üìÑ Text: Curiosity | Problem Solving | System Understanding | Technical Skills | Analytical Thinking | Problem Solving Skills | Teamwork | Initiative and Self-motivation | Discipline and Resilient \n",
      "üìë Metadata: {\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.600388+00:00\",\n",
      "  \"section\": \"soft_skills\",\n",
      "  \"chunk_id\": 0\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0024, 0.0147, ..., 0.0167 ]\n",
      "\n",
      "--- Record 9 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_certifications_0\n",
      "üìÑ Text: {'name': 'Coursera Crash Course on Python', 'issuing_organization': 'Coursera', 'date': 'Oct 2021'} | {'name': 'AWS Machine Learning Foundation', 'issuing_organization': 'AWS', 'date': 'Oct 2021'} | { ...\n",
      "üìë Metadata: {\n",
      "  \"chunk_id\": 0,\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\",\n",
      "  \"section\": \"certifications\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.600388+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0146, -0.0113, ..., 0.0392 ]\n",
      "\n",
      "--- Record 10 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_certifications_1\n",
      "üìÑ Text: 'Stanford University', 'date': 'Present'} | {'name': 'Google Data Analytics Professional Certificate', 'issuing_organization': 'Google', 'date': 'May 2023'} | {'name': 'ALX Data Science', 'issuing_org ...\n",
      "üìë Metadata: {\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\",\n",
      "  \"chunk_id\": 1,\n",
      "  \"section\": \"certifications\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.600388+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0083, -0.0082, ..., 0.0320 ]\n",
      "\n",
      "--- Record 11 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_projects_0\n",
      "üìÑ Text: {'name': 'Conducted advanced Excel analysis on water access datasets', 'description': 'applying data cleaning, formulas, statistical functions, and pivot tables. Designed visualizations (stacked bar c ...\n",
      "üìë Metadata: {\n",
      "  \"section\": \"projects\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.600388+00:00\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0009, -0.0010, ..., 0.0461 ]\n",
      "\n",
      "--- Record 12 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_projects_1\n",
      "üìÑ Text: 'using historical market data, achieving a validation MSE of 0.998. The model improved risk forecasting accuracy and provided actionable insights for financial decision-making.', 'technologies': []} | ...\n",
      "üìë Metadata: {\n",
      "  \"section\": \"projects\",\n",
      "  \"chunk_id\": 1,\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.600388+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0189, 0.0375, ..., 0.0464 ]\n",
      "\n",
      "--- Record 13 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_projects_2\n",
      "üìÑ Text: planning and resource distribution.', 'technologies': ['SQL']} | {'name': 'Developed stakeholder-driven Power BI dashboards', 'description': 'with advanced DAX calculations and multi-level drill-downs ...\n",
      "üìë Metadata: {\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.600388+00:00\",\n",
      "  \"section\": \"projects\",\n",
      "  \"chunk_id\": 2\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0284, -0.0070, ..., 0.0263 ]\n",
      "\n",
      "--- Record 14 ---\n",
      "üÜî ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8_years_of_experience_0\n",
      "üìÑ Text: 1.92 \n",
      "üìë Metadata: {\n",
      "  \"section\": \"years_of_experience\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:21.601393+00:00\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"cv_id\": \"153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0024, 0.0203, ..., -0.0442 ]\n",
      "\n",
      "--- Record 15 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_email_0\n",
      "üìÑ Text: aidookwadwo@gmail.com \n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.727946+00:00\",\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\",\n",
      "  \"section\": \"email\",\n",
      "  \"chunk_id\": 0\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0030, -0.0125, ..., -0.0051 ]\n",
      "\n",
      "--- Record 16 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_summary_0\n",
      "üìÑ Text: A Data Analyst with about two years of professional experience specialized in transforming complex datasets into strategic business solutions. I've consistently delivered actionable insights that have ...\n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.727946+00:00\",\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"section\": \"summary\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0113, 0.0270, ..., 0.0567 ]\n",
      "\n",
      "--- Record 17 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_work_experience_0\n",
      "üìÑ Text: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_date': 'November 2023', 'end_date': 'October 2024', 'responsibilities': ['Conducted Shapelet Analysis  ...\n",
      "üìë Metadata: {\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\",\n",
      "  \"section\": \"work_experience\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.729098+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0090, 0.0048, ..., -0.0103 ]\n",
      "\n",
      "--- Record 18 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_work_experience_1\n",
      "üìÑ Text: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': 'Data Scientist', 'location': '', 'start_date': 'September 2024', 'end_date': 'Present', 'responsibi ...\n",
      "üìë Metadata: {\n",
      "  \"section\": \"work_experience\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.729098+00:00\",\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\",\n",
      "  \"chunk_id\": 1\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0198, 0.0318, ..., 0.0189 ]\n",
      "\n",
      "--- Record 19 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_education_0\n",
      "üìÑ Text: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'location': 'Ghana', 'start_date': '', 'end_date': '2023'} \n",
      "üìë Metadata: {\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\",\n",
      "  \"section\": \"education\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.729098+00:00\",\n",
      "  \"chunk_id\": 0\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0163, -0.0555, ..., 0.0558 ]\n",
      "\n",
      "--- Record 20 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_skills_0\n",
      "üìÑ Text: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn | Matplotlib | Pytorch | Jupyter Notebook | Data Analysis | Classification Modeling | Deep Neural Ne ...\n",
      "üìë Metadata: {\n",
      "  \"section\": \"skills\",\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.729098+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0012, -0.0199, ..., 0.0387 ]\n",
      "\n",
      "--- Record 21 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_skills_1\n",
      "üìÑ Text: Query for data transformation | Cross-platform data integration \n",
      "üìë Metadata: {\n",
      "  \"chunk_id\": 1,\n",
      "  \"section\": \"skills\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.729098+00:00\",\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0122, -0.0000, ..., 0.0156 ]\n",
      "\n",
      "--- Record 22 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_soft_skills_0\n",
      "üìÑ Text: Curiosity | Problem Solving | System Understanding | Technical Skills | Analytical Thinking | Problem Solving Skills | Teamwork | Initiative and Self-motivation | Discipline and Resilient \n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.729098+00:00\",\n",
      "  \"section\": \"soft_skills\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0024, 0.0147, ..., 0.0167 ]\n",
      "\n",
      "--- Record 23 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_certifications_0\n",
      "üìÑ Text: {'name': 'ALX Data Science', 'issuing_organization': 'ALX', 'date': 'June 2025'} | {'name': 'Google Data Analytics Professional Certificate', 'issuing_organization': 'Google', 'date': 'Oct 2021'} | {' ...\n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.729098+00:00\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"section\": \"certifications\",\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0075, 0.0023, ..., 0.0351 ]\n",
      "\n",
      "--- Record 24 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_certifications_1\n",
      "üìÑ Text: 'issuing_organization': 'AWS', 'date': 'Aug 2025'} | {'name': 'AWS Certified Solutions Architect', 'issuing_organization': 'AWS', 'date': 'Present'} \n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.729098+00:00\",\n",
      "  \"section\": \"certifications\",\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\",\n",
      "  \"chunk_id\": 1\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0110, -0.0327, ..., 0.0148 ]\n",
      "\n",
      "--- Record 25 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_projects_0\n",
      "üìÑ Text: {'name': 'Leveraged SQL and Power BI skills to design interactive dashboards', 'description': 'Leveraged SQL and Power BI skills to design interactive dashboards that visualized complex data patterns, ...\n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.729098+00:00\",\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"section\": \"projects\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0200, -0.0066, ..., 0.0222 ]\n",
      "\n",
      "--- Record 26 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_projects_1\n",
      "üìÑ Text: and built a predictive model for quantitative finance with a validation MSE of about 0.998 to improve risk forecasting.', 'technologies': []} | {'name': 'Led SQL-based analysis of 60,000+ water infras ...\n",
      "üìë Metadata: {\n",
      "  \"chunk_id\": 1,\n",
      "  \"section\": \"projects\",\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.729098+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0403, 0.0172, ..., 0.0325 ]\n",
      "\n",
      "--- Record 27 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_projects_2\n",
      "üìÑ Text: for infrastructure improvements and resource allocation.', 'technologies': ['SQL']} | {'name': 'Built stakeholder-driven Power BI dashboards', 'description': 'Built stakeholder-driven Power BI dashboa ...\n",
      "üìë Metadata: {\n",
      "  \"chunk_id\": 2,\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.729098+00:00\",\n",
      "  \"section\": \"projects\",\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0319, 0.0036, ..., 0.0378 ]\n",
      "\n",
      "--- Record 28 ---\n",
      "üÜî ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe_years_of_experience_0\n",
      "üìÑ Text: 1.92 \n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T15:31:26.729098+00:00\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"cv_id\": \"f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe\",\n",
      "  \"section\": \"years_of_experience\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0024, 0.0203, ..., -0.0442 ]\n",
      "\n",
      "--- Record 29 ---\n",
      "üÜî ID: 2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e_email_0\n",
      "üìÑ Text: enochkwadwo@gmail.com \n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T15:31:31.699418+00:00\",\n",
      "  \"cv_id\": \"2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e\",\n",
      "  \"section\": \"email\",\n",
      "  \"chunk_id\": 0\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0082, -0.0162, ..., 0.0031 ]\n",
      "\n",
      "--- Record 30 ---\n",
      "üÜî ID: 2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e_summary_0\n",
      "üìÑ Text: A Data Analyst with about two years of professional experience specialized in transforming complex datasets into strategic business solutions. I've consistently delivered actionable insights that have ...\n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T15:31:31.699418+00:00\",\n",
      "  \"cv_id\": \"2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e\",\n",
      "  \"section\": \"summary\",\n",
      "  \"chunk_id\": 0\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0113, 0.0270, ..., 0.0567 ]\n",
      "\n",
      "--- Record 31 ---\n",
      "üÜî ID: 2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e_work_experience_0\n",
      "üìÑ Text: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_date': 'November 2023', 'end_date': 'October 2024', 'responsibilities': ['Conducted Shapelet Analysis  ...\n",
      "üìë Metadata: {\n",
      "  \"section\": \"work_experience\",\n",
      "  \"cv_id\": \"2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"embed_date\": \"2025-10-08T15:31:31.699418+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0045, -0.0046, ..., -0.0075 ]\n",
      "\n",
      "--- Record 32 ---\n",
      "üÜî ID: 2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e_work_experience_1\n",
      "üìÑ Text: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart disease diagnosis, integrated into a user-friendly web application to support clinical decision-making ...\n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T15:31:31.699418+00:00\",\n",
      "  \"section\": \"work_experience\",\n",
      "  \"chunk_id\": 1,\n",
      "  \"cv_id\": \"2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0112, 0.0227, ..., 0.0135 ]\n",
      "\n",
      "--- Record 33 ---\n",
      "üÜî ID: 2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e_work_experience_2\n",
      "üìÑ Text: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optimize customer pricing strategies for a tourist agency.']} \n",
      "üìë Metadata: {\n",
      "  \"section\": \"work_experience\",\n",
      "  \"chunk_id\": 2,\n",
      "  \"embed_date\": \"2025-10-08T15:31:31.699418+00:00\",\n",
      "  \"cv_id\": \"2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0093, 0.0580, ..., 0.0241 ]\n",
      "\n",
      "--- Record 34 ---\n",
      "üÜî ID: 2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e_education_0\n",
      "üìÑ Text: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'location': 'Ghana', 'start_date': '', 'end_date': '2023'} \n",
      "üìë Metadata: {\n",
      "  \"cv_id\": \"2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e\",\n",
      "  \"section\": \"education\",\n",
      "  \"embed_date\": \"2025-10-08T15:31:31.699418+00:00\",\n",
      "  \"chunk_id\": 0\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0163, -0.0555, ..., 0.0558 ]\n",
      "\n",
      "--- Record 35 ---\n",
      "üÜî ID: 2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e_skills_0\n",
      "üìÑ Text: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn | Matplotlib | Pytorch | Data Analysis | Classification Modeling | Deep Neural Networks | Regression ...\n",
      "üìë Metadata: {\n",
      "  \"chunk_id\": 0,\n",
      "  \"embed_date\": \"2025-10-08T15:31:31.699418+00:00\",\n",
      "  \"section\": \"skills\",\n",
      "  \"cv_id\": \"2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0037, -0.0173, ..., 0.0416 ]\n",
      "\n",
      "--- Record 36 ---\n",
      "üÜî ID: 2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e_soft_skills_0\n",
      "üìÑ Text: Curiosity | Problem Solving | System Understanding | Technical Skills | Analytical Thinking | Problem Solving Skills | Teamwork | Initiative and Self-motivation | Discipline and Resilient \n",
      "üìë Metadata: {\n",
      "  \"cv_id\": \"2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e\",\n",
      "  \"section\": \"soft_skills\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"embed_date\": \"2025-10-08T15:31:31.699418+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ 0.0024, 0.0147, ..., 0.0167 ]\n",
      "\n",
      "üì¶ Loading Chroma collection: 'job_descriptions' from ./chroma_db\n",
      "‚úÖ Retrieved 0 records from 'job_descriptions'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import json\n",
    "import os\n",
    "\n",
    "def fetch_chroma_data(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"cv_sections\",\n",
    "    limit=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch and display documents, metadata, and embeddings from a Chroma collection.\n",
    "    \"\"\"\n",
    "    print(f\"üì¶ Loading Chroma collection: '{collection_name}' from {persist_directory}\")\n",
    "    embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # 1. FIX: Explicitly include embeddings\n",
    "        data = vectorstore.get(\n",
    "            limit=limit,\n",
    "            include=['documents', 'metadatas', 'embeddings'] \n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to fetch from Chroma: {e}\")\n",
    "        return\n",
    "\n",
    "    num_docs = len(data.get(\"documents\", []))\n",
    "    print(f\"‚úÖ Retrieved {num_docs} records from '{collection_name}'\\n\")\n",
    "\n",
    "    for i in range(min(num_docs, limit)):\n",
    "        print(f\"--- Record {i+1} ---\")\n",
    "        print(\"üÜî ID:\", data[\"ids\"][i])\n",
    "        print(\"üìÑ Text:\", data[\"documents\"][i][:200], \"...\" if len(data[\"documents\"][i]) > 200 else \"\")\n",
    "        print(\"üìë Metadata:\", json.dumps(data[\"metadatas\"][i], indent=2))\n",
    "        \n",
    "        embedding_vector = data.get(\"embeddings\", [None]*num_docs)[i]\n",
    "        \n",
    "        # 2. FIX: Check length explicitly to avoid ValueError with NumPy arrays\n",
    "        if embedding_vector is not None and len(embedding_vector) > 0:\n",
    "            vector_size = len(embedding_vector)\n",
    "            print(f\"üìê Embedding Vector (Size {vector_size}): [ {embedding_vector[0]:.4f}, {embedding_vector[1]:.4f}, ..., {embedding_vector[-1]:.4f} ]\")\n",
    "        else:\n",
    "            print(\"‚ùå Embedding Vector: NOT FOUND (Vector was None or empty)\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    # Fetch CV embeddings\n",
    "    fetch_chroma_data(collection_name=\"cv_sections\", limit=36)\n",
    "    # Fetch JD embeddings\n",
    "    fetch_chroma_data(collection_name=\"job_descriptions\", limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a276591d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading Chroma collection: 'job_descriptions' from ./chroma_db\n",
      "‚ùå Failed to fetch from Chroma: Error executing plan: Internal error: Error creating hnsw segment reader: Nothing found on disk\n"
     ]
    }
   ],
   "source": [
    "fetch_chroma_data(collection_name=\"job_descriptions\", limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf40ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading Chroma collection: 'job_descriptions' from ./jd_chroma_db\n",
      "‚úÖ Retrieved 5 records from 'job_descriptions'\n",
      "\n",
      "--- Record 1 ---\n",
      "üÜî ID: f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486_job_title_0\n",
      "üìÑ Text: Data Analyst \n",
      "üìë Metadata: {\n",
      "  \"jd_id\": \"f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486\",\n",
      "  \"section\": \"job_title\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"embed_date\": \"2025-10-08T14:02:09.709790+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0371, -0.0021, ..., 0.0158 ]\n",
      "\n",
      "--- Record 2 ---\n",
      "üÜî ID: f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486_required_skills_0\n",
      "üìÑ Text: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Python or R for data manipulation, statistical analysis, and automation | Data visualization tools (Tabl ...\n",
      "üìë Metadata: {\n",
      "  \"embed_date\": \"2025-10-08T14:02:09.710787+00:00\",\n",
      "  \"section\": \"required_skills\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"jd_id\": \"f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0027, 0.0037, ..., 0.0412 ]\n",
      "\n",
      "--- Record 3 ---\n",
      "üÜî ID: f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486_required_skills_1\n",
      "üìÑ Text: with experimental design and statistical inference | Ability to work with ambiguous requirements and define analytical approaches | Understanding of business metrics and KPI development \n",
      "üìë Metadata: {\n",
      "  \"jd_id\": \"f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486\",\n",
      "  \"chunk_id\": 1,\n",
      "  \"section\": \"required_skills\",\n",
      "  \"embed_date\": \"2025-10-08T14:02:09.710787+00:00\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0037, 0.0134, ..., 0.0379 ]\n",
      "\n",
      "--- Record 4 ---\n",
      "üÜî ID: f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486_preferred_skills_0\n",
      "üìÑ Text: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machine learning concepts and applications | Familiarity with API integration and data extraction | Experi ...\n",
      "üìë Metadata: {\n",
      "  \"jd_id\": \"f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"embed_date\": \"2025-10-08T14:02:09.710787+00:00\",\n",
      "  \"section\": \"preferred_skills\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0176, 0.0319, ..., 0.0509 ]\n",
      "\n",
      "--- Record 5 ---\n",
      "üÜî ID: f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486_required_qualifications_0\n",
      "üìÑ Text: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical field | 2-4 years of experience in data analysis, business intelligence, or related role | Experienc ...\n",
      "üìë Metadata: {\n",
      "  \"jd_id\": \"f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486\",\n",
      "  \"embed_date\": \"2025-10-08T14:02:09.710787+00:00\",\n",
      "  \"chunk_id\": 0,\n",
      "  \"section\": \"required_qualifications\"\n",
      "}\n",
      "üìê Embedding Vector (Size 1024): [ -0.0216, -0.0055, ..., 0.0361 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import json\n",
    "import os\n",
    "\n",
    "def fetch_chroma_data(\n",
    "    persist_directory=\"./jd_chroma_db\",\n",
    "    collection_name=\"cv_sections\",\n",
    "    limit=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch and display documents, metadata, and embeddings from a Chroma collection.\n",
    "    \"\"\"\n",
    "    print(f\"üì¶ Loading Chroma collection: '{collection_name}' from {persist_directory}\")\n",
    "    embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # 1. FIX: Explicitly include embeddings\n",
    "        data = vectorstore.get(\n",
    "            limit=limit,\n",
    "            include=['documents', 'metadatas', 'embeddings'] \n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to fetch from Chroma: {e}\")\n",
    "        return\n",
    "\n",
    "    num_docs = len(data.get(\"documents\", []))\n",
    "    print(f\"‚úÖ Retrieved {num_docs} records from '{collection_name}'\\n\")\n",
    "\n",
    "    for i in range(min(num_docs, limit)):\n",
    "        print(f\"--- Record {i+1} ---\")\n",
    "        print(\"üÜî ID:\", data[\"ids\"][i])\n",
    "        print(\"üìÑ Text:\", data[\"documents\"][i][:200], \"...\" if len(data[\"documents\"][i]) > 200 else \"\")\n",
    "        print(\"üìë Metadata:\", json.dumps(data[\"metadatas\"][i], indent=2))\n",
    "        \n",
    "        embedding_vector = data.get(\"embeddings\", [None]*num_docs)[i]\n",
    "        \n",
    "        # 2. FIX: Check length explicitly to avoid ValueError with NumPy arrays\n",
    "        if embedding_vector is not None and len(embedding_vector) > 0:\n",
    "            vector_size = len(embedding_vector)\n",
    "            print(f\"üìê Embedding Vector (Size {vector_size}): [ {embedding_vector[0]:.4f}, {embedding_vector[1]:.4f}, ..., {embedding_vector[-1]:.4f} ]\")\n",
    "        else:\n",
    "            print(\"‚ùå Embedding Vector: NOT FOUND (Vector was None or empty)\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    # Fetch JD embeddings\n",
    "    fetch_chroma_data(collection_name=\"job_descriptions\", limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a59f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-08 16:19:45,509 - INFO - Querying JD collection for all chunks\n",
      "2025-10-08 16:19:45,518 - INFO - Fetched 12 chunks from job_descriptions collection\n",
      "2025-10-08 16:19:45,773 - INFO - Ranked 3 CVs from job_descriptions collection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CV 1 (ID: 2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e) ---\n",
      "Total Score: 0.0734\n",
      "Section Scores:\n",
      "  job_title: 0.8868\n",
      "  required_skills: 0.8122\n",
      "  preferred_skills: 0.8213\n",
      "  required_qualifications: 0.7875\n",
      "  education_requirements: 0.8493\n",
      "  experience_requirements: 0.7872\n",
      "  technical_skills: 0.9298\n",
      "  soft_skills: 0.8232\n",
      "  responsibilities: 0.8187\n",
      "Section Details:\n",
      "  job_title:\n",
      "    JD Chunk: Data Analyst...\n",
      "    CV Chunk: A Data Analyst with about two years of professional experience specialized in transforming complex d... (Section: summary)\n",
      "    Similarity: 0.8868\n",
      "  required_skills:\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.8771\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8441\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8210\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7545\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8151\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.7998\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7934\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.7926\n",
      "  preferred_skills:\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8530\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8258\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.8227\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7838\n",
      "  required_qualifications:\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8478\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8255\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'loc... (Section: education)\n",
      "    Similarity: 0.8010\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7539\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: 1.92... (Section: years_of_experience)\n",
      "    Similarity: 0.7093\n",
      "  education_requirements:\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'loc... (Section: education)\n",
      "    Similarity: 0.8493\n",
      "  experience_requirements:\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8588\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8267\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7447\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: 1.92... (Section: years_of_experience)\n",
      "    Similarity: 0.7186\n",
      "  technical_skills:\n",
      "    JD Chunk: SQL | Python | R | Tableau | Power BI | Excel | Google Sheets | AWS | GCP | Azure | Git...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.9298\n",
      "  soft_skills:\n",
      "    JD Chunk: Excellent written and verbal communication skills | Experience presenting to executive-level stakeho...\n",
      "    CV Chunk: Curiosity | Problem Solving | System Understanding | Technical Skills | Analytical Thinking | Proble... (Section: soft_skills)\n",
      "    Similarity: 0.8232\n",
      "  responsibilities:\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: performance tracking, and decision-making at national, provincial, and local levels.', 'technologies... (Section: projects)\n",
      "    Similarity: 0.8415\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: {'name': 'Water Access Data Analysis', 'description': 'Conducted advanced Excel analysis on water ac... (Section: projects)\n",
      "    Similarity: 0.8393\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8326\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8263\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: 'description': 'Built a predictive model for quantitative finance using historical market data, achi... (Section: projects)\n",
      "    Similarity: 0.8175\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: performance tracking, and decision-making at national, provincial, and local levels.', 'technologies... (Section: projects)\n",
      "    Similarity: 0.8226\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8189\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: {'name': 'Water Access Data Analysis', 'description': 'Conducted advanced Excel analysis on water ac... (Section: projects)\n",
      "    Similarity: 0.8187\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: to identify critical gaps in community water access. Delivered data-driven recommendations that guid... (Section: projects)\n",
      "    Similarity: 0.8047\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8024\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8373\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8131\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: to identify critical gaps in community water access. Delivered data-driven recommendations that guid... (Section: projects)\n",
      "    Similarity: 0.8055\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: 'description': 'Built a predictive model for quantitative finance using historical market data, achi... (Section: projects)\n",
      "    Similarity: 0.8006\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: {'name': 'Water Access Data Analysis', 'description': 'Conducted advanced Excel analysis on water ac... (Section: projects)\n",
      "    Similarity: 0.7992\n",
      "\n",
      "\n",
      "--- CV 2 (ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8) ---\n",
      "Total Score: 0.0734\n",
      "Section Scores:\n",
      "  job_title: 0.8868\n",
      "  required_skills: 0.8119\n",
      "  preferred_skills: 0.8211\n",
      "  required_qualifications: 0.7875\n",
      "  education_requirements: 0.8493\n",
      "  experience_requirements: 0.7873\n",
      "  technical_skills: 0.9298\n",
      "  soft_skills: 0.8232\n",
      "  responsibilities: 0.8160\n",
      "Section Details:\n",
      "  job_title:\n",
      "    JD Chunk: Data Analyst...\n",
      "    CV Chunk: A Data Analyst with about two years of professional experience specialized in transforming complex d... (Section: summary)\n",
      "    Similarity: 0.8868\n",
      "  required_skills:\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.8771\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8441\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8205\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7545\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8151\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.7978\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7934\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.7926\n",
      "  preferred_skills:\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8530\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8249\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.8227\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7838\n",
      "  required_qualifications:\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8478\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8254\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'loc... (Section: education)\n",
      "    Similarity: 0.8010\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7539\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: 1.92... (Section: years_of_experience)\n",
      "    Similarity: 0.7093\n",
      "  education_requirements:\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'loc... (Section: education)\n",
      "    Similarity: 0.8493\n",
      "  experience_requirements:\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8588\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8273\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7447\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: 1.92... (Section: years_of_experience)\n",
      "    Similarity: 0.7186\n",
      "  technical_skills:\n",
      "    JD Chunk: SQL | Python | R | Tableau | Power BI | Excel | Google Sheets | AWS | GCP | Azure | Git...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.9298\n",
      "  soft_skills:\n",
      "    JD Chunk: Excellent written and verbal communication skills | Experience presenting to executive-level stakeho...\n",
      "    CV Chunk: Curiosity | Problem Solving | System Understanding | Technical Skills | Analytical Thinking | Proble... (Section: soft_skills)\n",
      "    Similarity: 0.8232\n",
      "  responsibilities:\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: {'name': 'Conducted advanced Excel analysis on water access datasets', 'description': 'applying data... (Section: projects)\n",
      "    Similarity: 0.8532\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8326\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: planning and resource distribution.', 'technologies': ['SQL']} | {'name': 'Developed stakeholder-dri... (Section: projects)\n",
      "    Similarity: 0.8290\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8246\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.8128\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: {'name': 'Conducted advanced Excel analysis on water access datasets', 'description': 'applying data... (Section: projects)\n",
      "    Similarity: 0.8299\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: planning and resource distribution.', 'technologies': ['SQL']} | {'name': 'Developed stakeholder-dri... (Section: projects)\n",
      "    Similarity: 0.8241\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8189\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.7979\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7798\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8373\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: planning and resource distribution.', 'technologies': ['SQL']} | {'name': 'Developed stakeholder-dri... (Section: projects)\n",
      "    Similarity: 0.8104\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8098\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: {'name': 'Conducted advanced Excel analysis on water access datasets', 'description': 'applying data... (Section: projects)\n",
      "    Similarity: 0.8083\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: 'using historical market data, achieving a validation MSE of 0.998. The model improved risk forecast... (Section: projects)\n",
      "    Similarity: 0.7713\n",
      "\n",
      "\n",
      "--- CV 3 (ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe) ---\n",
      "Total Score: 0.0730\n",
      "Section Scores:\n",
      "  job_title: 0.8868\n",
      "  required_skills: 0.8064\n",
      "  preferred_skills: 0.8201\n",
      "  required_qualifications: 0.7894\n",
      "  education_requirements: 0.8493\n",
      "  experience_requirements: 0.7948\n",
      "  technical_skills: 0.8940\n",
      "  soft_skills: 0.8232\n",
      "  responsibilities: 0.8143\n",
      "Section Details:\n",
      "  job_title:\n",
      "    JD Chunk: Data Analyst...\n",
      "    CV Chunk: A Data Analyst with about two years of professional experience specialized in transforming complex d... (Section: summary)\n",
      "    Similarity: 0.8868\n",
      "  required_skills:\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.8822\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8387\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: Query for data transformation | Cross-platform data integration... (Section: skills)\n",
      "    Similarity: 0.7965\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.7951\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8068\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.7985\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.7930\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: Query for data transformation | Cross-platform data integration... (Section: skills)\n",
      "    Similarity: 0.7401\n",
      "  preferred_skills:\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8463\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.8337\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.8188\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: Query for data transformation | Cross-platform data integration... (Section: skills)\n",
      "    Similarity: 0.7817\n",
      "  required_qualifications:\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8384\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.8089\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'loc... (Section: education)\n",
      "    Similarity: 0.8010\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: 1.92... (Section: years_of_experience)\n",
      "    Similarity: 0.7093\n",
      "  education_requirements:\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'loc... (Section: education)\n",
      "    Similarity: 0.8493\n",
      "  experience_requirements:\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8503\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.8156\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: 1.92... (Section: years_of_experience)\n",
      "    Similarity: 0.7186\n",
      "  technical_skills:\n",
      "    JD Chunk: SQL | Python | R | Tableau | Power BI | Excel | Google Sheets | AWS | GCP | Azure | Git...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.9296\n",
      "    JD Chunk: SQL | Python | R | Tableau | Power BI | Excel | Google Sheets | AWS | GCP | Azure | Git...\n",
      "    CV Chunk: Query for data transformation | Cross-platform data integration... (Section: skills)\n",
      "    Similarity: 0.8584\n",
      "  soft_skills:\n",
      "    JD Chunk: Excellent written and verbal communication skills | Experience presenting to executive-level stakeho...\n",
      "    CV Chunk: Curiosity | Problem Solving | System Understanding | Technical Skills | Analytical Thinking | Proble... (Section: soft_skills)\n",
      "    Similarity: 0.8232\n",
      "  responsibilities:\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: {'name': 'Leveraged SQL and Power BI skills to design interactive dashboards', 'description': 'Lever... (Section: projects)\n",
      "    Similarity: 0.8640\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8236\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.8100\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: for infrastructure improvements and resource allocation.', 'technologies': ['SQL']} | {'name': 'Buil... (Section: projects)\n",
      "    Similarity: 0.8086\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: and built a predictive model for quantitative finance with a validation MSE of about 0.998 to improv... (Section: projects)\n",
      "    Similarity: 0.7934\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: {'name': 'Leveraged SQL and Power BI skills to design interactive dashboards', 'description': 'Lever... (Section: projects)\n",
      "    Similarity: 0.8428\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8148\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: for infrastructure improvements and resource allocation.', 'technologies': ['SQL']} | {'name': 'Buil... (Section: projects)\n",
      "    Similarity: 0.8016\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.7968\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: and built a predictive model for quantitative finance with a validation MSE of about 0.998 to improv... (Section: projects)\n",
      "    Similarity: 0.7854\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8339\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: {'name': 'Leveraged SQL and Power BI skills to design interactive dashboards', 'description': 'Lever... (Section: projects)\n",
      "    Similarity: 0.8325\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: for infrastructure improvements and resource allocation.', 'technologies': ['SQL']} | {'name': 'Buil... (Section: projects)\n",
      "    Similarity: 0.8112\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.8094\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: and built a predictive model for quantitative finance with a validation MSE of about 0.998 to improv... (Section: projects)\n",
      "    Similarity: 0.7862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CVJDVectorSearch:\n",
    "    \"\"\"Performs vector search of CVs against a job description with section-wise scoring.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        cv_persist_dir=\"./chroma_db_cv\",\n",
    "        jd_persist_dir=\"./jd_chroma_db\",\n",
    "        cv_collection_name=\"cv_sections\",\n",
    "        jd_collection_name=\"job_descriptions\",\n",
    "        model=\"mxbai-embed-large\",\n",
    "        top_k_per_section=5\n",
    "    ):\n",
    "        \"\"\"Initialize with Chroma collections and embedding model.\"\"\"\n",
    "        self.embeddings = OllamaEmbeddings(model=model)\n",
    "        self.top_k_per_section = top_k_per_section\n",
    "        \n",
    "        # Initialize Chroma vector stores\n",
    "        self.cv_vectorstore = Chroma(\n",
    "            persist_directory=cv_persist_dir,\n",
    "            embedding_function=self.embeddings,\n",
    "            collection_name=cv_collection_name,\n",
    "            collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "        self.jd_vectorstore = Chroma(\n",
    "            persist_directory=jd_persist_dir,\n",
    "            embedding_function=self.embeddings,\n",
    "            collection_name=jd_collection_name,\n",
    "            collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "        \n",
    "        # Section mapping: JD section -> List of relevant CV sections\n",
    "        self.section_mapping = {\n",
    "            \"job_title\": [\"summary\"],\n",
    "            \"required_skills\": [\"skills\", \"work_experience\"],\n",
    "            \"preferred_skills\": [\"skills\", \"work_experience\"],\n",
    "            \"required_qualifications\": [\"education\", \"years_of_experience\", \"work_experience\"],\n",
    "            \"education_requirements\": [\"education\"],\n",
    "            \"experience_requirements\": [\"work_experience\", \"years_of_experience\"],\n",
    "            \"technical_skills\": [\"skills\"],\n",
    "            \"soft_skills\": [\"soft_skills\"],\n",
    "            \"certifications\": [\"certifications\"],\n",
    "            \"responsibilities\": [\"work_experience\", \"projects\"]\n",
    "        }\n",
    "        \n",
    "        # Section weights for scoring\n",
    "        self.section_weights = {\n",
    "            \"required_skills\": 0.3,\n",
    "            \"preferred_skills\": 0.05,\n",
    "            \"required_qualifications\": 0.05,\n",
    "            \"education_requirements\": 0.05,\n",
    "            \"experience_requirements\": 0.05,\n",
    "            \"technical_skills\": 0.05,\n",
    "            \"soft_skills\": 0.1,\n",
    "            \"certifications\": 0.1,\n",
    "            \"responsibilities\": 0.1,\n",
    "            \"job_title\": 0.05\n",
    "        }\n",
    "        \n",
    "    def fetch_jd_chunks(self) -> List[Dict]:\n",
    "        \"\"\"Fetch all chunks from the job_descriptions collection.\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Querying JD collection for all chunks\")\n",
    "            data = self.jd_vectorstore.get(\n",
    "                include=[\"documents\", \"metadatas\", \"embeddings\"]\n",
    "            )\n",
    "            chunks = [\n",
    "                {\n",
    "                    \"text\": data[\"documents\"][i],\n",
    "                    \"metadata\": data[\"metadatas\"][i],\n",
    "                    \"embedding\": data[\"embeddings\"][i]\n",
    "                }\n",
    "                for i in range(len(data[\"documents\"]))\n",
    "            ]\n",
    "            logger.info(f\"Fetched {len(chunks)} chunks from job_descriptions collection\")\n",
    "            \n",
    "            if len(chunks) == 0:\n",
    "                all_data = self.jd_vectorstore.get(include=[\"metadatas\"])\n",
    "                all_jd_ids = set(meta.get(\"jd_id\", \"UNKNOWN\") for meta in all_data.get(\"metadatas\", []))\n",
    "                logger.warning(f\"No chunks found in job_descriptions. Available JD IDs: {all_jd_ids}\")\n",
    "            \n",
    "            return chunks\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to fetch JD chunks: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def search_cv_chunks(\n",
    "        self,\n",
    "        jd_chunk_embedding: List[float],\n",
    "        cv_sections: List[str],\n",
    "        cv_id: str = None\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Search CV chunks matching a JD chunk embedding, filtered by CV sections and optional CV ID.\"\"\"\n",
    "        try:\n",
    "            # Access the underlying Chroma client\n",
    "            collection = self.cv_vectorstore._collection\n",
    "            # Build where clause with $and operator if cv_id is provided\n",
    "            if cv_id:\n",
    "                where_clause = {\n",
    "                    \"$and\": [\n",
    "                        {\"section\": {\"$in\": cv_sections}},\n",
    "                        {\"cv_id\": cv_id}\n",
    "                    ]\n",
    "                }\n",
    "            else:\n",
    "                where_clause = {\"section\": {\"$in\": cv_sections}}\n",
    "            \n",
    "            # Perform query using precomputed embedding\n",
    "            results = collection.query(\n",
    "                query_embeddings=[jd_chunk_embedding],\n",
    "                n_results=self.top_k_per_section,\n",
    "                where=where_clause,\n",
    "                include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "            )\n",
    "            \n",
    "            # Check if results are empty\n",
    "            if not results[\"documents\"] or not results[\"documents\"][0]:\n",
    "                logger.warning(f\"No CV chunks found for sections {cv_sections} and cv_id {cv_id}\")\n",
    "                return []\n",
    "            \n",
    "            return [\n",
    "                {\n",
    "                    \"text\": results[\"documents\"][0][i],\n",
    "                    \"metadata\": results[\"metadatas\"][0][i],\n",
    "                    \"score\": results[\"distances\"][0][i],\n",
    "                    \"cv_id\": results[\"metadatas\"][0][i][\"cv_id\"],\n",
    "                    \"section\": results[\"metadatas\"][0][i][\"section\"]\n",
    "                }\n",
    "                for i in range(len(results[\"documents\"][0]))\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error searching CV chunks: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def compute_section_score(\n",
    "        self,\n",
    "        jd_section: str,\n",
    "        jd_chunks: List[Dict],\n",
    "        cv_id: str\n",
    "    ) -> Tuple[float, List[Dict]]:\n",
    "        \"\"\"Compute similarity score for a JD section against a CV, handling multiple chunks.\"\"\"\n",
    "        cv_sections = self.section_mapping.get(jd_section, [])\n",
    "        if not cv_sections:\n",
    "            return 0.0, []\n",
    "        \n",
    "        similarities = []\n",
    "        matched_chunks = []\n",
    "        \n",
    "        for jd_chunk in jd_chunks:\n",
    "            if jd_chunk[\"metadata\"][\"section\"] != jd_section:\n",
    "                continue\n",
    "            results = self.search_cv_chunks(\n",
    "                jd_chunk_embedding=jd_chunk[\"embedding\"],\n",
    "                cv_sections=cv_sections,\n",
    "                cv_id=cv_id\n",
    "            )\n",
    "            for result in results:\n",
    "                # Convert distance (0 to 2, where 0 is identical) to similarity (0 to 1)\n",
    "                similarity = 1 - (result[\"score\"] / 2)\n",
    "                similarities.append(similarity)\n",
    "                matched_chunks.append({\n",
    "                    \"jd_chunk\": jd_chunk[\"text\"],\n",
    "                    \"cv_chunk\": result[\"text\"],\n",
    "                    \"cv_section\": result[\"section\"],\n",
    "                    \"similarity\": similarity\n",
    "                })\n",
    "        \n",
    "        # Average similarity across all matches for this section\n",
    "        section_score = np.mean(similarities) if similarities else 0.0\n",
    "        return section_score, matched_chunks\n",
    "    \n",
    "    def search_and_score_cvs(self, top_k_cvs: int = 5) -> List[Dict]:\n",
    "        \"\"\"Search and score CVs against the JD in job_descriptions collection.\"\"\"\n",
    "        # Fetch JD chunks\n",
    "        jd_chunks = self.fetch_jd_chunks()\n",
    "        if not jd_chunks:\n",
    "            logger.error(\"No JD chunks found, aborting search\")\n",
    "            return []\n",
    "        \n",
    "        # Get all unique CV IDs\n",
    "        cv_ids = set(self.cv_vectorstore.get()[\"metadatas\"][i][\"cv_id\"] \n",
    "                    for i in range(len(self.cv_vectorstore.get()[\"metadatas\"])))\n",
    "        \n",
    "        # Score each CV\n",
    "        cv_scores = []\n",
    "        for cv_id in cv_ids:\n",
    "            section_scores = {}\n",
    "            section_details = {}\n",
    "            total_score = 0.0\n",
    "            matched_sections = 0\n",
    "            \n",
    "            # Compute score for each JD section\n",
    "            for jd_section in self.section_mapping.keys():\n",
    "                score, matched_chunks = self.compute_section_score(jd_section, jd_chunks, cv_id)\n",
    "                if score > 0:\n",
    "                    section_scores[jd_section] = score\n",
    "                    section_details[jd_section] = matched_chunks\n",
    "                    total_score += score * self.section_weights.get(jd_section, 0.05)\n",
    "                    matched_sections += 1\n",
    "            \n",
    "            # Normalize total score by number of matched sections\n",
    "            if matched_sections > 0:\n",
    "                total_score /= matched_sections\n",
    "            else:\n",
    "                total_score = 0.0\n",
    "            \n",
    "            cv_scores.append({\n",
    "                \"cv_id\": cv_id,\n",
    "                \"total_score\": total_score,\n",
    "                \"section_scores\": section_scores,\n",
    "                \"section_details\": section_details\n",
    "            })\n",
    "        \n",
    "        # Sort CVs by total score\n",
    "        cv_scores.sort(key=lambda x: x[\"total_score\"], reverse=True)\n",
    "        logger.info(f\"Ranked {len(cv_scores)} CVs from job_descriptions collection\")\n",
    "        return cv_scores[:top_k_cvs]\n",
    "    \n",
    "    def print_results(self, results: List[Dict]):\n",
    "        \"\"\"Print ranked CVs with section-wise scores and details.\"\"\"\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"\\n--- CV {i+1} (ID: {result['cv_id']}) ---\")\n",
    "            print(f\"Total Score: {result['total_score']:.4f}\")\n",
    "            print(\"Section Scores:\")\n",
    "            for section, score in result[\"section_scores\"].items():\n",
    "                print(f\"  {section}: {score:.4f}\")\n",
    "            print(\"Section Details:\")\n",
    "            for section, matches in result[\"section_details\"].items():\n",
    "                print(f\"  {section}:\")\n",
    "                for match in matches:\n",
    "                    print(f\"    JD Chunk: {match['jd_chunk'][:100]}...\")\n",
    "                    print(f\"    CV Chunk: {match['cv_chunk'][:100]}... (Section: {match['cv_section']})\")\n",
    "                    print(f\"    Similarity: {match['similarity']:.4f}\")\n",
    "            print()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    searcher = CVJDVectorSearch(\n",
    "        cv_persist_dir=\"./chroma_db\",\n",
    "        jd_persist_dir=\"./jd_chroma_db\",\n",
    "        cv_collection_name=\"cv_sections\",\n",
    "        jd_collection_name=\"job_descriptions\",\n",
    "        model=\"mxbai-embed-large\",\n",
    "        top_k_per_section=5\n",
    "    )\n",
    "    results = searcher.search_and_score_cvs(top_k_cvs=5)\n",
    "    searcher.print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b151e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 11:05:51,945 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-10-09 11:05:52,179 - INFO - Querying JD collection for all chunks\n",
      "2025-10-09 11:05:52,191 - INFO - Fetched 12 chunks from job_descriptions collection\n",
      "2025-10-09 11:05:52,695 - INFO - Ranked 3 CVs from job_descriptions collection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CV 1 (ID: 2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e) ---\n",
      "Total Score: 0.7344\n",
      "Section Scores:\n",
      "  job_title: 0.8868\n",
      "  required_skills: 0.8122\n",
      "  preferred_skills: 0.8213\n",
      "  required_qualifications: 0.7875\n",
      "  education_requirements: 0.8493\n",
      "  experience_requirements: 0.7872\n",
      "  technical_skills: 0.9298\n",
      "  soft_skills: 0.8232\n",
      "  certifications: 0.0000\n",
      "  responsibilities: 0.8187\n",
      "Section Details:\n",
      "  job_title:\n",
      "    JD Chunk: Data Analyst...\n",
      "    CV Chunk: A Data Analyst with about two years of professional experience specialized in transforming complex d... (Section: summary)\n",
      "    Similarity: 0.8868\n",
      "  required_skills:\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.8771\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8441\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8210\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7545\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8151\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.7998\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7934\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.7926\n",
      "  preferred_skills:\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8530\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8258\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.8227\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7838\n",
      "  required_qualifications:\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8478\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8255\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'loc... (Section: education)\n",
      "    Similarity: 0.8010\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7539\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: 1.92... (Section: years_of_experience)\n",
      "    Similarity: 0.7093\n",
      "  education_requirements:\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'loc... (Section: education)\n",
      "    Similarity: 0.8493\n",
      "  experience_requirements:\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8588\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8267\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7447\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: 1.92... (Section: years_of_experience)\n",
      "    Similarity: 0.7186\n",
      "  technical_skills:\n",
      "    JD Chunk: SQL | Python | R | Tableau | Power BI | Excel | Google Sheets | AWS | GCP | Azure | Git...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.9298\n",
      "  soft_skills:\n",
      "    JD Chunk: Excellent written and verbal communication skills | Experience presenting to executive-level stakeho...\n",
      "    CV Chunk: Curiosity | Problem Solving | System Understanding | Technical Skills | Analytical Thinking | Proble... (Section: soft_skills)\n",
      "    Similarity: 0.8232\n",
      "  responsibilities:\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: performance tracking, and decision-making at national, provincial, and local levels.', 'technologies... (Section: projects)\n",
      "    Similarity: 0.8415\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: {'name': 'Water Access Data Analysis', 'description': 'Conducted advanced Excel analysis on water ac... (Section: projects)\n",
      "    Similarity: 0.8393\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8326\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8263\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: 'description': 'Built a predictive model for quantitative finance using historical market data, achi... (Section: projects)\n",
      "    Similarity: 0.8175\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: performance tracking, and decision-making at national, provincial, and local levels.', 'technologies... (Section: projects)\n",
      "    Similarity: 0.8226\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8189\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: {'name': 'Water Access Data Analysis', 'description': 'Conducted advanced Excel analysis on water ac... (Section: projects)\n",
      "    Similarity: 0.8187\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: to identify critical gaps in community water access. Delivered data-driven recommendations that guid... (Section: projects)\n",
      "    Similarity: 0.8047\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8024\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8373\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8131\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: to identify critical gaps in community water access. Delivered data-driven recommendations that guid... (Section: projects)\n",
      "    Similarity: 0.8055\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: 'description': 'Built a predictive model for quantitative finance using historical market data, achi... (Section: projects)\n",
      "    Similarity: 0.8006\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: {'name': 'Water Access Data Analysis', 'description': 'Conducted advanced Excel analysis on water ac... (Section: projects)\n",
      "    Similarity: 0.7992\n",
      "\n",
      "\n",
      "--- CV 2 (ID: 153f885ca3d2db24433ed0fdc60b67e72dcc4714b7c8860e4799b3eb3c45f3b8) ---\n",
      "Total Score: 0.7340\n",
      "Section Scores:\n",
      "  job_title: 0.8868\n",
      "  required_skills: 0.8119\n",
      "  preferred_skills: 0.8211\n",
      "  required_qualifications: 0.7875\n",
      "  education_requirements: 0.8493\n",
      "  experience_requirements: 0.7873\n",
      "  technical_skills: 0.9298\n",
      "  soft_skills: 0.8232\n",
      "  certifications: 0.0000\n",
      "  responsibilities: 0.8160\n",
      "Section Details:\n",
      "  job_title:\n",
      "    JD Chunk: Data Analyst...\n",
      "    CV Chunk: A Data Analyst with about two years of professional experience specialized in transforming complex d... (Section: summary)\n",
      "    Similarity: 0.8868\n",
      "  required_skills:\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.8771\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8441\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8205\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7545\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8151\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.7978\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7934\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.7926\n",
      "  preferred_skills:\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8530\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8249\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.8227\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7838\n",
      "  required_qualifications:\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8478\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8254\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'loc... (Section: education)\n",
      "    Similarity: 0.8010\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7539\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: 1.92... (Section: years_of_experience)\n",
      "    Similarity: 0.7093\n",
      "  education_requirements:\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'loc... (Section: education)\n",
      "    Similarity: 0.8493\n",
      "  experience_requirements:\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8588\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8273\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7447\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: 1.92... (Section: years_of_experience)\n",
      "    Similarity: 0.7186\n",
      "  technical_skills:\n",
      "    JD Chunk: SQL | Python | R | Tableau | Power BI | Excel | Google Sheets | AWS | GCP | Azure | Git...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.9298\n",
      "  soft_skills:\n",
      "    JD Chunk: Excellent written and verbal communication skills | Experience presenting to executive-level stakeho...\n",
      "    CV Chunk: Curiosity | Problem Solving | System Understanding | Technical Skills | Analytical Thinking | Proble... (Section: soft_skills)\n",
      "    Similarity: 0.8232\n",
      "  responsibilities:\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: {'name': 'Conducted advanced Excel analysis on water access datasets', 'description': 'applying data... (Section: projects)\n",
      "    Similarity: 0.8532\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8326\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: planning and resource distribution.', 'technologies': ['SQL']} | {'name': 'Developed stakeholder-dri... (Section: projects)\n",
      "    Similarity: 0.8290\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8246\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.8128\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: {'name': 'Conducted advanced Excel analysis on water access datasets', 'description': 'applying data... (Section: projects)\n",
      "    Similarity: 0.8299\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: planning and resource distribution.', 'technologies': ['SQL']} | {'name': 'Developed stakeholder-dri... (Section: projects)\n",
      "    Similarity: 0.8241\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8189\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.7979\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: techniques to uncover trends and patterns and built a predictive model to forecast revenue and optim... (Section: work_experience)\n",
      "    Similarity: 0.7798\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8373\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: planning and resource distribution.', 'technologies': ['SQL']} | {'name': 'Developed stakeholder-dri... (Section: projects)\n",
      "    Similarity: 0.8104\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di... (Section: work_experience)\n",
      "    Similarity: 0.8098\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: {'name': 'Conducted advanced Excel analysis on water access datasets', 'description': 'applying data... (Section: projects)\n",
      "    Similarity: 0.8083\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: 'using historical market data, achieving a validation MSE of 0.998. The model improved risk forecast... (Section: projects)\n",
      "    Similarity: 0.7713\n",
      "\n",
      "\n",
      "--- CV 3 (ID: f188bc924e13a03c8f9d51467a099df83de36d97256564c10821e7ed79e3b8fe) ---\n",
      "Total Score: 0.7304\n",
      "Section Scores:\n",
      "  job_title: 0.8868\n",
      "  required_skills: 0.8064\n",
      "  preferred_skills: 0.8201\n",
      "  required_qualifications: 0.7894\n",
      "  education_requirements: 0.8493\n",
      "  experience_requirements: 0.7948\n",
      "  technical_skills: 0.8940\n",
      "  soft_skills: 0.8232\n",
      "  certifications: 0.0000\n",
      "  responsibilities: 0.8143\n",
      "Section Details:\n",
      "  job_title:\n",
      "    JD Chunk: Data Analyst...\n",
      "    CV Chunk: A Data Analyst with about two years of professional experience specialized in transforming complex d... (Section: summary)\n",
      "    Similarity: 0.8868\n",
      "  required_skills:\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.8822\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8387\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: Query for data transformation | Cross-platform data integration... (Section: skills)\n",
      "    Similarity: 0.7965\n",
      "    JD Chunk: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.7951\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8068\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.7985\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.7930\n",
      "    JD Chunk: with experimental design and statistical inference | Ability to work with ambiguous requirements and...\n",
      "    CV Chunk: Query for data transformation | Cross-platform data integration... (Section: skills)\n",
      "    Similarity: 0.7401\n",
      "  preferred_skills:\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8463\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.8337\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.8188\n",
      "    JD Chunk: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV Chunk: Query for data transformation | Cross-platform data integration... (Section: skills)\n",
      "    Similarity: 0.7817\n",
      "  required_qualifications:\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8384\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.8089\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'loc... (Section: education)\n",
      "    Similarity: 0.8010\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: 1.92... (Section: years_of_experience)\n",
      "    Similarity: 0.7093\n",
      "  education_requirements:\n",
      "    JD Chunk: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV Chunk: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'loc... (Section: education)\n",
      "    Similarity: 0.8493\n",
      "  experience_requirements:\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8503\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.8156\n",
      "    JD Chunk: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV Chunk: 1.92... (Section: years_of_experience)\n",
      "    Similarity: 0.7186\n",
      "  technical_skills:\n",
      "    JD Chunk: SQL | Python | R | Tableau | Power BI | Excel | Google Sheets | AWS | GCP | Azure | Git...\n",
      "    CV Chunk: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ... (Section: skills)\n",
      "    Similarity: 0.9296\n",
      "    JD Chunk: SQL | Python | R | Tableau | Power BI | Excel | Google Sheets | AWS | GCP | Azure | Git...\n",
      "    CV Chunk: Query for data transformation | Cross-platform data integration... (Section: skills)\n",
      "    Similarity: 0.8584\n",
      "  soft_skills:\n",
      "    JD Chunk: Excellent written and verbal communication skills | Experience presenting to executive-level stakeho...\n",
      "    CV Chunk: Curiosity | Problem Solving | System Understanding | Technical Skills | Analytical Thinking | Proble... (Section: soft_skills)\n",
      "    Similarity: 0.8232\n",
      "  responsibilities:\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: {'name': 'Leveraged SQL and Power BI skills to design interactive dashboards', 'description': 'Lever... (Section: projects)\n",
      "    Similarity: 0.8640\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8236\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.8100\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: for infrastructure improvements and resource allocation.', 'technologies': ['SQL']} | {'name': 'Buil... (Section: projects)\n",
      "    Similarity: 0.8086\n",
      "    JD Chunk: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV Chunk: and built a predictive model for quantitative finance with a validation MSE of about 0.998 to improv... (Section: projects)\n",
      "    Similarity: 0.7934\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: {'name': 'Leveraged SQL and Power BI skills to design interactive dashboards', 'description': 'Lever... (Section: projects)\n",
      "    Similarity: 0.8428\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8148\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: for infrastructure improvements and resource allocation.', 'technologies': ['SQL']} | {'name': 'Buil... (Section: projects)\n",
      "    Similarity: 0.8016\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.7968\n",
      "    JD Chunk: Product, and Operations to understand analytical needs | Translate business questions into analytica...\n",
      "    CV Chunk: and built a predictive model for quantitative finance with a validation MSE of about 0.998 to improv... (Section: projects)\n",
      "    Similarity: 0.7854\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da... (Section: work_experience)\n",
      "    Similarity: 0.8339\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: {'name': 'Leveraged SQL and Power BI skills to design interactive dashboards', 'description': 'Lever... (Section: projects)\n",
      "    Similarity: 0.8325\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: for infrastructure improvements and resource allocation.', 'technologies': ['SQL']} | {'name': 'Buil... (Section: projects)\n",
      "    Similarity: 0.8112\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: relationships for improved team visibility.']} | {'company': 'Freelancer (ALX venturers)', 'title': ... (Section: work_experience)\n",
      "    Similarity: 0.8094\n",
      "    JD Chunk: Collaborate with Engineering team to improve data collection and storage processes | Maintain and op...\n",
      "    CV Chunk: and built a predictive model for quantitative finance with a validation MSE of about 0.998 to improv... (Section: projects)\n",
      "    Similarity: 0.7862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CVJDVectorSearch:\n",
    "    \"\"\"Performs vector search of CVs against a job description with section-wise scoring.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        cv_persist_dir=\"./chroma_db_cv\",\n",
    "        jd_persist_dir=\"./jd_chroma_db\",\n",
    "        cv_collection_name=\"cv_sections\",\n",
    "        jd_collection_name=\"job_descriptions\",\n",
    "        model=\"mxbai-embed-large\",\n",
    "        top_k_per_section=5\n",
    "    ):\n",
    "        \"\"\"Initialize with Chroma collections and embedding model.\"\"\"\n",
    "        self.embeddings = OllamaEmbeddings(model=model)\n",
    "        self.top_k_per_section = top_k_per_section\n",
    "        \n",
    "        # Initialize Chroma vector stores\n",
    "        self.cv_vectorstore = Chroma(\n",
    "            persist_directory=cv_persist_dir,\n",
    "            embedding_function=self.embeddings,\n",
    "            collection_name=cv_collection_name,\n",
    "            collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "        self.jd_vectorstore = Chroma(\n",
    "            persist_directory=jd_persist_dir,\n",
    "            embedding_function=self.embeddings,\n",
    "            collection_name=jd_collection_name,\n",
    "            collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "        \n",
    "        # Section mapping: JD section -> List of relevant CV sections\n",
    "        self.section_mapping = {\n",
    "            \"job_title\": [\"summary\"],\n",
    "            \"required_skills\": [\"skills\", \"work_experience\"],\n",
    "            \"preferred_skills\": [\"skills\", \"work_experience\"],\n",
    "            \"required_qualifications\": [\"education\", \"years_of_experience\", \"work_experience\"],\n",
    "            \"education_requirements\": [\"education\"],\n",
    "            \"experience_requirements\": [\"work_experience\", \"years_of_experience\"],\n",
    "            \"technical_skills\": [\"skills\"],\n",
    "            \"soft_skills\": [\"soft_skills\"],\n",
    "            \"certifications\": [\"certifications\"],\n",
    "            \"responsibilities\": [\"work_experience\", \"projects\"]\n",
    "        }\n",
    "        \n",
    "        # Section weights for scoring\n",
    "        self.section_weights = {\n",
    "            \"required_skills\": 0.3,\n",
    "            \"preferred_skills\": 0.05,\n",
    "            \"required_qualifications\": 0.05,\n",
    "            \"education_requirements\": 0.05,\n",
    "            \"experience_requirements\": 0.05,\n",
    "            \"technical_skills\": 0.05,\n",
    "            \"soft_skills\": 0.1,\n",
    "            \"certifications\": 0.1,\n",
    "            \"responsibilities\": 0.1,\n",
    "            \"job_title\": 0.05\n",
    "        }\n",
    "        \n",
    "    def fetch_jd_chunks(self) -> List[Dict]:\n",
    "        \"\"\"Fetch all chunks from the job_descriptions collection.\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Querying JD collection for all chunks\")\n",
    "            data = self.jd_vectorstore.get(\n",
    "                include=[\"documents\", \"metadatas\", \"embeddings\"]\n",
    "            )\n",
    "            chunks = [\n",
    "                {\n",
    "                    \"text\": data[\"documents\"][i],\n",
    "                    \"metadata\": data[\"metadatas\"][i],\n",
    "                    \"embedding\": data[\"embeddings\"][i]\n",
    "                }\n",
    "                for i in range(len(data[\"documents\"]))\n",
    "            ]\n",
    "            logger.info(f\"Fetched {len(chunks)} chunks from job_descriptions collection\")\n",
    "            \n",
    "            if len(chunks) == 0:\n",
    "                all_data = self.jd_vectorstore.get(include=[\"metadatas\"])\n",
    "                all_jd_ids = set(meta.get(\"jd_id\", \"UNKNOWN\") for meta in all_data.get(\"metadatas\", []))\n",
    "                logger.warning(f\"No chunks found in job_descriptions. Available JD IDs: {all_jd_ids}\")\n",
    "            \n",
    "            return chunks\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to fetch JD chunks: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def search_cv_chunks(\n",
    "        self,\n",
    "        jd_chunk_embedding: List[float],\n",
    "        cv_sections: List[str],\n",
    "        cv_id: str = None\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Search CV chunks matching a JD chunk embedding, filtered by CV sections and optional CV ID.\"\"\"\n",
    "        try:\n",
    "            # Access the underlying Chroma client\n",
    "            collection = self.cv_vectorstore._collection\n",
    "            # Build where clause with $and operator if cv_id is provided\n",
    "            if cv_id:\n",
    "                where_clause = {\n",
    "                    \"$and\": [\n",
    "                        {\"section\": {\"$in\": cv_sections}},\n",
    "                        {\"cv_id\": cv_id}\n",
    "                    ]\n",
    "                }\n",
    "            else:\n",
    "                where_clause = {\"section\": {\"$in\": cv_sections}}\n",
    "            \n",
    "            # Perform query using precomputed embedding\n",
    "            results = collection.query(\n",
    "                query_embeddings=[jd_chunk_embedding],\n",
    "                n_results=self.top_k_per_section,\n",
    "                where=where_clause,\n",
    "                include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "            )\n",
    "            \n",
    "            # Check if results are empty\n",
    "            if not results[\"documents\"] or not results[\"documents\"][0]:\n",
    "                logger.warning(f\"No CV chunks found for sections {cv_sections} and cv_id {cv_id}\")\n",
    "                return []\n",
    "            \n",
    "            return [\n",
    "                {\n",
    "                    \"text\": results[\"documents\"][0][i],\n",
    "                    \"metadata\": results[\"metadatas\"][0][i],\n",
    "                    \"score\": results[\"distances\"][0][i],\n",
    "                    \"cv_id\": results[\"metadatas\"][0][i][\"cv_id\"],\n",
    "                    \"section\": results[\"metadatas\"][0][i][\"section\"]\n",
    "                }\n",
    "                for i in range(len(results[\"documents\"][0]))\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error searching CV chunks: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def compute_section_score(\n",
    "        self,\n",
    "        jd_section: str,\n",
    "        jd_chunks: List[Dict],\n",
    "        cv_id: str\n",
    "    ) -> Tuple[float, List[Dict]]:\n",
    "        \"\"\"Compute similarity score for a JD section against a CV, handling multiple chunks.\"\"\"\n",
    "        cv_sections = self.section_mapping.get(jd_section, [])\n",
    "        if not cv_sections:\n",
    "            return 0.0, []\n",
    "        \n",
    "        similarities = []\n",
    "        matched_chunks = []\n",
    "        \n",
    "        for jd_chunk in jd_chunks:\n",
    "            if jd_chunk[\"metadata\"][\"section\"] != jd_section:\n",
    "                continue\n",
    "            results = self.search_cv_chunks(\n",
    "                jd_chunk_embedding=jd_chunk[\"embedding\"],\n",
    "                cv_sections=cv_sections,\n",
    "                cv_id=cv_id\n",
    "            )\n",
    "            for result in results:\n",
    "                # Convert distance (0 to 2, where 0 is identical) to similarity (0 to 1)\n",
    "                similarity = 1 - (result[\"score\"] / 2)\n",
    "                similarities.append(similarity)\n",
    "                matched_chunks.append({\n",
    "                    \"jd_chunk\": jd_chunk[\"text\"],\n",
    "                    \"cv_chunk\": result[\"text\"],\n",
    "                    \"cv_section\": result[\"section\"],\n",
    "                    \"similarity\": similarity\n",
    "                })\n",
    "        \n",
    "        # Average similarity across all matches for this section\n",
    "        section_score = np.mean(similarities) if similarities else 0.0\n",
    "        return section_score, matched_chunks\n",
    "    \n",
    "    def search_and_score_cvs(self, top_k_cvs: int = 5) -> List[Dict]:\n",
    "        \"\"\"Search and score CVs against the JD in job_descriptions collection.\"\"\"\n",
    "        # Fetch JD chunks\n",
    "        jd_chunks = self.fetch_jd_chunks()\n",
    "        if not jd_chunks:\n",
    "            logger.error(\"No JD chunks found, aborting search\")\n",
    "            return []\n",
    "        \n",
    "        # Get all unique CV IDs\n",
    "        cv_ids = set(self.cv_vectorstore.get()[\"metadatas\"][i][\"cv_id\"] \n",
    "                    for i in range(len(self.cv_vectorstore.get()[\"metadatas\"])))\n",
    "        \n",
    "        # Score each CV\n",
    "        cv_scores = []\n",
    "        for cv_id in cv_ids:\n",
    "            section_scores = {}\n",
    "            section_details = {}\n",
    "            total_score = 0.0\n",
    "            total_weight = 0.0\n",
    "            \n",
    "            # Compute score for each JD section\n",
    "            for jd_section in self.section_mapping.keys():\n",
    "                score, matched_chunks = self.compute_section_score(jd_section, jd_chunks, cv_id)\n",
    "                section_scores[jd_section] = score\n",
    "                if score > 0:\n",
    "                    section_details[jd_section] = matched_chunks\n",
    "                total_score += score * self.section_weights.get(jd_section, 0.05)\n",
    "                total_weight += self.section_weights.get(jd_section, 0.05)\n",
    "            \n",
    "            # Normalize total score by sum of weights\n",
    "            if total_weight > 0:\n",
    "                total_score /= total_weight\n",
    "            else:\n",
    "                total_score = 0.0\n",
    "            \n",
    "            cv_scores.append({\n",
    "                \"cv_id\": cv_id,\n",
    "                \"total_score\": total_score,\n",
    "                \"section_scores\": section_scores,\n",
    "                \"section_details\": section_details\n",
    "            })\n",
    "        \n",
    "        # Sort CVs by total score\n",
    "        cv_scores.sort(key=lambda x: x[\"total_score\"], reverse=True)\n",
    "        logger.info(f\"Ranked {len(cv_scores)} CVs from job_descriptions collection\")\n",
    "        return cv_scores[:top_k_cvs]\n",
    "    \n",
    "    def print_results(self, results: List[Dict]):\n",
    "        \"\"\"Print ranked CVs with section-wise scores and details.\"\"\"\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"\\n--- CV {i+1} (ID: {result['cv_id']}) ---\")\n",
    "            print(f\"Total Score: {result['total_score']:.4f}\")\n",
    "            print(\"Section Scores:\")\n",
    "            for section, score in result[\"section_scores\"].items():\n",
    "                print(f\"  {section}: {score:.4f}\")\n",
    "            print(\"Section Details:\")\n",
    "            for section, matches in result[\"section_details\"].items():\n",
    "                print(f\"  {section}:\")\n",
    "                for match in matches:\n",
    "                    print(f\"    JD Chunk: {match['jd_chunk'][:100]}...\")\n",
    "                    print(f\"    CV Chunk: {match['cv_chunk'][:100]}... (Section: {match['cv_section']})\")\n",
    "                    print(f\"    Similarity: {match['similarity']:.4f}\")\n",
    "            print()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    searcher = CVJDVectorSearch(\n",
    "        cv_persist_dir=\"./chroma_db\",\n",
    "        jd_persist_dir=\"./jd_chroma_db\",\n",
    "        cv_collection_name=\"cv_sections\",\n",
    "        jd_collection_name=\"job_descriptions\",\n",
    "        model=\"mxbai-embed-large\",\n",
    "        top_k_per_section=5\n",
    "    )\n",
    "    results = searcher.search_and_score_cvs(top_k_cvs=5)\n",
    "    searcher.print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d822ea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 11:51:26,558 - INFO - Fetching job description chunks...\n",
      "2025-10-09 11:51:26,576 - INFO - ‚úÖ Fetched 12 JD chunks.\n",
      "2025-10-09 11:51:26,584 - INFO - Found 3 unique CVs to score.\n",
      "2025-10-09 11:51:26,587 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,594 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,603 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,610 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,619 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,629 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,636 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,643 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,649 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,657 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,666 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,674 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,680 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,687 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,694 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,701 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,715 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,725 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,736 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,746 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,755 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,761 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,768 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,772 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,779 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,785 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,792 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,798 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,803 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,809 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,816 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,824 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,828 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,833 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,841 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,847 - WARNING - Falling back to _collection.query() for Chroma compatibility.\n",
      "2025-10-09 11:51:26,853 - INFO - ‚úÖ Ranked 3 CVs successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV 1 | ID: 2b95c553fbd50733f96df36baaabea5e2c35098b8a16d270c2e4d5d2806f067e ===\n",
      "Total Score: 0.8262\n",
      "\n",
      "Section Scores:\n",
      "  job_title                : 0.8868\n",
      "  required_skills          : 0.8122\n",
      "  preferred_skills         : 0.8213\n",
      "  required_qualifications  : 0.7875\n",
      "  education_requirements   : 0.8493\n",
      "  experience_requirements  : 0.7872\n",
      "  technical_skills         : 0.9298\n",
      "  soft_skills              : 0.8232\n",
      "  certifications           : 0.0000\n",
      "  responsibilities         : 0.8187\n",
      "\n",
      "Detailed Matches:\n",
      "\n",
      "  [JOB_TITLE]\n",
      "    JD: Data Analyst...\n",
      "    CV: A Data Analyst with about two years of professional experience specialized in transforming complex d...\n",
      "    Similarity: 0.8868\n",
      "\n",
      "  [REQUIRED_SKILLS]\n",
      "    JD: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ...\n",
      "    Similarity: 0.8771\n",
      "    JD: Advanced SQL proficiency (complex queries, joins, window functions, performance optimization) | Pyth...\n",
      "    CV: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da...\n",
      "    Similarity: 0.8441\n",
      "\n",
      "  [PREFERRED_SKILLS]\n",
      "    JD: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da...\n",
      "    Similarity: 0.8530\n",
      "    JD: Experience with cloud platforms (AWS, GCP, Azure) and their analytics services | Knowledge of machin...\n",
      "    CV: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di...\n",
      "    Similarity: 0.8258\n",
      "\n",
      "  [REQUIRED_QUALIFICATIONS]\n",
      "    JD: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da...\n",
      "    Similarity: 0.8478\n",
      "    JD: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di...\n",
      "    Similarity: 0.8255\n",
      "\n",
      "  [EDUCATION_REQUIREMENTS]\n",
      "    JD: Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science, or related analytical ...\n",
      "    CV: {'degree': 'Bachelor of Science', 'field_of_study': 'Computer Science', 'institution': 'KNUST', 'loc...\n",
      "    Similarity: 0.8493\n",
      "\n",
      "  [EXPERIENCE_REQUIREMENTS]\n",
      "    JD: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV: {'company': 'Really Great Tech', 'title': 'Data Analytics/AI/ML Engineer', 'location': '', 'start_da...\n",
      "    Similarity: 0.8588\n",
      "    JD: years_of_experience: 2-4 years | specific_experience: in data analysis, business intelligence, or re...\n",
      "    CV: for improved team visibility.', 'Analyzed patient data and developed a predictive model for heart di...\n",
      "    Similarity: 0.8267\n",
      "\n",
      "  [TECHNICAL_SKILLS]\n",
      "    JD: SQL | Python | R | Tableau | Power BI | Excel | Google Sheets | AWS | GCP | Azure | Git...\n",
      "    CV: Python | R | AWS | Microsoft Excel | Google Sheets | Power BI | SQL | NumPy | Pandas | Scikit-Learn ...\n",
      "    Similarity: 0.9298\n",
      "\n",
      "  [SOFT_SKILLS]\n",
      "    JD: Excellent written and verbal communication skills | Experience presenting to executive-level stakeho...\n",
      "    CV: Curiosity | Problem Solving | System Understanding | Technical Skills | Analytical Thinking | Proble...\n",
      "    Similarity: 0.8232\n",
      "\n",
      "  [RESPONSIBILITIES]\n",
      "    JD: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV: performance tracking, and decision-making at national, provincial, and local levels.', 'technologies...\n",
      "    Similarity: 0.8415\n",
      "    JD: Extract, clean, and analyze large datasets from multiple sources including databases, APIs, and thir...\n",
      "    CV: {'name': 'Water Access Data Analysis', 'description': 'Conducted advanced Excel analysis on water ac...\n",
      "    Similarity: 0.8393\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class CVJDVectorSearch:\n",
    "    \"\"\"Performs vector search and scoring of CVs against a job description (JD) using embeddings and section-based logic.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cv_persist_dir: str = \"./chroma_db_cv\",\n",
    "        jd_persist_dir: str = \"./jd_chroma_db\",\n",
    "        cv_collection_name: str = \"cv_sections\",\n",
    "        jd_collection_name: str = \"job_descriptions\",\n",
    "        model: str = \"mxbai-embed-large\",\n",
    "        top_k_per_section: int = 5,\n",
    "    ):\n",
    "        \"\"\"Initialize Chroma vector stores and embedding model.\"\"\"\n",
    "        self.embeddings = OllamaEmbeddings(model=model)\n",
    "        self.top_k_per_section = top_k_per_section\n",
    "\n",
    "        self.cv_vectorstore = Chroma(\n",
    "            persist_directory=cv_persist_dir,\n",
    "            embedding_function=self.embeddings,\n",
    "            collection_name=cv_collection_name,\n",
    "            collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "        self.jd_vectorstore = Chroma(\n",
    "            persist_directory=jd_persist_dir,\n",
    "            embedding_function=self.embeddings,\n",
    "            collection_name=jd_collection_name,\n",
    "            collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "\n",
    "        # Section mapping: JD section ‚Üí relevant CV sections\n",
    "        self.section_mapping = {\n",
    "            \"job_title\": [\"summary\"],\n",
    "            \"required_skills\": [\"skills\", \"work_experience\"],\n",
    "            \"preferred_skills\": [\"skills\", \"work_experience\"],\n",
    "            \"required_qualifications\": [\"education\", \"years_of_experience\", \"work_experience\"],\n",
    "            \"education_requirements\": [\"education\"],\n",
    "            \"experience_requirements\": [\"work_experience\", \"years_of_experience\"],\n",
    "            \"technical_skills\": [\"skills\"],\n",
    "            \"soft_skills\": [\"soft_skills\"],\n",
    "            \"certifications\": [\"certifications\"],\n",
    "            \"responsibilities\": [\"work_experience\", \"projects\"],\n",
    "        }\n",
    "\n",
    "        # Section weights\n",
    "        self.section_weights = {\n",
    "            \"required_skills\": 0.3,\n",
    "            \"preferred_skills\": 0.05,\n",
    "            \"required_qualifications\": 0.05,\n",
    "            \"education_requirements\": 0.05,\n",
    "            \"experience_requirements\": 0.05,\n",
    "            \"technical_skills\": 0.05,\n",
    "            \"soft_skills\": 0.1,\n",
    "            \"certifications\": 0.1,\n",
    "            \"responsibilities\": 0.1,\n",
    "            \"job_title\": 0.05,\n",
    "        }\n",
    "\n",
    "    # -------------------------------\n",
    "    # üîπ JD Fetching\n",
    "    # -------------------------------\n",
    "    def fetch_jd_chunks(self, jd_id: Optional[str] = None) -> List[Dict]:\n",
    "        \"\"\"Fetch all JD chunks (optionally filter by jd_id).\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Fetching job description chunks...\")\n",
    "            data = self.jd_vectorstore.get(include=[\"documents\", \"metadatas\", \"embeddings\"])\n",
    "            chunks = [\n",
    "                {\n",
    "                    \"text\": data[\"documents\"][i],\n",
    "                    \"metadata\": data[\"metadatas\"][i],\n",
    "                    \"embedding\": data[\"embeddings\"][i],\n",
    "                }\n",
    "                for i in range(len(data[\"documents\"]))\n",
    "            ]\n",
    "\n",
    "            if jd_id:\n",
    "                chunks = [c for c in chunks if c[\"metadata\"].get(\"jd_id\") == jd_id]\n",
    "\n",
    "            logger.info(f\"‚úÖ Fetched {len(chunks)} JD chunks.\")\n",
    "            return chunks\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to fetch JD chunks: {e}\")\n",
    "            return []\n",
    "\n",
    "    # -------------------------------\n",
    "    # üîπ CV Search Wrapper\n",
    "    # -------------------------------\n",
    "    def _safe_query_chroma(self, vectorstore: Chroma, **kwargs) -> Dict:\n",
    "        \"\"\"Safely query Chroma using public method or fallback to private collection.\"\"\"\n",
    "        try:\n",
    "            return vectorstore.query(**kwargs)\n",
    "        except Exception:\n",
    "            logger.warning(\"Falling back to _collection.query() for Chroma compatibility.\")\n",
    "            collection = vectorstore._collection\n",
    "            return collection.query(**kwargs)\n",
    "\n",
    "    def search_cv_chunks(\n",
    "        self,\n",
    "        jd_chunk_embedding: List[float],\n",
    "        cv_sections: List[str],\n",
    "        cv_id: Optional[str] = None,\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Search CV chunks matching a JD chunk embedding, filtered by section and optionally CV ID.\"\"\"\n",
    "        try:\n",
    "            where_clause = {\"section\": {\"$in\": cv_sections}}\n",
    "            if cv_id:\n",
    "                where_clause = {\n",
    "                    \"$and\": [\n",
    "                        {\"section\": {\"$in\": cv_sections}},\n",
    "                        {\"cv_id\": cv_id}\n",
    "                    ]\n",
    "                }\n",
    "\n",
    "            results = self._safe_query_chroma(\n",
    "                self.cv_vectorstore,\n",
    "                query_embeddings=[jd_chunk_embedding],\n",
    "                n_results=self.top_k_per_section,\n",
    "                where=where_clause,\n",
    "                include=[\"documents\", \"metadatas\", \"distances\"],\n",
    "            )\n",
    "\n",
    "            if not results.get(\"documents\") or not results[\"documents\"][0]:\n",
    "                logger.debug(f\"No results for CV sections {cv_sections} (cv_id={cv_id})\")\n",
    "                return []\n",
    "\n",
    "            return [\n",
    "                {\n",
    "                    \"text\": results[\"documents\"][0][i],\n",
    "                    \"metadata\": results[\"metadatas\"][0][i],\n",
    "                    \"score\": results[\"distances\"][0][i],\n",
    "                    \"cv_id\": results[\"metadatas\"][0][i][\"cv_id\"],\n",
    "                    \"section\": results[\"metadatas\"][0][i][\"section\"],\n",
    "                }\n",
    "                for i in range(len(results[\"documents\"][0]))\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error searching CV chunks: {e}\")\n",
    "            return []\n",
    "\n",
    "    # -------------------------------\n",
    "    # üîπ Section Scoring\n",
    "    # -------------------------------\n",
    "    def compute_section_score(\n",
    "        self, jd_section: str, jd_chunks: List[Dict], cv_id: str\n",
    "    ) -> Tuple[float, List[Dict]]:\n",
    "        \"\"\"Compute similarity score for a JD section vs a CV.\"\"\"\n",
    "        cv_sections = self.section_mapping.get(jd_section, [])\n",
    "        if not cv_sections:\n",
    "            return 0.0, []\n",
    "\n",
    "        similarities, matched_chunks = [], []\n",
    "\n",
    "        for jd_chunk in jd_chunks:\n",
    "            if jd_chunk[\"metadata\"].get(\"section\") != jd_section:\n",
    "                continue\n",
    "\n",
    "            results = self.search_cv_chunks(\n",
    "                jd_chunk_embedding=jd_chunk[\"embedding\"],\n",
    "                cv_sections=cv_sections,\n",
    "                cv_id=cv_id,\n",
    "            )\n",
    "            for r in results:\n",
    "                similarity = 1 - (r[\"score\"] / 2)  # Convert cosine distance ‚Üí similarity\n",
    "                similarities.append(similarity)\n",
    "                matched_chunks.append({\n",
    "                    \"jd_chunk\": jd_chunk[\"text\"],\n",
    "                    \"cv_chunk\": r[\"text\"],\n",
    "                    \"cv_section\": r[\"section\"],\n",
    "                    \"similarity\": similarity,\n",
    "                })\n",
    "\n",
    "        section_score = np.mean(similarities) if similarities else 0.0\n",
    "        return section_score, matched_chunks\n",
    "\n",
    "    # -------------------------------\n",
    "    # üîπ Main Scoring Function\n",
    "    # -------------------------------\n",
    "    def search_and_score_cvs(\n",
    "        self, top_k_cvs: int = 5, jd_id: Optional[str] = None\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Search and score all CVs against a JD (optionally specify jd_id).\"\"\"\n",
    "        jd_chunks = self.fetch_jd_chunks(jd_id)\n",
    "        if not jd_chunks:\n",
    "            logger.error(\"No JD chunks found; aborting search.\")\n",
    "            return []\n",
    "\n",
    "        cv_data = self.cv_vectorstore.get(include=[\"metadatas\"])\n",
    "        cv_ids = {meta[\"cv_id\"] for meta in cv_data[\"metadatas\"]}\n",
    "        logger.info(f\"Found {len(cv_ids)} unique CVs to score.\")\n",
    "\n",
    "        cv_scores = []\n",
    "\n",
    "        for cv_id in cv_ids:\n",
    "            section_scores, section_details = {}, {}\n",
    "            weighted_sum, total_weight = 0.0, 0.0\n",
    "\n",
    "            for jd_section in self.section_mapping.keys():\n",
    "                score, matches = self.compute_section_score(jd_section, jd_chunks, cv_id)\n",
    "                section_scores[jd_section] = score\n",
    "                if matches:\n",
    "                    section_details[jd_section] = matches\n",
    "                    weight = self.section_weights.get(jd_section, 0.05)\n",
    "                    weighted_sum += score * weight\n",
    "                    total_weight += weight\n",
    "\n",
    "            total_score = (weighted_sum / total_weight) if total_weight > 0 else 0.0\n",
    "\n",
    "            cv_scores.append({\n",
    "                \"cv_id\": cv_id,\n",
    "                \"total_score\": total_score,\n",
    "                \"section_scores\": section_scores,\n",
    "                \"section_details\": section_details,\n",
    "            })\n",
    "\n",
    "        cv_scores.sort(key=lambda x: x[\"total_score\"], reverse=True)\n",
    "        logger.info(f\"‚úÖ Ranked {len(cv_scores)} CVs successfully.\")\n",
    "        return cv_scores[:top_k_cvs]\n",
    "\n",
    "    # -------------------------------\n",
    "    # üîπ Result Display\n",
    "    # -------------------------------\n",
    "    def print_results(self, results: List[Dict], show_details: bool = False):\n",
    "        \"\"\"Print ranked CVs with section-wise scores (and optional detail view).\"\"\"\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"\\n=== CV {i+1} | ID: {result['cv_id']} ===\")\n",
    "            print(f\"Total Score: {result['total_score']:.4f}\\n\")\n",
    "            print(\"Section Scores:\")\n",
    "            for section, score in result[\"section_scores\"].items():\n",
    "                print(f\"  {section:25}: {score:.4f}\")\n",
    "\n",
    "            if show_details and result[\"section_details\"]:\n",
    "                print(\"\\nDetailed Matches:\")\n",
    "                for section, matches in result[\"section_details\"].items():\n",
    "                    print(f\"\\n  [{section.upper()}]\")\n",
    "                    for match in matches[:2]:  # show top 2 per section\n",
    "                        print(f\"    JD: {match['jd_chunk'][:100]}...\")\n",
    "                        print(f\"    CV: {match['cv_chunk'][:100]}...\")\n",
    "                        print(f\"    Similarity: {match['similarity']:.4f}\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    searcher = CVJDVectorSearch(\n",
    "        cv_persist_dir=\"./chroma_db\",\n",
    "        jd_persist_dir=\"./jd_chroma_db\",\n",
    "        cv_collection_name=\"cv_sections\",\n",
    "        jd_collection_name=\"job_descriptions\",\n",
    "        model=\"mxbai-embed-large\",\n",
    "        top_k_per_section=5,\n",
    "    )\n",
    "    results = searcher.search_and_score_cvs(top_k_cvs=1)\n",
    "    searcher.print_results(results, show_details=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ddcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
