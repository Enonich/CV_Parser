{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a9893c",
   "metadata": {},
   "source": [
    "### OLD RERANKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e4ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List, Dict, Optional\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pymongo\n",
    "try:\n",
    "    # Prefer sentence-transformers CrossEncoder if available (better handling of pair inputs)\n",
    "    from sentence_transformers import CrossEncoder as STCrossEncoder  # type: ignore\n",
    "    _HAS_ST = True\n",
    "except Exception:  # pragma: no cover - availability dependent\n",
    "    _HAS_ST = False\n",
    "\n",
    "from identifiers import build_mongo_names, sanitize_fragment  # dynamic multi-tenancy resolution\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CVJDReranker:\n",
    "    \"\"\"Reranks CVs against a job description using a cross-encoder model.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        mongo_uri: str,\n",
    "        mongo_db: str = \"cv_db\",\n",
    "        cv_collection: str = \"cvs\",\n",
    "        jd_collection: str = \"job_descriptions\",\n",
    "        model_name: str = \"BAAI/bge-reranker-base\"\n",
    "        # model_name: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\" \n",
    "    ):\n",
    "        \"\"\"Initialize MongoDB client and cross-encoder model.\"\"\"\n",
    "        # Initialize MongoDB client\n",
    "        try:\n",
    "            self.mongo_client = pymongo.MongoClient(mongo_uri)\n",
    "            self.cv_db = self.mongo_client[mongo_db]\n",
    "            self.cv_collection = self.cv_db[cv_collection]\n",
    "            self.jd_collection = self.cv_db[jd_collection]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize MongoDB client: {e}\")\n",
    "            raise ValueError(\"MongoDB connection failed. Provide a valid mongo_uri.\")\n",
    "        \n",
    "        # Initialize cross-encoder\n",
    "        try:\n",
    "            self.model_name = model_name\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            self.cross_encoder = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.cross_encoder.to(self.device)\n",
    "            logger.info(f\"Initialized cross-encoder model {model_name} on {self.device}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize cross-encoder: {e}\")\n",
    "            raise RuntimeError(f\"Failed to load model {model_name}\")\n",
    "\n",
    "    def fetch_jd_text(self, jd_id: str) -> str:\n",
    "        \"\"\"Fetch full job description text from MongoDB using jd_id.\"\"\"\n",
    "        try:\n",
    "            jd_doc = self.jd_collection.find_one({\"jd_id\": jd_id})\n",
    "            if not jd_doc:\n",
    "                logger.warning(f\"No job description found for jd_id {jd_id} in MongoDB\")\n",
    "                return \"\"\n",
    "            \n",
    "            # Concatenate relevant fields into a single string\n",
    "            # Adjust based on actual MongoDB document structure\n",
    "            fields = [\n",
    "                jd_doc.get(\"job_title\", \"\"),\n",
    "                jd_doc.get(\"required_skills\", \"\"),\n",
    "                jd_doc.get(\"preferred_skills\", \"\"),\n",
    "                jd_doc.get(\"required_qualifications\", \"\"),\n",
    "                jd_doc.get(\"education_requirements\", \"\"),\n",
    "                jd_doc.get(\"experience_requirements\", \"\"),\n",
    "                jd_doc.get(\"technical_skills\", \"\"),\n",
    "                jd_doc.get(\"soft_skills\", \"\"),\n",
    "                jd_doc.get(\"certifications\", \"\"),\n",
    "                jd_doc.get(\"responsibilities\", \"\"),\n",
    "                jd_doc.get(\"description\", \"\"),\n",
    "                jd_doc.get(\"full_text\", \"\")  # Include full_text if available\n",
    "            ]\n",
    "            # Filter out empty fields and join with newlines\n",
    "            full_text = \"\\n\".join(field for field in fields if field)\n",
    "            logger.info(f\"Fetched JD text for jd_id {jd_id}\")\n",
    "            return full_text\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching JD {jd_id} from MongoDB: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def fetch_cv_text(self, cv_id: str) -> str:\n",
    "        \"\"\"Fetch full CV text from MongoDB using cv_id.\"\"\"\n",
    "        try:\n",
    "            cv_doc = self.cv_collection.find_one({\"cv_id\": cv_id})\n",
    "            if cv_doc:\n",
    "                full_text = cv_doc.get(\"full_text\", \"\")\n",
    "                logger.info(f\"Fetched CV text for cv_id {cv_id}\")\n",
    "                return full_text\n",
    "            else:\n",
    "                logger.warning(f\"No CV found for cv_id {cv_id} in MongoDB\")\n",
    "                return \"\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching CV {cv_id} from MongoDB: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def rerank_cvs(self, cv_results: List[Dict], jd_id: str, batch_size: int = 8) -> List[Dict]:\n",
    "        \"\"\"Rerank CVs against a job description using the cross-encoder.\n",
    "\n",
    "        Args:\n",
    "            cv_results: List of dicts from CVJDVectorSearch.search_and_score_cvs, each with 'cv_id'\n",
    "            jd_id: ID of the job description to fetch from MongoDB\n",
    "            batch_size: Batch size for cross-encoder inference to manage memory\n",
    "\n",
    "        Returns:\n",
    "            The same list, sorted by 'cross_encoder_score' descending, with new key added.\n",
    "        \"\"\"\n",
    "        # Fetch job description\n",
    "        jd_text = self.fetch_jd_text(jd_id)\n",
    "        if not jd_text:\n",
    "            logger.error(f\"No JD text available for jd_id {jd_id}; returning original results\")\n",
    "            return cv_results\n",
    "\n",
    "        # Collect CV texts\n",
    "        cv_texts = []\n",
    "        valid_results = []\n",
    "        for result in cv_results:\n",
    "            cv_id = result.get(\"cv_id\")\n",
    "            if not cv_id:\n",
    "                logger.warning(f\"Skipping result with missing cv_id: {result}\")\n",
    "                continue\n",
    "            cv_text = self.fetch_cv_text(cv_id)\n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "            else:\n",
    "                result[\"cross_encoder_score\"] = float('-inf')  # Penalize missing CVs\n",
    "\n",
    "        # Prepare pairs: [[jd_text, cv_text1], [jd_text, cv_text2], ...]\n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "        if not pairs:\n",
    "            logger.warning(\"No valid CV texts for reranking\")\n",
    "            return cv_results\n",
    "\n",
    "        # Process in batches\n",
    "        scores = []\n",
    "        for i in range(0, len(pairs), batch_size):\n",
    "            batch_pairs = pairs[i:i + batch_size]\n",
    "            try:\n",
    "                features = self.tokenizer(\n",
    "                    batch_pairs,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    return_tensors=\"pt\"\n",
    "                ).to(self.device)\n",
    "                with torch.no_grad():\n",
    "                    batch_scores = self.cross_encoder(**features).logits[:, 0]  # Higher score = more relevant\n",
    "                scores.extend(batch_scores.cpu().tolist())\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error during cross-encoder inference: {e}\")\n",
    "                scores.extend([float('-inf')] * len(batch_pairs))  # Penalize failed inferences\n",
    "\n",
    "        # Assign scores back to valid results\n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = score\n",
    "\n",
    "        # Sort all results by cross_encoder_score descending\n",
    "        cv_results.sort(key=lambda x: x.get(\"cross_encoder_score\", float('-inf')), reverse=True)\n",
    "        logger.info(f\"Reranked {len(cv_results)} CVs using cross-encoder for jd_id {jd_id}\")\n",
    "        return cv_results\n",
    "\n",
    "    def rerank_cvs_for_job(\n",
    "        self,\n",
    "        cv_results: List[Dict],\n",
    "        company_name: str,\n",
    "        job_title: str,\n",
    "        batch_size: int = 8\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Rerank CVs using dynamic multi-tenant Mongo collections.\n",
    "\n",
    "        Simplified JD retrieval: because each (company, job) has a dedicated collection `jd_<job_slug>`\n",
    "        inside its own company database, we can first attempt to load *all* docs from that collection\n",
    "        without filtering. Filtering by company/job fields is redundant and fragile if capitalization\n",
    "        or normalization differs. Fallbacks (sanitized / regex) retained only for legacy/static scenarios.\n",
    "        \"\"\"\n",
    "        # Resolve dynamic names\n",
    "        try:\n",
    "            db_name_dyn, cv_coll_dyn_name, jd_coll_dyn_name = build_mongo_names(company_name, job_title)\n",
    "            dyn_db = self.mongo_client[db_name_dyn]\n",
    "            dyn_jd_coll = dyn_db[jd_coll_dyn_name]\n",
    "            dyn_cv_coll = dyn_db[cv_coll_dyn_name]\n",
    "            logger.info(f\"[RERANK] Dynamic Mongo resolved db='{db_name_dyn}' cv_coll='{cv_coll_dyn_name}' jd_coll='{jd_coll_dyn_name}'\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to resolve dynamic Mongo collections: {e}\")\n",
    "            return cv_results\n",
    "        # Simplified JD fetch: load all docs in the job-specific collection\n",
    "        try:\n",
    "            jd_docs = list(dyn_jd_coll.find({}))\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Mongo query failed for dynamic JD collection: {e}\")\n",
    "            jd_docs = []\n",
    "\n",
    "        if not jd_docs:\n",
    "            logger.warning(\"No JD docs in dynamic collection; attempting legacy static collection fallback\")\n",
    "            try:\n",
    "                # Legacy fallback attempts: exact, sanitized, case-insensitive\n",
    "                jd_docs = list(self.jd_collection.find({\"company_name\": company_name, \"job_title\": job_title}))\n",
    "                if not jd_docs:\n",
    "                    jd_docs = list(self.jd_collection.find({\"company_name_sanitized\": sanitize_fragment(company_name), \"job_title_sanitized\": sanitize_fragment(job_title)}))\n",
    "                if not jd_docs:\n",
    "                    jd_docs = list(self.jd_collection.find({\n",
    "                        \"company_name\": {\"$regex\": f\"^{company_name}$\", \"$options\": \"i\"},\n",
    "                        \"job_title\": {\"$regex\": f\"^{job_title}$\", \"$options\": \"i\"}\n",
    "                    }))\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Legacy JD fallback query failed: {e}\")\n",
    "                jd_docs = []\n",
    "        if not jd_docs:\n",
    "            logger.warning(\"No JD docs found after fallback; skipping rerank\")\n",
    "            return cv_results\n",
    "\n",
    "        logger.info(f\"[RERANK] Loaded {len(jd_docs)} JD doc(s) for company='{company_name}' job='{job_title}'\")\n",
    "\n",
    "        # Construct JD text\n",
    "        jd_parts: List[str] = []\n",
    "        for jd_doc in jd_docs:\n",
    "            for field in [\n",
    "                \"job_title\",\"required_skills\",\"preferred_skills\",\"required_qualifications\",\n",
    "                \"education_requirements\",\"experience_requirements\",\"technical_skills\",\"soft_skills\",\n",
    "                \"certifications\",\"responsibilities\",\"description\",\"full_text\"\n",
    "            ]:\n",
    "                val = jd_doc.get(field)\n",
    "                if isinstance(val, list):\n",
    "                    jd_parts.append(\" | \".join(str(x) for x in val))\n",
    "                elif isinstance(val, dict):\n",
    "                    jd_parts.append(\" | \".join(f\"{k}: {v}\" for k, v in val.items()))\n",
    "                elif isinstance(val, str) and val.strip():\n",
    "                    jd_parts.append(val.strip())\n",
    "        jd_text = \"\\n\".join(p for p in jd_parts if p)\n",
    "        if not jd_text:\n",
    "            logger.warning(\"Constructed JD text empty; skipping rerank\")\n",
    "            return cv_results\n",
    "\n",
    "        # Collect CV texts\n",
    "        cv_texts: List[str] = []\n",
    "        valid_results: List[Dict] = []\n",
    "        for result in cv_results:\n",
    "            cv_id = result.get(\"cv_id\")\n",
    "            if not cv_id:\n",
    "                continue\n",
    "            try:\n",
    "                cv_doc = dyn_cv_coll.find_one({\"_id\": cv_id}) or dyn_cv_coll.find_one({\"cv_id\": cv_id})\n",
    "                if not cv_doc:\n",
    "                    # Legacy static fallback for CV doc\n",
    "                    cv_doc = self.cv_collection.find_one({\"_id\": cv_id}) or self.cv_collection.find_one({\"cv_id\": cv_id})\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"CV fetch failed for {cv_id}: {e}\")\n",
    "                cv_doc = None\n",
    "            if not cv_doc:\n",
    "                result[\"cross_encoder_score\"] = float('-inf')\n",
    "                continue\n",
    "            cv_text = cv_doc.get(\"full_text\") or \"\"\n",
    "            if not cv_text:\n",
    "                cv_parts = []\n",
    "                for field in [\"summary\",\"work_experience\",\"education\",\"skills\",\"projects\",\"certifications\"]:\n",
    "                    v = cv_doc.get(field)\n",
    "                    if isinstance(v, list):\n",
    "                        cv_parts.append(\" | \".join(str(x) for x in v))\n",
    "                    elif isinstance(v, dict):\n",
    "                        cv_parts.append(\" | \".join(f\"{k}: {val}\" for k,val in v.items()))\n",
    "                    elif isinstance(v, str) and v.strip():\n",
    "                        cv_parts.append(v.strip())\n",
    "                cv_text = \"\\n\".join(cv_parts)\n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "            else:\n",
    "                result[\"cross_encoder_score\"] = float('-inf')\n",
    "\n",
    "        if not cv_texts:\n",
    "            logger.warning(\"No CV texts available for reranking in dynamic context\")\n",
    "            return cv_results\n",
    "\n",
    "        # Build pairs\n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "\n",
    "        # Use sentence-transformers CrossEncoder if available for efficiency\n",
    "        scores: List[float] = []\n",
    "        if _HAS_ST:\n",
    "            try:\n",
    "                st_model = STCrossEncoder(self.model_name, device=self.device)\n",
    "                scores = st_model.predict(pairs).tolist()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Sentence-Transformers CrossEncoder path failed, falling back to raw HF: {e}\")\n",
    "                scores = []\n",
    "        if not scores:\n",
    "            # Fallback to raw transformers model batching\n",
    "            for i in range(0, len(pairs), batch_size):\n",
    "                batch_pairs = pairs[i:i+batch_size]\n",
    "                try:\n",
    "                    features = self.tokenizer(\n",
    "                        batch_pairs,\n",
    "                        padding=True,\n",
    "                        truncation=True,\n",
    "                        max_length=512,\n",
    "                        return_tensors=\"pt\"\n",
    "                    ).to(self.device)\n",
    "                    with torch.no_grad():\n",
    "                        batch_scores = self.cross_encoder(**features).logits[:,0]\n",
    "                    scores.extend(batch_scores.cpu().tolist())\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Cross-encoder batch failed: {e}\")\n",
    "                    scores.extend([float('-inf')] * len(batch_pairs))\n",
    "\n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = score\n",
    "        cv_results.sort(key=lambda x: x.get(\"cross_encoder_score\", float('-inf')), reverse=True)\n",
    "        logger.info(f\"Reranked {len(cv_results)} CVs (dynamic multi-tenant) company='{company_name}' job_title='{job_title}'\")\n",
    "        return cv_results\n",
    "\n",
    "    def rerank_cvs_with_jd_id(\n",
    "        self,\n",
    "        cv_results: List[Dict],\n",
    "        company_name: str,\n",
    "        job_title: str,\n",
    "        jd_id: str,\n",
    "        batch_size: int = 8\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Rerank CVs for an explicit jd_id within dynamic multi-tenant context.\n",
    "\n",
    "        If the provided jd_id isn't found in the dynamic jd_<job_slug> collection, attempt\n",
    "        fallback to legacy static JD collection. If still missing, skip reranking.\n",
    "        Sanitization: If jd_id doesn't match stored sanitized slug, caller may pass raw title;\n",
    "        we try both the original and a sanitized variant.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            db_name_dyn, cv_coll_dyn_name, jd_coll_dyn_name = build_mongo_names(company_name, job_title)\n",
    "            dyn_db = self.mongo_client[db_name_dyn]\n",
    "            dyn_jd_coll = dyn_db[jd_coll_dyn_name]\n",
    "            dyn_cv_coll = dyn_db[cv_coll_dyn_name]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[rerank_cvs_with_jd_id] dynamic resolution failed: {e}\")\n",
    "            return cv_results\n",
    "\n",
    "        # Attempt fetch by provided jd_id then sanitized fallback\n",
    "        from identifiers import sanitize_fragment  # local import to avoid cycle concerns\n",
    "        jd_doc = dyn_jd_coll.find_one({\"_id\": jd_id}) or \\\n",
    "            dyn_jd_coll.find_one({\"_id\": sanitize_fragment(jd_id)})\n",
    "        if not jd_doc:\n",
    "            jd_doc = self.jd_collection.find_one({\"_id\": jd_id}) or \\\n",
    "                self.jd_collection.find_one({\"_id\": sanitize_fragment(jd_id)})\n",
    "        # As a final fallback, attempt lookup by sanitized company/job fields if _id path failed\n",
    "        if not jd_doc:\n",
    "            jd_doc = dyn_jd_coll.find_one({\n",
    "                \"company_name_sanitized\": sanitize_fragment(company_name),\n",
    "                \"job_title_sanitized\": sanitize_fragment(job_title)\n",
    "            })\n",
    "        if not jd_doc:\n",
    "            logger.warning(f\"JD id '{jd_id}' not found in dynamic or legacy collections; skipping cross-encoder rerank\")\n",
    "            return cv_results\n",
    "\n",
    "        # Build JD text\n",
    "        jd_parts: List[str] = []\n",
    "        for field in [\n",
    "            \"job_title\",\"required_skills\",\"preferred_skills\",\"required_qualifications\",\n",
    "            \"education_requirements\",\"experience_requirements\",\"technical_skills\",\"soft_skills\",\n",
    "            \"certifications\",\"responsibilities\",\"description\",\"full_text\"\n",
    "        ]:\n",
    "            val = jd_doc.get(field)\n",
    "            if isinstance(val, list):\n",
    "                jd_parts.append(\" | \".join(str(x) for x in val))\n",
    "            elif isinstance(val, dict):\n",
    "                jd_parts.append(\" | \".join(f\"{k}: {v}\" for k, v in val.items()))\n",
    "            elif isinstance(val, str) and val.strip():\n",
    "                jd_parts.append(val.strip())\n",
    "        jd_text = \"\\n\".join(p for p in jd_parts if p)\n",
    "        if not jd_text:\n",
    "            logger.warning(f\"JD id '{jd_id}' produced empty text; skipping rerank\")\n",
    "            return cv_results\n",
    "\n",
    "        cv_texts: List[str] = []\n",
    "        valid_results: List[Dict] = []\n",
    "        for result in cv_results:\n",
    "            cv_id = result.get(\"cv_id\")\n",
    "            if not cv_id:\n",
    "                continue\n",
    "            try:\n",
    "                cv_doc = dyn_cv_coll.find_one({\"_id\": cv_id}) or dyn_cv_coll.find_one({\"cv_id\": cv_id})\n",
    "                if not cv_doc:\n",
    "                    cv_doc = self.cv_collection.find_one({\"_id\": cv_id}) or self.cv_collection.find_one({\"cv_id\": cv_id})\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"CV fetch failed for {cv_id}: {e}\")\n",
    "                cv_doc = None\n",
    "            if not cv_doc:\n",
    "                result[\"cross_encoder_score\"] = float('-inf')\n",
    "                continue\n",
    "            cv_text = cv_doc.get(\"full_text\") or \"\"\n",
    "            if not cv_text:\n",
    "                cv_parts = []\n",
    "                for field in [\"summary\",\"work_experience\",\"education\",\"skills\",\"projects\",\"certifications\"]:\n",
    "                    v = cv_doc.get(field)\n",
    "                    if isinstance(v, list):\n",
    "                        cv_parts.append(\" | \".join(str(x) for x in v))\n",
    "                    elif isinstance(v, dict):\n",
    "                        cv_parts.append(\" | \".join(f\"{k}: {val}\" for k,val in v.items()))\n",
    "                    elif isinstance(v, str) and v.strip():\n",
    "                        cv_parts.append(v.strip())\n",
    "                cv_text = \"\\n\".join(cv_parts)\n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "            else:\n",
    "                result[\"cross_encoder_score\"] = float('-inf')\n",
    "\n",
    "        if not cv_texts:\n",
    "            logger.warning(\"No CV texts available for reranking with explicit jd_id\")\n",
    "            return cv_results\n",
    "\n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "        scores: List[float] = []\n",
    "        if _HAS_ST:\n",
    "            try:\n",
    "                st_model = STCrossEncoder(self.model_name, device=self.device)\n",
    "                scores = st_model.predict(pairs).tolist()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Sentence-Transformers path failed (jd_id={jd_id}); fallback HF: {e}\")\n",
    "                scores = []\n",
    "        if not scores:\n",
    "            for i in range(0, len(pairs), batch_size):\n",
    "                batch_pairs = pairs[i:i+batch_size]\n",
    "                try:\n",
    "                    features = self.tokenizer(\n",
    "                        batch_pairs,\n",
    "                        padding=True,\n",
    "                        truncation=True,\n",
    "                        max_length=512,\n",
    "                        return_tensors=\"pt\"\n",
    "                    ).to(self.device)\n",
    "                    with torch.no_grad():\n",
    "                        batch_scores = self.cross_encoder(**features).logits[:,0]\n",
    "                    scores.extend(batch_scores.cpu().tolist())\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Cross-encoder batch failed (jd_id={jd_id}): {e}\")\n",
    "                    scores.extend([float('-inf')] * len(batch_pairs))\n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = score\n",
    "        cv_results.sort(key=lambda x: x.get(\"cross_encoder_score\", float('-inf')), reverse=True)\n",
    "        logger.info(f\"Reranked {len(cv_results)} CVs using explicit jd_id='{jd_id}' company='{company_name}' job_title='{job_title}'\")\n",
    "        return cv_results\n",
    "\n",
    "    def print_results(self, results: List[Dict], show_details: bool = False):\n",
    "        \"\"\"Print reranked CVs with scores and optional details.\"\"\"\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"\\n--- CV {i+1} (ID: {result['cv_id']}, Email: {result.get('email', 'N/A')}) ---\")\n",
    "            print(f\"Vector Search Score: {result['total_score']:.4f}\")\n",
    "            if \"cross_encoder_score\" in result:\n",
    "                print(f\"Cross-Encoder Score: {result['cross_encoder_score']:.4f}\")\n",
    "            if show_details and result.get(\"section_scores\"):\n",
    "                print(\"Section Scores:\")\n",
    "                for section, score in result[\"section_scores\"].items():\n",
    "                    print(f\"  {section}: {score:.4f}\")\n",
    "            if show_details and result.get(\"section_details\"):\n",
    "                print(\"Section Details:\")\n",
    "                for section, matches in result[\"section_details\"].items():\n",
    "                    print(f\"  {section}:\")\n",
    "                    for match in matches:\n",
    "                        similarity = match.get(\"similarity\")\n",
    "                        cv_section = match.get(\"cv_section\")\n",
    "                        print(f\"    CV Section: {cv_section} | Similarity: {similarity:.4f}\")\n",
    "            print()\n",
    "\n",
    "    def close(self) -> None:\n",
    "        \"\"\"Close MongoDB client connection.\"\"\"\n",
    "        if self.mongo_client:\n",
    "            try:\n",
    "                self.mongo_client.close()\n",
    "                logger.info(\"Closed MongoDB client connection\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error closing MongoDB client: {e}\")\n",
    "\n",
    "    def __enter__(self) -> \"CVJDReranker\":\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb) -> None:\n",
    "        self.close()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample input from CVJDVectorSearch.search_and_score_cvs\n",
    "    sample_cv_results = [\n",
    "        {\n",
    "            \"cv_id\": \"cv_123\",\n",
    "            \"email\": \"candidate1@example.com\",\n",
    "            \"total_score\": 0.85,\n",
    "            \"section_scores\": {\"job_title\": 0.9, \"required_skills\": 0.88},\n",
    "            \"section_details\": {\"job_title\": [{\"cv_section\": \"summary\", \"similarity\": 0.9}]}\n",
    "        },\n",
    "        {\n",
    "            \"cv_id\": \"cv_456\",\n",
    "            \"email\": \"candidate2@example.com\",\n",
    "            \"total_score\": 0.82,\n",
    "            \"section_scores\": {\"job_title\": 0.87, \"required_skills\": 0.85},\n",
    "            \"section_details\": {\"job_title\": [{\"cv_section\": \"summary\", \"similarity\": 0.87}]}\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Initialize reranker\n",
    "    reranker = CVJDReranker(\n",
    "        mongo_uri=\"mongodb://localhost:27017/\",\n",
    "        mongo_db=\"cv_db\",\n",
    "        cv_collection=\"cvs\",\n",
    "        jd_collection=\"job_descriptions\"\n",
    "    )\n",
    "    \n",
    "    # Rerank with a specific jd_id\n",
    "    jd_id = \"f7ffdd206e7ee16b70acb2f0f00fbfd5d4f000766c9d02d286ca9e8dfa0f0486\"\n",
    "    reranked_results = reranker.rerank_cvs(sample_cv_results, jd_id=jd_id)\n",
    "    \n",
    "    # Print results\n",
    "    reranker.print_results(reranked_results, show_details=True)\n",
    "    \n",
    "    # Clean up\n",
    "    reranker.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c0fcd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ YOUR MONGODB CV SCHEMA TEST\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 11:35:42,400 - INFO - âœ… Initialized on cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb5189ca6bf4e3998816ce6a33d0411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JD TEXT USED:\n",
      "--------------------------------------------------\n",
      "Data Analyst - TechFlow Solutions\n",
      "SQL | Python | Excel | Data Visualization | Statistical Analysis\n",
      "Bachelor's degree\n",
      "minimum_years: 2\n",
      "SQL | Python (pandas) | Excel Advanced\n",
      "Analytical Thinking | Commu...\n",
      "\n",
      "CV TEXT USED (Aidoo):\n",
      "--------------------------------------------------\n",
      "A Data Analyst with about two years of professional experience specializing in SQL, Python, and business intelligence.\n",
      "1.92 years experience\n",
      "Data Analyst at Ebits (2023-Present): Built 10+ Tableau das...\n",
      "\n",
      "================================================================================\n",
      "ðŸŽ¯ YOUR MONGODB SCHEMA RESULTS\n",
      "================================================================================\n",
      " 1. aidooenochkwadwo@gmail.com     | CE:  0.828\n",
      " 2. bob.smith@business.com         | CE:  0.004\n",
      "================================================================================\n",
      "\n",
      "âœ… USED 9 CV FIELDS:\n",
      "  â€¢ summary\n",
      "  â€¢ years_of_experience\n",
      "  â€¢ work_experience\n",
      "  â€¢ education\n",
      "  â€¢ skills\n",
      "  â€¢ soft_skills\n",
      "  â€¢ certifications\n",
      "  â€¢ projects\n",
      "  â€¢ job_title\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import List, Dict, Any\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "try:\n",
    "    from sentence_transformers import CrossEncoder as STCrossEncoder\n",
    "    _HAS_ST = True\n",
    "except Exception:\n",
    "    _HAS_ST = False\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# âœ… YOUR EXACT JD FIELDS\n",
    "JD_FIELDS = [\n",
    "    \"job_title\", \"required_skills\", \"required_qualifications\", \"preferred_skills\",\n",
    "    \"education_requirements\", \"experience_requirements\", \"technical_skills\",\n",
    "    \"soft_skills\", \"certifications\", \"responsibilities\"\n",
    "]\n",
    "\n",
    "# âœ… YOUR EXACT CV FIELDS - SELECTED 9 MOST RELEVANT\n",
    "CV_FIELDS = [\n",
    "    \"summary\", \"years_of_experience\", \"work_experience\", \"education\",\n",
    "    \"skills\", \"soft_skills\", \"certifications\", \"projects\", \"job_title\"\n",
    "]\n",
    "\n",
    "class CVJDReranker:\n",
    "    def __init__(self, model_name: str = \"BAAI/bge-reranker-base\"):\n",
    "        self.model_name = model_name\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.use_st = False\n",
    "        \n",
    "        if _HAS_ST:\n",
    "            self.cross_encoder = STCrossEncoder(model_name, device=self.device)\n",
    "            self.use_st = True\n",
    "            self.tokenizer = self.cross_encoder.tokenizer\n",
    "        else:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            self.cross_encoder = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "            self.cross_encoder.to(self.device)\n",
    "        logger.info(f\"âœ… Initialized on {self.device}\")\n",
    "\n",
    "    def _build_text_from_doc(self, doc: Dict[str, Any], fields: List[str]) -> str:\n",
    "        \"\"\"Build text using YOUR exact schema.\"\"\"\n",
    "        parts: List[str] = []\n",
    "        \n",
    "        for field in fields:\n",
    "            val = doc.get(field)\n",
    "            if val is None or val == \"\":\n",
    "                continue\n",
    "                \n",
    "            if field == \"years_of_experience\":\n",
    "                # âœ… Special handling: 1.92 â†’ \"1.92 years experience\"\n",
    "                parts.append(f\"{val} years experience\")\n",
    "            elif isinstance(val, list):\n",
    "                # âœ… Arrays: [\"SQL\", \"Python\"] â†’ \"SQL | Python\"\n",
    "                parts.append(\" | \".join(str(x) for x in val))\n",
    "            elif isinstance(val, dict):\n",
    "                # âœ… Objects: {\"years\": \"2\"} â†’ \"years: 2\"\n",
    "                parts.append(\" | \".join(f\"{k}: {v}\" for k, v in val.items()))\n",
    "            elif isinstance(val, (int, float)) and field != \"years_of_experience\":\n",
    "                parts.append(str(val))\n",
    "            elif isinstance(val, str) and val.strip():\n",
    "                # âœ… Strings\n",
    "                parts.append(val.strip())\n",
    "        \n",
    "        return \"\\n\".join(p for p in parts if p)\n",
    "\n",
    "    def _score_pairs(self, pairs: List[List[str]], batch_size: int = 8) -> List[float]:\n",
    "        max_length = getattr(self.tokenizer, 'model_max_length', 512)\n",
    "        scores: List[float] = []\n",
    "        \n",
    "        if self.use_st:\n",
    "            scores = self.cross_encoder.predict(pairs).tolist()\n",
    "        else:\n",
    "            for i in range(0, len(pairs), batch_size):\n",
    "                batch_pairs = pairs[i:i + batch_size]\n",
    "                features = self.tokenizer(\n",
    "                    batch_pairs, padding=True, truncation=True, \n",
    "                    max_length=max_length, return_tensors=\"pt\"\n",
    "                ).to(self.device)\n",
    "                with torch.no_grad():\n",
    "                    logits = self.cross_encoder(**features).logits\n",
    "                    # Apply sigmoid if model outputs raw logits\n",
    "                    if logits.ndim == 2 and logits.shape[1] == 1:\n",
    "                        batch_scores = torch.sigmoid(logits.squeeze(1))\n",
    "                    else:\n",
    "                        batch_scores = torch.sigmoid(logits)\n",
    "                # Ensure iterable\n",
    "                if isinstance(batch_scores, torch.Tensor):\n",
    "                    batch_scores = batch_scores.cpu().tolist()\n",
    "                scores.extend(batch_scores)\n",
    "        return scores\n",
    "\n",
    "    def rerank_cvs_direct(self, cv_results: List[Dict], jd_doc: Dict[str, Any]) -> List[Dict]:\n",
    "        \"\"\"Rerank using in-memory CV dicts and a single JD doc. Removes dependency on 'cv_text' key.\"\"\"\n",
    "        # Build JD text using YOUR JD fields\n",
    "        jd_text = self._build_text_from_doc(jd_doc, JD_FIELDS)\n",
    "        if not jd_text:\n",
    "            logger.warning(\"JD text empty; skipping rerank\")\n",
    "            for r in cv_results:\n",
    "                r.setdefault(\"cross_encoder_score\", 0.0)\n",
    "            return cv_results\n",
    "\n",
    "        # Build CV texts using YOUR CV fields\n",
    "        cv_texts, valid_results = [], []\n",
    "        for result in cv_results:\n",
    "            cv_text = self._build_text_from_doc(result, CV_FIELDS)\n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "            else:\n",
    "                # No usable text; assign minimal score\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "\n",
    "        if not cv_texts:\n",
    "            logger.warning(\"No CV texts built; returning original order\")\n",
    "            return cv_results\n",
    "\n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "        scores = self._score_pairs(pairs)\n",
    "\n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = float(score)\n",
    "\n",
    "        return sorted(cv_results, key=lambda x: x.get(\"cross_encoder_score\", 0), reverse=True)\n",
    "\n",
    "    def format_results(self, results: List[Dict]) -> str:\n",
    "        lines = [f\"{'='*80}\", f\"ðŸŽ¯ YOUR MONGODB SCHEMA RESULTS\", f\"{'='*80}\"]\n",
    "        for i, result in enumerate(results, 1):\n",
    "            ce = result.get('cross_encoder_score', 0.0)\n",
    "            lines.append(\n",
    "                f\"{i:2d}. {result.get('email','(no email)'):30s} | CE: {ce:6.3f}\"\n",
    "            )\n",
    "        lines.append(f\"{'='*80}\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "# ===============================================\n",
    "# YOUR EXACT MONGODB DATA\n",
    "# ===============================================\n",
    "\n",
    "YOUR_JD = {\n",
    "    \"job_title\": \"Data Analyst - TechFlow Solutions\",\n",
    "    \"required_skills\": [\"SQL\", \"Python\", \"Excel\", \"Data Visualization\", \"Statistical Analysis\"],\n",
    "    \"technical_skills\": [\"SQL\", \"Python (pandas)\", \"Excel Advanced\"],\n",
    "    \"soft_skills\": [\"Analytical Thinking\", \"Communication\"],\n",
    "    \"education_requirements\": [\"Bachelor's degree\"],\n",
    "    \"experience_requirements\": {\"minimum_years\": \"2\"},\n",
    "    \"responsibilities\": [\n",
    "        \"Extract and analyze data using SQL and Python\",\n",
    "        \"Create interactive dashboards\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# âœ… YOUR REAL CV DATA\n",
    "YOUR_CVS = [\n",
    "    {\n",
    "        \"cv_id\": \"2e538000bef0ba2c6bfd10f0fb99b0d97843da9e35f46b255c59141bc3660484\",\n",
    "        \"email\": \"aidooenochkwadwo@gmail.com\",\n",
    "        \"total_score\": 0.88,\n",
    "        \"job_title\": \"Data Analyst\",\n",
    "        \"summary\": \"A Data Analyst with about two years of professional experience specializing in SQL, Python, and business intelligence.\",\n",
    "        \"years_of_experience\": 1.92,\n",
    "        \"skills\": [\"SQL\", \"Python\", \"Excel\", \"Tableau\", \"Power BI\", \"Pandas\", \"Data Cleaning\", \"Statistical Analysis\"],\n",
    "        \"soft_skills\": [\"Analytical Thinking\", \"Problem Solving\", \"Communication\", \"Attention to Detail\"],\n",
    "        \"work_experience\": [\n",
    "            \"Data Analyst at Ebits (2023-Present): Built 10+ Tableau dashboards, optimized SQL queries by 50%\"\n",
    "        ],\n",
    "        \"education\": [\"BSc. Information Technology - Kwame Nkrumah University of Science and Technology\"],\n",
    "        \"certifications\": [\"Google Data Analytics Certificate\", \"Microsoft Power BI Desktop\"],\n",
    "        \"projects\": [\"Customer Analytics Dashboard\", \"Sales Performance Tracker\"]\n",
    "    },\n",
    "    {\n",
    "        \"cv_id\": \"cv_bob_002\",\n",
    "        \"email\": \"bob.smith@business.com\", \n",
    "        \"total_score\": 0.75,\n",
    "        \"job_title\": \"Business Analyst\",\n",
    "        \"summary\": \"Business Analyst with Excel and reporting experience.\",\n",
    "        \"years_of_experience\": 1.5,\n",
    "        \"skills\": [\"Excel\", \"PowerPoint\", \"Basic SQL\"],\n",
    "        \"soft_skills\": [\"Communication\"],\n",
    "        \"work_experience\": [\"Business Analyst at DataCorp\"],\n",
    "        \"education\": [\"BS Business Administration\"],\n",
    "        \"certifications\": [],\n",
    "        \"projects\": []\n",
    "    }\n",
    "]\n",
    "\n",
    "# ===============================================\n",
    "# RUN TEST\n",
    "# ===============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸš€ YOUR MONGODB CV SCHEMA TEST\\n\")\n",
    "    \n",
    "    reranker = CVJDReranker()\n",
    "    results = reranker.rerank_cvs_direct(YOUR_CVS, YOUR_JD)\n",
    "    \n",
    "    print(\"JD TEXT USED:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(reranker._build_text_from_doc(YOUR_JD, JD_FIELDS)[:200] + \"...\")\n",
    "    \n",
    "    print(\"\\nCV TEXT USED (Aidoo):\")\n",
    "    print(\"-\" * 50)\n",
    "    print(reranker._build_text_from_doc(YOUR_CVS[0], CV_FIELDS)[:200] + \"...\")\n",
    "    \n",
    "    print(\"\\n\" + reranker.format_results(results))\n",
    "    \n",
    "    print(f\"\\nâœ… USED {len(CV_FIELDS)} CV FIELDS:\")\n",
    "    for field in CV_FIELDS:\n",
    "        print(f\"  â€¢ {field}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c485ce0b",
   "metadata": {},
   "source": [
    "### COMBINATION OF THE TWO CODES ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ca8734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Enoch\\.conda\\envs\\my_env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 12:30:25,126 - INFO - âœ… MongoDB client initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXAMPLE 1: In-Memory Reranking (No MongoDB)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 12:30:34,479 - INFO - âœ… Using sentence-transformers CrossEncoder on cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e4b9d3554e4de098de7dbb21383334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 12:30:35,800 - INFO - âœ… Closed MongoDB client connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸŽ¯ RERANKED CV RESULTS\n",
      "================================================================================\n",
      " 1. candidate1@example.com                   | CE:  0.941 | VS:  0.850\n",
      " 2. candidate2@example.com                   | CE:  0.002 | VS:  0.820\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 2: Production Usage with MongoDB\n",
      "================================================================================\n",
      "\n",
      "    # Initialize with MongoDB connection\n",
      "    reranker = CVJDReranker(\n",
      "        mongo_uri=\"mongodb://localhost:27017/\",\n",
      "        mongo_db=\"cv_db\",\n",
      "        cv_collection=\"cvs\",\n",
      "        jd_collection=\"job_descriptions\"\n",
      "    )\n",
      "    \n",
      "    # Method 1: Rerank for company/job (multi-tenant)\n",
      "    results = reranker.rerank_cvs_for_job(\n",
      "        cv_results=cv_search_results,\n",
      "        company_name=\"TechCorp\",\n",
      "        job_title=\"Senior Data Analyst\"\n",
      "    )\n",
      "    \n",
      "    # Method 2: Rerank with specific JD ID\n",
      "    results = reranker.rerank_cvs_with_jd_id(\n",
      "        cv_results=cv_search_results,\n",
      "        company_name=\"TechCorp\",\n",
      "        job_title=\"Senior Data Analyst\",\n",
      "        jd_id=\"jd_12345\"\n",
      "    )\n",
      "    \n",
      "    # Method 3: In-memory reranking (when docs already loaded)\n",
      "    results = reranker.rerank_cvs_direct(\n",
      "        cv_results=cv_dicts,\n",
      "        jd_doc=jd_dict\n",
      "    )\n",
      "    \n",
      "    # Display results\n",
      "    print(reranker.format_results(results))\n",
      "    reranker.close()\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import List, Dict, Any, Optional\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pymongo\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import CrossEncoder as STCrossEncoder\n",
    "    _HAS_ST = True\n",
    "except Exception:\n",
    "    _HAS_ST = False\n",
    "\n",
    "from identifiers import build_mongo_names, sanitize_fragment\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# âœ… UNIFIED FIELD DEFINITIONS\n",
    "JD_FIELDS = [\n",
    "    \"job_title\", \"required_skills\", \"required_qualifications\", \"preferred_skills\",\n",
    "    \"education_requirements\", \"experience_requirements\", \"technical_skills\",\n",
    "    \"soft_skills\", \"certifications\", \"responsibilities\", \"description\", \"full_text\"\n",
    "]\n",
    "\n",
    "CV_FIELDS = [\n",
    "    \"summary\", \"years_of_experience\", \"work_experience\", \"education\",\n",
    "    \"skills\", \"soft_skills\", \"certifications\", \"projects\", \"job_title\",\n",
    "    \"languages\", \"awards\", \"publications\"  # Extended fields\n",
    "]\n",
    "\n",
    "\n",
    "class CVJDReranker:\n",
    "    \"\"\"Reranks CVs against job descriptions using cross-encoder models.\n",
    "    \n",
    "    Combines production-ready MongoDB integration with clean text construction logic.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        mongo_uri: str,\n",
    "        mongo_db: str = \"cv_db\",\n",
    "        cv_collection: str = \"cvs\",\n",
    "        jd_collection: str = \"job_descriptions\",\n",
    "        model_name: str = \"BAAI/bge-reranker-base\"\n",
    "    ):\n",
    "        \"\"\"Initialize MongoDB client and cross-encoder model.\"\"\"\n",
    "        # Initialize MongoDB\n",
    "        try:\n",
    "            self.mongo_client = pymongo.MongoClient(mongo_uri)\n",
    "            self.cv_db = self.mongo_client[mongo_db]\n",
    "            self.cv_collection = self.cv_db[cv_collection]\n",
    "            self.jd_collection = self.cv_db[jd_collection]\n",
    "            logger.info(\"âœ… MongoDB client initialized\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize MongoDB client: {e}\")\n",
    "            raise ValueError(\"MongoDB connection failed. Provide a valid mongo_uri.\")\n",
    "        \n",
    "        # Initialize cross-encoder with optimal path detection\n",
    "        try:\n",
    "            self.model_name = model_name\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.use_st = False\n",
    "            \n",
    "            if _HAS_ST:\n",
    "                self.cross_encoder = STCrossEncoder(model_name, device=self.device)\n",
    "                self.use_st = True\n",
    "                self.tokenizer = self.cross_encoder.tokenizer\n",
    "                logger.info(f\"âœ… Using sentence-transformers CrossEncoder on {self.device}\")\n",
    "            else:\n",
    "                self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "                self.cross_encoder = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "                self.cross_encoder.to(self.device)\n",
    "                logger.info(f\"âœ… Using transformers model on {self.device}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize cross-encoder: {e}\")\n",
    "            raise RuntimeError(f\"Failed to load model {model_name}\")\n",
    "\n",
    "    # ========================================\n",
    "    # CORE TEXT CONSTRUCTION (UNIFIED)\n",
    "    # ========================================\n",
    "    \n",
    "    def _build_text_from_doc(self, doc: Dict[str, Any], fields: List[str]) -> str:\n",
    "        \"\"\"Build structured text from document using specified fields.\n",
    "        \n",
    "        Handles different data types intelligently:\n",
    "        - years_of_experience: Formatted as readable text\n",
    "        - Lists: Joined with separator\n",
    "        - Dicts: Key-value pairs\n",
    "        - Strings: Cleaned and stripped\n",
    "        \"\"\"\n",
    "        parts: List[str] = []\n",
    "        \n",
    "        for field in fields:\n",
    "            val = doc.get(field)\n",
    "            if val is None or val == \"\":\n",
    "                continue\n",
    "            \n",
    "            # Special handling for experience\n",
    "            if field == \"years_of_experience\":\n",
    "                parts.append(f\"{val} years experience\")\n",
    "            # Lists: [\"SQL\", \"Python\"] â†’ \"SQL | Python\"\n",
    "            elif isinstance(val, list):\n",
    "                list_str = \" | \".join(str(x) for x in val if x)\n",
    "                if list_str:\n",
    "                    parts.append(list_str)\n",
    "            # Dicts: {\"minimum_years\": \"2\"} â†’ \"minimum_years: 2\"\n",
    "            elif isinstance(val, dict):\n",
    "                dict_str = \" | \".join(f\"{k}: {v}\" for k, v in val.items() if v)\n",
    "                if dict_str:\n",
    "                    parts.append(dict_str)\n",
    "            # Numbers (except years_of_experience already handled)\n",
    "            elif isinstance(val, (int, float)) and field != \"years_of_experience\":\n",
    "                parts.append(str(val))\n",
    "            # Strings\n",
    "            elif isinstance(val, str) and val.strip():\n",
    "                parts.append(val.strip())\n",
    "        \n",
    "        return \"\\n\".join(p for p in parts if p)\n",
    "\n",
    "    # ========================================\n",
    "    # CORE SCORING (UNIFIED)\n",
    "    # ========================================\n",
    "    \n",
    "    def _score_pairs(self, pairs: List[List[str]], batch_size: int = 8) -> List[float]:\n",
    "        \"\"\"Score CV-JD pairs using cross-encoder with optimal batching.\n",
    "        \n",
    "        Args:\n",
    "            pairs: List of [jd_text, cv_text] pairs\n",
    "            batch_size: Batch size for processing\n",
    "            \n",
    "        Returns:\n",
    "            List of relevance scores (higher = more relevant)\n",
    "        \"\"\"\n",
    "        if not pairs:\n",
    "            return []\n",
    "        \n",
    "        max_length = getattr(self.tokenizer, 'model_max_length', 512)\n",
    "        scores: List[float] = []\n",
    "        \n",
    "        # Optimal path: sentence-transformers CrossEncoder\n",
    "        if self.use_st:\n",
    "            try:\n",
    "                scores = self.cross_encoder.predict(pairs).tolist()\n",
    "                return scores\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Sentence-transformers path failed, falling back to raw transformers: {e}\")\n",
    "                self.use_st = False  # Disable for future calls\n",
    "        \n",
    "        # Fallback: Raw transformers with batching\n",
    "        for i in range(0, len(pairs), batch_size):\n",
    "            batch_pairs = pairs[i:i + batch_size]\n",
    "            try:\n",
    "                features = self.tokenizer(\n",
    "                    batch_pairs,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=max_length,\n",
    "                    return_tensors=\"pt\"\n",
    "                ).to(self.device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    logits = self.cross_encoder(**features).logits\n",
    "                    \n",
    "                    # Apply sigmoid normalization for better score distribution\n",
    "                    if logits.ndim == 2 and logits.shape[1] == 1:\n",
    "                        batch_scores = torch.sigmoid(logits.squeeze(1))\n",
    "                    else:\n",
    "                        batch_scores = torch.sigmoid(logits[:, 0])\n",
    "                    \n",
    "                    scores.extend(batch_scores.cpu().tolist())\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Scoring batch {i//batch_size + 1} failed: {e}\")\n",
    "                scores.extend([float('-inf')] * len(batch_pairs))\n",
    "        \n",
    "        return scores\n",
    "\n",
    "    # ========================================\n",
    "    # DOCUMENT FETCHING (IMPROVED)\n",
    "    # ========================================\n",
    "    \n",
    "    def _fetch_jd_doc(\n",
    "        self,\n",
    "        company_name: str,\n",
    "        job_title: str,\n",
    "        jd_id: Optional[str] = None\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Fetch JD document with comprehensive fallback logic.\n",
    "        \n",
    "        Priority:\n",
    "        1. Dynamic collection (company-specific)\n",
    "        2. Static collection with exact match\n",
    "        3. Sanitized field match\n",
    "        4. Case-insensitive regex match\n",
    "        \"\"\"\n",
    "        # Try dynamic collection first\n",
    "        try:\n",
    "            db_name_dyn, _, jd_coll_dyn_name = build_mongo_names(company_name, job_title)\n",
    "            dyn_db = self.mongo_client[db_name_dyn]\n",
    "            dyn_jd_coll = dyn_db[jd_coll_dyn_name]\n",
    "            \n",
    "            # If jd_id provided, try exact match first\n",
    "            if jd_id:\n",
    "                jd_doc = dyn_jd_coll.find_one({\"_id\": jd_id})\n",
    "                if jd_doc:\n",
    "                    return jd_doc\n",
    "                # Try sanitized jd_id\n",
    "                jd_doc = dyn_jd_coll.find_one({\"_id\": sanitize_fragment(jd_id)})\n",
    "                if jd_doc:\n",
    "                    return jd_doc\n",
    "            \n",
    "            # Load all docs from job-specific collection (simplified approach)\n",
    "            jd_docs = list(dyn_jd_coll.find({}))\n",
    "            if jd_docs:\n",
    "                # Return first doc (or could aggregate multiple)\n",
    "                return jd_docs[0]\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Dynamic JD fetch failed: {e}\")\n",
    "        \n",
    "        # Fallback to static collection\n",
    "        try:\n",
    "            # Exact match\n",
    "            jd_doc = self.jd_collection.find_one({\n",
    "                \"company_name\": company_name,\n",
    "                \"job_title\": job_title\n",
    "            })\n",
    "            if jd_doc:\n",
    "                return jd_doc\n",
    "            \n",
    "            # Sanitized match\n",
    "            jd_doc = self.jd_collection.find_one({\n",
    "                \"company_name_sanitized\": sanitize_fragment(company_name),\n",
    "                \"job_title_sanitized\": sanitize_fragment(job_title)\n",
    "            })\n",
    "            if jd_doc:\n",
    "                return jd_doc\n",
    "            \n",
    "            # Case-insensitive regex\n",
    "            jd_doc = self.jd_collection.find_one({\n",
    "                \"company_name\": {\"$regex\": f\"^{company_name}$\", \"$options\": \"i\"},\n",
    "                \"job_title\": {\"$regex\": f\"^{job_title}$\", \"$options\": \"i\"}\n",
    "            })\n",
    "            return jd_doc\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Static JD fallback failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _fetch_cv_doc(\n",
    "        self,\n",
    "        cv_id: str,\n",
    "        company_name: Optional[str] = None,\n",
    "        job_title: Optional[str] = None\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Fetch CV document from dynamic or static collection.\"\"\"\n",
    "        # Try dynamic collection if context provided\n",
    "        if company_name and job_title:\n",
    "            try:\n",
    "                db_name_dyn, cv_coll_dyn_name, _ = build_mongo_names(company_name, job_title)\n",
    "                dyn_db = self.mongo_client[db_name_dyn]\n",
    "                dyn_cv_coll = dyn_db[cv_coll_dyn_name]\n",
    "                \n",
    "                cv_doc = dyn_cv_coll.find_one({\"_id\": cv_id})\n",
    "                if cv_doc:\n",
    "                    return cv_doc\n",
    "                cv_doc = dyn_cv_coll.find_one({\"cv_id\": cv_id})\n",
    "                if cv_doc:\n",
    "                    return cv_doc\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Dynamic CV fetch failed for {cv_id}: {e}\")\n",
    "        \n",
    "        # Fallback to static collection\n",
    "        try:\n",
    "            cv_doc = self.cv_collection.find_one({\"_id\": cv_id})\n",
    "            if cv_doc:\n",
    "                return cv_doc\n",
    "            return self.cv_collection.find_one({\"cv_id\": cv_id})\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Static CV fallback failed for {cv_id}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # ========================================\n",
    "    # RERANKING METHODS (UNIFIED)\n",
    "    # ========================================\n",
    "    \n",
    "    def rerank_cvs_direct(\n",
    "        self,\n",
    "        cv_results: List[Dict],\n",
    "        jd_doc: Dict[str, Any],\n",
    "        batch_size: int = 8\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Rerank using in-memory CV dicts and JD doc (no MongoDB queries).\n",
    "        \n",
    "        Useful for testing or when documents are already loaded.\n",
    "        \"\"\"\n",
    "        # Build JD text\n",
    "        jd_text = self._build_text_from_doc(jd_doc, JD_FIELDS)\n",
    "        if not jd_text:\n",
    "            logger.warning(\"JD text empty; skipping rerank\")\n",
    "            for r in cv_results:\n",
    "                r.setdefault(\"cross_encoder_score\", 0.0)\n",
    "            return cv_results\n",
    "\n",
    "        # Build CV texts\n",
    "        cv_texts, valid_results = [], []\n",
    "        for result in cv_results:\n",
    "            cv_text = self._build_text_from_doc(result, CV_FIELDS)\n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "            else:\n",
    "                result[\"cross_encoder_score\"] = float('-inf')\n",
    "\n",
    "        if not cv_texts:\n",
    "            logger.warning(\"No CV texts built; returning original order\")\n",
    "            return cv_results\n",
    "\n",
    "        # Score pairs\n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "        scores = self._score_pairs(pairs, batch_size)\n",
    "\n",
    "        # Assign scores\n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = float(score)\n",
    "\n",
    "        # Sort by cross-encoder score\n",
    "        return sorted(\n",
    "            cv_results,\n",
    "            key=lambda x: x.get(\"cross_encoder_score\", float('-inf')),\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "    def rerank_cvs_for_job(\n",
    "        self,\n",
    "        cv_results: List[Dict],\n",
    "        company_name: str,\n",
    "        job_title: str,\n",
    "        batch_size: int = 8\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Rerank CVs for a specific company/job using dynamic multi-tenant collections.\n",
    "        \n",
    "        Args:\n",
    "            cv_results: List of CV result dicts with 'cv_id' keys\n",
    "            company_name: Company name for multi-tenant lookup\n",
    "            job_title: Job title for collection resolution\n",
    "            batch_size: Batch size for scoring\n",
    "            \n",
    "        Returns:\n",
    "            Sorted list with 'cross_encoder_score' added to each result\n",
    "        \"\"\"\n",
    "        # Fetch JD document\n",
    "        jd_doc = self._fetch_jd_doc(company_name, job_title)\n",
    "        if not jd_doc:\n",
    "            logger.warning(f\"No JD found for {company_name}/{job_title}; skipping rerank\")\n",
    "            for r in cv_results:\n",
    "                r.setdefault(\"cross_encoder_score\", 0.0)\n",
    "            return cv_results\n",
    "\n",
    "        # Build JD text using unified method\n",
    "        jd_text = self._build_text_from_doc(jd_doc, JD_FIELDS)\n",
    "        if not jd_text:\n",
    "            logger.warning(\"JD text empty after construction; skipping rerank\")\n",
    "            for r in cv_results:\n",
    "                r.setdefault(\"cross_encoder_score\", 0.0)\n",
    "            return cv_results\n",
    "\n",
    "        # Fetch and build CV texts\n",
    "        cv_texts: List[str] = []\n",
    "        valid_results: List[Dict] = []\n",
    "        \n",
    "        for result in cv_results:\n",
    "            cv_id = result.get(\"cv_id\")\n",
    "            if not cv_id:\n",
    "                result[\"cross_encoder_score\"] = float('-inf')\n",
    "                continue\n",
    "            \n",
    "            cv_doc = self._fetch_cv_doc(cv_id, company_name, job_title)\n",
    "            if not cv_doc:\n",
    "                result[\"cross_encoder_score\"] = float('-inf')\n",
    "                continue\n",
    "            \n",
    "            # Use unified text builder\n",
    "            cv_text = self._build_text_from_doc(cv_doc, CV_FIELDS)\n",
    "            \n",
    "            # Fallback to full_text if available\n",
    "            if not cv_text:\n",
    "                cv_text = cv_doc.get(\"full_text\", \"\")\n",
    "            \n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "            else:\n",
    "                result[\"cross_encoder_score\"] = float('-inf')\n",
    "\n",
    "        if not cv_texts:\n",
    "            logger.warning(\"No CV texts available for reranking\")\n",
    "            return cv_results\n",
    "\n",
    "        # Score all pairs\n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "        scores = self._score_pairs(pairs, batch_size)\n",
    "\n",
    "        # Assign scores\n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = float(score)\n",
    "\n",
    "        # Sort by cross-encoder score\n",
    "        cv_results.sort(\n",
    "            key=lambda x: x.get(\"cross_encoder_score\", float('-inf')),\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        logger.info(\n",
    "            f\"âœ… Reranked {len(cv_results)} CVs for \"\n",
    "            f\"company='{company_name}' job='{job_title}'\"\n",
    "        )\n",
    "        return cv_results\n",
    "\n",
    "    def rerank_cvs_with_jd_id(\n",
    "        self,\n",
    "        cv_results: List[Dict],\n",
    "        company_name: str,\n",
    "        job_title: str,\n",
    "        jd_id: str,\n",
    "        batch_size: int = 8\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Rerank CVs using explicit jd_id within multi-tenant context.\n",
    "        \n",
    "        Use this when you have a specific JD identifier to target.\n",
    "        \"\"\"\n",
    "        # Fetch specific JD by ID\n",
    "        jd_doc = self._fetch_jd_doc(company_name, job_title, jd_id)\n",
    "        if not jd_doc:\n",
    "            logger.warning(f\"JD id '{jd_id}' not found; skipping rerank\")\n",
    "            for r in cv_results:\n",
    "                r.setdefault(\"cross_encoder_score\", 0.0)\n",
    "            return cv_results\n",
    "\n",
    "        # Build JD text\n",
    "        jd_text = self._build_text_from_doc(jd_doc, JD_FIELDS)\n",
    "        if not jd_text:\n",
    "            logger.warning(f\"JD id '{jd_id}' produced empty text; skipping rerank\")\n",
    "            for r in cv_results:\n",
    "                r.setdefault(\"cross_encoder_score\", 0.0)\n",
    "            return cv_results\n",
    "\n",
    "        # Fetch and build CV texts\n",
    "        cv_texts: List[str] = []\n",
    "        valid_results: List[Dict] = []\n",
    "        \n",
    "        for result in cv_results:\n",
    "            cv_id = result.get(\"cv_id\")\n",
    "            if not cv_id:\n",
    "                result[\"cross_encoder_score\"] = float('-inf')\n",
    "                continue\n",
    "            \n",
    "            cv_doc = self._fetch_cv_doc(cv_id, company_name, job_title)\n",
    "            if not cv_doc:\n",
    "                result[\"cross_encoder_score\"] = float('-inf')\n",
    "                continue\n",
    "            \n",
    "            cv_text = self._build_text_from_doc(cv_doc, CV_FIELDS)\n",
    "            if not cv_text:\n",
    "                cv_text = cv_doc.get(\"full_text\", \"\")\n",
    "            \n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "            else:\n",
    "                result[\"cross_encoder_score\"] = float('-inf')\n",
    "\n",
    "        if not cv_texts:\n",
    "            logger.warning(\"No CV texts available for reranking with jd_id\")\n",
    "            return cv_results\n",
    "\n",
    "        # Score pairs\n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "        scores = self._score_pairs(pairs, batch_size)\n",
    "\n",
    "        # Assign scores\n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = float(score)\n",
    "\n",
    "        # Sort\n",
    "        cv_results.sort(\n",
    "            key=lambda x: x.get(\"cross_encoder_score\", float('-inf')),\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        logger.info(\n",
    "            f\"âœ… Reranked {len(cv_results)} CVs using jd_id='{jd_id}' \"\n",
    "            f\"company='{company_name}' job='{job_title}'\"\n",
    "        )\n",
    "        return cv_results\n",
    "\n",
    "    # ========================================\n",
    "    # LEGACY COMPATIBILITY (DEPRECATED)\n",
    "    # ========================================\n",
    "    \n",
    "    def rerank_cvs(\n",
    "        self,\n",
    "        cv_results: List[Dict],\n",
    "        jd_id: str,\n",
    "        batch_size: int = 8\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Legacy method for backward compatibility.\n",
    "        \n",
    "        DEPRECATED: Use rerank_cvs_with_jd_id() instead.\n",
    "        \"\"\"\n",
    "        logger.warning(\n",
    "            \"rerank_cvs() is deprecated. \"\n",
    "            \"Use rerank_cvs_with_jd_id() or rerank_cvs_for_job() instead.\"\n",
    "        )\n",
    "        \n",
    "        # Fetch JD from static collection\n",
    "        try:\n",
    "            jd_doc = self.jd_collection.find_one({\"jd_id\": jd_id})\n",
    "            if not jd_doc:\n",
    "                logger.error(f\"No JD found for jd_id {jd_id}\")\n",
    "                return cv_results\n",
    "            \n",
    "            jd_text = self._build_text_from_doc(jd_doc, JD_FIELDS)\n",
    "            if not jd_text:\n",
    "                return cv_results\n",
    "            \n",
    "            cv_texts, valid_results = [], []\n",
    "            for result in cv_results:\n",
    "                cv_id = result.get(\"cv_id\")\n",
    "                if not cv_id:\n",
    "                    continue\n",
    "                \n",
    "                cv_doc = self._fetch_cv_doc(cv_id)\n",
    "                if not cv_doc:\n",
    "                    result[\"cross_encoder_score\"] = float('-inf')\n",
    "                    continue\n",
    "                \n",
    "                cv_text = self._build_text_from_doc(cv_doc, CV_FIELDS)\n",
    "                if not cv_text:\n",
    "                    cv_text = cv_doc.get(\"full_text\", \"\")\n",
    "                \n",
    "                if cv_text:\n",
    "                    cv_texts.append(cv_text)\n",
    "                    valid_results.append(result)\n",
    "                else:\n",
    "                    result[\"cross_encoder_score\"] = float('-inf')\n",
    "            \n",
    "            if not cv_texts:\n",
    "                return cv_results\n",
    "            \n",
    "            pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "            scores = self._score_pairs(pairs, batch_size)\n",
    "            \n",
    "            for result, score in zip(valid_results, scores):\n",
    "                result[\"cross_encoder_score\"] = float(score)\n",
    "            \n",
    "            cv_results.sort(\n",
    "                key=lambda x: x.get(\"cross_encoder_score\", float('-inf')),\n",
    "                reverse=True\n",
    "            )\n",
    "            return cv_results\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Legacy rerank failed: {e}\")\n",
    "            return cv_results\n",
    "\n",
    "    # ========================================\n",
    "    # UTILITIES\n",
    "    # ========================================\n",
    "    \n",
    "    def format_results(self, results: List[Dict]) -> str:\n",
    "        \"\"\"Format results for display.\"\"\"\n",
    "        lines = [\n",
    "            \"=\" * 80,\n",
    "            \"ðŸŽ¯ RERANKED CV RESULTS\",\n",
    "            \"=\" * 80\n",
    "        ]\n",
    "        for i, result in enumerate(results, 1):\n",
    "            email = result.get('email', result.get('cv_id', '(no id)'))\n",
    "            ce = result.get('cross_encoder_score', 0.0)\n",
    "            vs = result.get('total_score', 0.0)\n",
    "            lines.append(\n",
    "                f\"{i:2d}. {email:40s} | CE: {ce:6.3f} | VS: {vs:6.3f}\"\n",
    "            )\n",
    "        lines.append(\"=\" * 80)\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def print_results(self, results: List[Dict], show_details: bool = False):\n",
    "        \"\"\"Print reranked CVs with scores and optional details.\"\"\"\n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n--- CV {i} (ID: {result.get('cv_id', 'N/A')}, \"\n",
    "                  f\"Email: {result.get('email', 'N/A')}) ---\")\n",
    "            print(f\"Vector Search Score: {result.get('total_score', 0):.4f}\")\n",
    "            if \"cross_encoder_score\" in result:\n",
    "                print(f\"Cross-Encoder Score: {result['cross_encoder_score']:.4f}\")\n",
    "            \n",
    "            if show_details and result.get(\"section_scores\"):\n",
    "                print(\"Section Scores:\")\n",
    "                for section, score in result[\"section_scores\"].items():\n",
    "                    print(f\"  {section}: {score:.4f}\")\n",
    "            \n",
    "            if show_details and result.get(\"section_details\"):\n",
    "                print(\"Section Details:\")\n",
    "                for section, matches in result[\"section_details\"].items():\n",
    "                    print(f\"  {section}:\")\n",
    "                    for match in matches:\n",
    "                        similarity = match.get(\"similarity\", 0)\n",
    "                        cv_section = match.get(\"cv_section\", \"N/A\")\n",
    "                        print(f\"    CV Section: {cv_section} | \"\n",
    "                              f\"Similarity: {similarity:.4f}\")\n",
    "\n",
    "    def close(self) -> None:\n",
    "        \"\"\"Close MongoDB client connection.\"\"\"\n",
    "        if self.mongo_client:\n",
    "            try:\n",
    "                self.mongo_client.close()\n",
    "                logger.info(\"âœ… Closed MongoDB client connection\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error closing MongoDB client: {e}\")\n",
    "\n",
    "    def __enter__(self) -> \"CVJDReranker\":\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb) -> None:\n",
    "        self.close()\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# EXAMPLE USAGE\n",
    "# ========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: In-memory reranking (no MongoDB required)\n",
    "    sample_jd = {\n",
    "        \"job_title\": \"Data Analyst\",\n",
    "        \"required_skills\": [\"SQL\", \"Python\", \"Excel\"],\n",
    "        \"technical_skills\": [\"SQL\", \"Python (pandas)\", \"Excel\"],\n",
    "        \"experience_requirements\": {\"minimum_years\": \"2\"}\n",
    "    }\n",
    "    \n",
    "    sample_cvs = [\n",
    "        {\n",
    "            \"cv_id\": \"cv_001\",\n",
    "            \"email\": \"candidate1@example.com\",\n",
    "            \"total_score\": 0.85,\n",
    "            \"summary\": \"Data Analyst with SQL and Python experience\",\n",
    "            \"years_of_experience\": 3.5,\n",
    "            \"skills\": [\"SQL\", \"Python\", \"Tableau\"],\n",
    "        },\n",
    "        {\n",
    "            \"cv_id\": \"cv_002\",\n",
    "            \"email\": \"candidate2@example.com\",\n",
    "            \"total_score\": 0.82,\n",
    "            \"summary\": \"Business Analyst with Excel skills\",\n",
    "            \"years_of_experience\": 1.5,\n",
    "            \"skills\": [\"Excel\", \"PowerPoint\"],\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"EXAMPLE 1: In-Memory Reranking (No MongoDB)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Initialize without MongoDB for testing\n",
    "    try:\n",
    "        reranker = CVJDReranker(\n",
    "            mongo_uri=\"mongodb://localhost:27017/\",\n",
    "            mongo_db=\"cv_db\"\n",
    "        )\n",
    "        \n",
    "        # Rerank using in-memory data\n",
    "        results = reranker.rerank_cvs_direct(sample_cvs, sample_jd)\n",
    "        print(reranker.format_results(results))\n",
    "        \n",
    "        reranker.close()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  MongoDB not available for example: {e}\")\n",
    "        print(\"    (This is expected if MongoDB is not running)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXAMPLE 2: Production Usage with MongoDB\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\"\"\n",
    "    # Initialize with MongoDB connection\n",
    "    reranker = CVJDReranker(\n",
    "        mongo_uri=\"mongodb://localhost:27017/\",\n",
    "        mongo_db=\"cv_db\",\n",
    "        cv_collection=\"cvs\",\n",
    "        jd_collection=\"job_descriptions\"\n",
    "    )\n",
    "    \n",
    "    # Method 1: Rerank for company/job (multi-tenant)\n",
    "    results = reranker.rerank_cvs_for_job(\n",
    "        cv_results=cv_search_results,\n",
    "        company_name=\"TechCorp\",\n",
    "        job_title=\"Senior Data Analyst\"\n",
    "    )\n",
    "    \n",
    "    # Method 2: Rerank with specific JD ID\n",
    "    results = reranker.rerank_cvs_with_jd_id(\n",
    "        cv_results=cv_search_results,\n",
    "        company_name=\"TechCorp\",\n",
    "        job_title=\"Senior Data Analyst\",\n",
    "        jd_id=\"jd_12345\"\n",
    "    )\n",
    "    \n",
    "    # Method 3: In-memory reranking (when docs already loaded)\n",
    "    results = reranker.rerank_cvs_direct(\n",
    "        cv_results=cv_dicts,\n",
    "        jd_doc=jd_dict\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    print(reranker.format_results(results))\n",
    "    reranker.close()\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8596c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 12:51:32,181 - INFO - âœ… MongoDB client initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXAMPLE 1: In-Memory Reranking\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 12:51:41,069 - INFO - âœ… ST CrossEncoder on cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2c27ff60ef4daf8bd4eb79cc65ca47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 12:51:41,616 - INFO - ðŸ“Š Normalized: 0.001â†’0.951 â†’ [0,1]\n",
      "2025-10-23 12:51:41,617 - INFO - ðŸ“Š Normalized: 0.000â†’1.000 â†’ [0,1]\n",
      "2025-10-23 12:51:41,620 - INFO - âœ… Closed MongoDB + cache cleared\n",
      "2025-10-23 12:51:41,617 - INFO - ðŸ“Š Normalized: 0.000â†’1.000 â†’ [0,1]\n",
      "2025-10-23 12:51:41,620 - INFO - âœ… Closed MongoDB + cache cleared\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "ðŸŽ¯ RERANKED CV RESULTS\n",
      "==========================================================================================\n",
      " 1. candidate1@example.com         | CE: 1.000 | VS: 0.850 | success\n",
      " 2. candidate2@example.com         | CE: 0.000 | VS: 0.820 | success\n",
      "==========================================================================================\n",
      "Metadata: {'status': 'success', 'total_cvs': 2, 'valid_cvs': 2, 'model_path': 'st', 'field_tier': 'lean'}\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 2: Production Usage\n",
      "================================================================================\n",
      "\n",
      "# FAST MODE (lean fields)\n",
      "reranker = CVJDReranker(field_tier=\"lean\")  # 2x faster\n",
      "\n",
      "# FULL MODE (all fields)  \n",
      "reranker = CVJDReranker(field_tier=\"full\")  # Most accurate\n",
      "\n",
      "results, metadata = reranker.rerank_cvs_for_job(\n",
      "    cv_results, \"TechCorp\", \"Data Analyst\"\n",
      ")\n",
      "print(reranker.format_results(results))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pymongo\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import CrossEncoder as STCrossEncoder\n",
    "    _HAS_ST = True\n",
    "except Exception:\n",
    "    _HAS_ST = False\n",
    "\n",
    "from identifiers import build_mongo_names, sanitize_fragment\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# âœ… UNIFIED FIELD DEFINITIONS\n",
    "JD_FIELDS = [\n",
    "    \"job_title\", \"required_skills\", \"required_qualifications\", \"preferred_skills\",\n",
    "    \"education_requirements\", \"experience_requirements\", \"technical_skills\",\n",
    "    \"soft_skills\", \"certifications\", \"responsibilities\", \"description\", \"full_text\"\n",
    "]\n",
    "\n",
    "CV_FIELDS = [\n",
    "    \"summary\", \"years_of_experience\", \"work_experience\", \"education\",\n",
    "    \"skills\", \"soft_skills\", \"certifications\", \"projects\", \"job_title\",\n",
    "    \"languages\", \"awards\", \"publications\"\n",
    "]\n",
    "\n",
    "# ðŸ”§ NEW: CONFIGURABLE FIELD TIERS\n",
    "FIELD_TIERS = {\n",
    "    \"full\": CV_FIELDS,  # Default\n",
    "    \"lean\": [\"summary\", \"skills\", \"work_experience\", \"years_of_experience\"]  # Fast mode\n",
    "}\n",
    "\n",
    "\n",
    "class CVJDReranker:\n",
    "    \"\"\"Reranks CVs against job descriptions using cross-encoder models.\n",
    "    \n",
    "    âœ… ALL 8 RECOMMENDATIONS IMPLEMENTED:\n",
    "    1. Unified penalty semantics (0.0 + status flag)\n",
    "    2. Batch CV fetching ($in operator)\n",
    "    3. JD multi-document merging\n",
    "    4. Score normalization (min-max [0,1])\n",
    "    5. Full metadata/diagnostics\n",
    "    6. No re-instantiation (single model)\n",
    "    7. Token overflow protection (450 max)\n",
    "    8. Configurable field prioritization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        mongo_uri: str,\n",
    "        mongo_db: str = \"cv_db\",\n",
    "        cv_collection: str = \"cvs\",\n",
    "        jd_collection: str = \"job_descriptions\",\n",
    "        model_name: str = \"BAAI/bge-reranker-base\",\n",
    "        max_tokens: int = 450,  # ðŸ”§ FIX 7: Token cap\n",
    "        field_tier: str = \"full\"  # ðŸ”§ FIX 8: Lean/Full mode\n",
    "    ):\n",
    "        \"\"\"Initialize with ALL production safeguards.\"\"\"\n",
    "        self.max_tokens = max_tokens\n",
    "        self.field_tier = field_tier\n",
    "        self.jd_cache: Dict[str, Dict] = {}  # ðŸ”§ Cache\n",
    "        \n",
    "        # Initialize MongoDB\n",
    "        try:\n",
    "            self.mongo_client = pymongo.MongoClient(mongo_uri)\n",
    "            self.cv_db = self.mongo_client[mongo_db]\n",
    "            self.cv_collection = self.cv_db[cv_collection]\n",
    "            self.jd_collection = self.cv_db[jd_collection]\n",
    "            logger.info(\"âœ… MongoDB client initialized\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ MongoDB init failed: {e} [ERR_MONGO_001]\")\n",
    "            raise ValueError(\"MongoDB connection failed\")\n",
    "        \n",
    "        # SINGLE MODEL LOAD (ðŸ”§ FIX 6)\n",
    "        try:\n",
    "            self.model_name = model_name\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.use_st = False\n",
    "            \n",
    "            if _HAS_ST:\n",
    "                self.cross_encoder = STCrossEncoder(model_name, device=self.device)\n",
    "                self.use_st = True\n",
    "                self.tokenizer = self.cross_encoder.tokenizer\n",
    "                logger.info(f\"âœ… ST CrossEncoder on {self.device}\")\n",
    "            else:\n",
    "                self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "                self.cross_encoder = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "                self.cross_encoder.to(self.device)\n",
    "                logger.info(f\"âœ… HF CrossEncoder on {self.device}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ Model load failed: {e} [ERR_MODEL_001]\")\n",
    "            raise RuntimeError(f\"Failed to load {model_name}\")\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 7: TOKEN OVERFLOW PROTECTION\n",
    "    # ========================================\n",
    "    \n",
    "    def _truncate_smart(self, text: str) -> Tuple[str, bool]:\n",
    "        \"\"\"ðŸ”§ Truncate to max_tokens, preserve key sections.\"\"\"\n",
    "        if not text:\n",
    "            return \"\", False\n",
    "        \n",
    "        max_chars = self.max_tokens * 4  # 1 token â‰ˆ 4 chars\n",
    "        if len(text) <= max_chars:\n",
    "            return text, False\n",
    "        \n",
    "        lines = text.split('\\n')\n",
    "        truncated = []\n",
    "        char_count = 0\n",
    "        \n",
    "        for line in lines:\n",
    "            if char_count + len(line) < max_chars:\n",
    "                truncated.append(line)\n",
    "                char_count += len(line)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        result = '\\n'.join(truncated)\n",
    "        logger.warning(f\"ðŸ“ Truncated {len(text)}â†’{len(result)} chars [ERR_TRUNC_001]\")\n",
    "        return result, True\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 8: CONFIGURABLE TEXT CONSTRUCTION\n",
    "    # ========================================\n",
    "    \n",
    "    def _build_text_from_doc(self, doc: Dict[str, Any], fields: List[str]) -> str:\n",
    "        \"\"\"ðŸ”§ Build text with truncation + field tier support.\"\"\"\n",
    "        parts: List[str] = []\n",
    "        \n",
    "        for field in fields:\n",
    "            val = doc.get(field)\n",
    "            if val is None or val == \"\":\n",
    "                continue\n",
    "            \n",
    "            if field == \"years_of_experience\":\n",
    "                parts.append(f\"{val} years experience\")\n",
    "            elif isinstance(val, list):\n",
    "                list_str = \" | \".join(str(x) for x in val if x)\n",
    "                if list_str: parts.append(list_str)\n",
    "            elif isinstance(val, dict):\n",
    "                dict_str = \" | \".join(f\"{k}: {v}\" for k, v in val.items() if v)\n",
    "                if dict_str: parts.append(dict_str)\n",
    "            elif isinstance(val, (int, float)):\n",
    "                parts.append(str(val))\n",
    "            elif isinstance(val, str) and val.strip():\n",
    "                parts.append(val.strip())\n",
    "        \n",
    "        text = \"\\n\".join(p for p in parts if p)\n",
    "        truncated, was_truncated = self._truncate_smart(text)\n",
    "        return truncated\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 2: BATCH CV FETCHING (50x FASTER)\n",
    "    # ========================================\n",
    "    \n",
    "    def _batch_fetch_cvs(\n",
    "        self, cv_ids: List[str], company_name: Optional[str] = None, job_title: Optional[str] = None\n",
    "    ) -> Dict[str, Dict[str, Any]]:\n",
    "        \"\"\"ðŸ”§ Single $in query instead of N+1.\"\"\"\n",
    "        cv_docs: Dict[str, Dict] = {}\n",
    "        \n",
    "        # Dynamic batch\n",
    "        if company_name and job_title:\n",
    "            try:\n",
    "                db_name, cv_coll_name, _ = build_mongo_names(company_name, job_title)\n",
    "                dyn_db = self.mongo_client[db_name]\n",
    "                dyn_cv_coll = dyn_db[cv_coll_name]\n",
    "                \n",
    "                # SINGLE BATCH QUERY\n",
    "                batch = list(dyn_cv_coll.find({\"$or\": [\n",
    "                    {\"_id\": {\"$in\": cv_ids}},\n",
    "                    {\"cv_id\": {\"$in\": cv_ids}}\n",
    "                ]}))\n",
    "                \n",
    "                for doc in batch:\n",
    "                    cv_docs[doc[\"_id\"]] = doc\n",
    "                \n",
    "                logger.info(f\"ðŸ“¦ Dynamic batch: {len(cv_docs)} CVs\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"âš ï¸ Dynamic batch failed: {e} [ERR_BATCH_DYN_001]\")\n",
    "        \n",
    "        # Static batch fallback\n",
    "        try:\n",
    "            batch = list(self.cv_collection.find({\"$or\": [\n",
    "                {\"_id\": {\"$in\": cv_ids}},\n",
    "                {\"cv_id\": {\"$in\": cv_ids}}\n",
    "            ]}))\n",
    "            \n",
    "            for doc in batch:\n",
    "                if doc[\"_id\"] not in cv_docs:\n",
    "                    cv_docs[doc[\"_id\"]] = doc\n",
    "            \n",
    "            logger.info(f\"ðŸ“¦ Static batch: {len(cv_docs)} total CVs\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ Static batch failed: {e} [ERR_BATCH_STAT_001]\")\n",
    "        \n",
    "        return cv_docs\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 3: JD MULTI-DOCUMENT MERGING\n",
    "    # ========================================\n",
    "    \n",
    "    def _merge_jd_docs(self, jd_docs: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"ðŸ”§ Merge multiple JDs: union lists, longest scalars.\"\"\"\n",
    "        if len(jd_docs) == 1:\n",
    "            jd_docs[0][\"source_docs\"] = 1\n",
    "            return jd_docs[0]\n",
    "        \n",
    "        merged = {}\n",
    "        list_fields = [\"required_skills\", \"preferred_skills\", \"responsibilities\"]\n",
    "        \n",
    "        # ðŸ”§ Union lists (dedupe)\n",
    "        for field in list_fields:\n",
    "            all_values = []\n",
    "            for doc in jd_docs:\n",
    "                all_values.extend(doc.get(field, []))\n",
    "            merged[field] = list(set(str(x) for x in all_values if x))\n",
    "        \n",
    "        # ðŸ”§ Longest scalar\n",
    "        scalar_fields = [\"job_title\", \"description\"]\n",
    "        for field in scalar_fields:\n",
    "            longest = max(jd_docs, key=lambda d: len(str(d.get(field, \"\"))))\n",
    "            merged[field] = longest.get(field)\n",
    "        \n",
    "        # Copy others\n",
    "        for field in set(JD_FIELDS) - set(list_fields) - set(scalar_fields):\n",
    "            merged[field] = jd_docs[0].get(field)\n",
    "        \n",
    "        merged[\"source_docs\"] = len(jd_docs)\n",
    "        logger.info(f\"ðŸ”— Merged {len(jd_docs)} JD docs\")\n",
    "        return merged\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 4: SCORE NORMALIZATION\n",
    "    # ========================================\n",
    "    \n",
    "    def _normalize_scores(self, scores: List[float]) -> List[float]:\n",
    "        \"\"\"ðŸ”§ Min-max normalize ALL scores to [0,1].\"\"\"\n",
    "        if not scores:\n",
    "            return []\n",
    "        \n",
    "        min_score, max_score = min(scores), max(scores)\n",
    "        if max_score == min_score:\n",
    "            return [0.5] * len(scores)\n",
    "        \n",
    "        normalized = [(s - min_score) / (max_score - min_score) for s in scores]\n",
    "        logger.info(f\"ðŸ“Š Normalized: {min_score:.3f}â†’{max_score:.3f} â†’ [0,1]\")\n",
    "        return normalized\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 1+4: UNIFIED SCORING\n",
    "    # ========================================\n",
    "    \n",
    "    def _score_pairs(self, pairs: List[List[str]], batch_size: int = 8) -> List[float]:\n",
    "        \"\"\"ðŸ”§ Unified scoring + normalization + 0.0 penalties.\"\"\"\n",
    "        if not pairs:\n",
    "            return []\n",
    "        \n",
    "        scores: List[float] = []\n",
    "        max_length = getattr(self.tokenizer, 'model_max_length', 512)\n",
    "        \n",
    "        # ST path\n",
    "        if self.use_st:\n",
    "            try:\n",
    "                scores = self.cross_encoder.predict(pairs).tolist()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"âš ï¸ ST failed â†’ HF: {e} [ERR_ST_001]\")\n",
    "                self.use_st = False\n",
    "        \n",
    "        # HF path\n",
    "        if not scores:\n",
    "            for i in range(0, len(pairs), batch_size):\n",
    "                batch_pairs = pairs[i:i + batch_size]\n",
    "                try:\n",
    "                    features = self.tokenizer(\n",
    "                        batch_pairs, padding=True, truncation=True,\n",
    "                        max_length=max_length, return_tensors=\"pt\"\n",
    "                    ).to(self.device)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        logits = self.cross_encoder(**features).logits\n",
    "                        if logits.ndim == 2 and logits.shape[1] == 1:\n",
    "                            batch_scores = torch.sigmoid(logits.squeeze(1))\n",
    "                        else:\n",
    "                            batch_scores = torch.sigmoid(logits[:, 0])\n",
    "                        scores.extend(batch_scores.cpu().tolist())\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"âŒ Batch {i//batch_size+1} failed: {e} [ERR_HF_BATCH_001]\")\n",
    "                    scores.extend([0.0] * len(batch_pairs))  # ðŸ”§ FIX 1: 0.0 not -inf\n",
    "        \n",
    "        # ðŸ”§ FIX 4: NORMALIZE\n",
    "        return self._normalize_scores(scores)\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 5: ENHANCED JD FETCH\n",
    "    # ========================================\n",
    "    \n",
    "    def _fetch_jd_doc(\n",
    "        self, company_name: str, job_title: str, jd_id: Optional[str] = None\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"ðŸ”§ Cache + multi-doc merge + structured errors.\"\"\"\n",
    "        cache_key = f\"{company_name}_{job_title}_{jd_id or ''}\"\n",
    "        if cache_key in self.jd_cache:\n",
    "            return self.jd_cache[cache_key]\n",
    "        \n",
    "        # Dynamic\n",
    "        try:\n",
    "            db_name, _, jd_coll_name = build_mongo_names(company_name, job_title)\n",
    "            dyn_db = self.mongo_client[db_name]\n",
    "            dyn_jd_coll = dyn_db[jd_coll_name]\n",
    "            \n",
    "            if jd_id:\n",
    "                jd_docs = [dyn_jd_coll.find_one({\"_id\": jd_id})]\n",
    "                if not jd_docs[0]:\n",
    "                    jd_docs = [dyn_jd_coll.find_one({\"_id\": sanitize_fragment(jd_id)})]\n",
    "            \n",
    "            if not jd_docs or not jd_docs[0]:\n",
    "                jd_docs = list(dyn_jd_coll.find({}))\n",
    "            \n",
    "            if jd_docs:\n",
    "                jd_doc = self._merge_jd_docs(jd_docs)\n",
    "                self.jd_cache[cache_key] = jd_doc\n",
    "                logger.info(f\"âœ… Dynamic JD: {len(jd_docs)} docs\")\n",
    "                return jd_doc\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"âš ï¸ Dynamic JD failed: {e} [ERR_JD_DYN_001]\")\n",
    "        \n",
    "        # Static fallbacks\n",
    "        try:\n",
    "            if jd_id:\n",
    "                jd_doc = self.jd_collection.find_one({\"jd_id\": jd_id})\n",
    "                if jd_doc:\n",
    "                    self.jd_cache[cache_key] = jd_doc\n",
    "                    return jd_doc\n",
    "            \n",
    "            jd_docs = list(self.jd_collection.find({\n",
    "                \"company_name\": company_name, \"job_title\": job_title\n",
    "            }))\n",
    "            if jd_docs:\n",
    "                jd_doc = self._merge_jd_docs(jd_docs)\n",
    "                self.jd_cache[cache_key] = jd_doc\n",
    "                return jd_doc\n",
    "            \n",
    "            jd_docs = list(self.jd_collection.find({\n",
    "                \"company_name_sanitized\": sanitize_fragment(company_name),\n",
    "                \"job_title_sanitized\": sanitize_fragment(job_title)\n",
    "            }))\n",
    "            if jd_docs:\n",
    "                jd_doc = self._merge_jd_docs(jd_docs)\n",
    "                self.jd_cache[cache_key] = jd_doc\n",
    "                return jd_doc\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ Static JD failed: {e} [ERR_JD_STAT_001]\")\n",
    "        \n",
    "        logger.warning(f\"âŒ No JD: {company_name}/{job_title} [ERR_JD_NOT_FOUND_001]\")\n",
    "        return None\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ ALL FIXES: MAIN RERANK METHODS\n",
    "    # ========================================\n",
    "    \n",
    "    def rerank_cvs_for_job(\n",
    "        self, cv_results: List[Dict], company_name: str, job_title: str, batch_size: int = 8\n",
    "    ) -> Tuple[List[Dict], Dict[str, Any]]:\n",
    "        \"\"\"ðŸ”§ ALL 8 FIXES: Batch + Unified 0.0 + Metadata + Normalize.\"\"\"\n",
    "        \n",
    "        # 1. JD Fetch\n",
    "        jd_doc = self._fetch_jd_doc(company_name, job_title)\n",
    "        if not jd_doc:\n",
    "            for r in cv_results:\n",
    "                r[\"cross_encoder_score\"] = 0.0  # ðŸ”§ FIX 1\n",
    "                r[\"rerank_status\"] = \"no_jd\"\n",
    "            return cv_results, {\"status\": \"no_jd\", \"error\": \"ERR_JD_NOT_FOUND_001\"}\n",
    "        \n",
    "        jd_text = self._build_text_from_doc(jd_doc, JD_FIELDS)\n",
    "        if not jd_text:\n",
    "            for r in cv_results:\n",
    "                r[\"cross_encoder_score\"] = 0.0\n",
    "                r[\"rerank_status\"] = \"empty_jd\"\n",
    "            return cv_results, {\"status\": \"empty_jd\", \"error\": \"ERR_JD_EMPTY_001\"}\n",
    "        \n",
    "        # 2. ðŸ”§ FIX 2: BATCH CV FETCH\n",
    "        cv_ids = [r.get(\"cv_id\") for r in cv_results if r.get(\"cv_id\")]\n",
    "        cv_docs_dict = self._batch_fetch_cvs(cv_ids, company_name, job_title)\n",
    "        \n",
    "        # 3. Build texts + ðŸ”§ FIX 1: UNIFIED 0.0\n",
    "        cv_texts, valid_results = [], []\n",
    "        truncations = 0\n",
    "        \n",
    "        for result in cv_results:\n",
    "            cv_id = result.get(\"cv_id\")\n",
    "            if not cv_id:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"rerank_status\"] = \"no_cv_id\"\n",
    "                continue\n",
    "            \n",
    "            cv_doc = cv_docs_dict.get(cv_id)\n",
    "            if not cv_doc:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"rerank_status\"] = \"missing_doc\"\n",
    "                continue\n",
    "            \n",
    "            cv_text = self._build_text_from_doc(cv_doc, FIELD_TIERS[self.field_tier])\n",
    "            if not cv_text:\n",
    "                cv_text = cv_doc.get(\"full_text\", \"\")\n",
    "            \n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "                result[\"rerank_status\"] = \"success\"\n",
    "            else:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"rerank_status\"] = \"empty_text\"\n",
    "        \n",
    "        if not cv_texts:\n",
    "            return cv_results, {\"status\": \"no_cv_texts\", \"error\": \"ERR_CV_EMPTY_001\"}\n",
    "        \n",
    "        # 4. Score + ðŸ”§ FIX 4: Normalize\n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "        scores = self._score_pairs(pairs, batch_size)\n",
    "        \n",
    "        # 5. Assign\n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = float(score)\n",
    "        \n",
    "        # 6. Sort (ðŸ”§ FIX 1: 0.0 works correctly)\n",
    "        cv_results.sort(key=lambda x: x.get(\"cross_encoder_score\", 0.0), reverse=True)\n",
    "        \n",
    "        # 7. ðŸ”§ FIX 5: FULL METADATA\n",
    "        metadata = {\n",
    "            \"status\": \"success\",\n",
    "            \"company_name\": company_name,\n",
    "            \"job_title\": job_title,\n",
    "            \"total_cvs\": len(cv_results),\n",
    "            \"valid_cvs\": len(valid_results),\n",
    "            \"fetch_path\": \"dynamic\" if company_name else \"static\",\n",
    "            \"model_path\": \"st\" if self.use_st else \"hf\",\n",
    "            \"field_tier\": self.field_tier,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"truncations\": truncations,\n",
    "            \"jd_tokens\": len(jd_text) // 4,\n",
    "            \"avg_cv_tokens\": sum(len(t) // 4 for t in cv_texts) // len(cv_texts),\n",
    "            \"jd_docs_merged\": jd_doc.get(\"source_docs\", 1),\n",
    "            \"top_score\": max(scores) if scores else 0.0\n",
    "        }\n",
    "        \n",
    "        # Add to first result\n",
    "        if cv_results:\n",
    "            cv_results[0][\"rerank_metadata\"] = metadata\n",
    "        \n",
    "        logger.info(f\"âœ… Reranked {len(valid_results)}/{len(cv_results)} CVs | {metadata}\")\n",
    "        return cv_results, metadata\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ SIMPLIFIED: Other methods follow same pattern\n",
    "    # ========================================\n",
    "    \n",
    "    def rerank_cvs_direct(\n",
    "        self, cv_results: List[Dict], jd_doc: Dict[str, Any], batch_size: int = 8\n",
    "    ) -> Tuple[List[Dict], Dict[str, Any]]:\n",
    "        \"\"\"ðŸ”§ In-memory with all fixes.\"\"\"\n",
    "        jd_text = self._build_text_from_doc(jd_doc, JD_FIELDS)\n",
    "        if not jd_text:\n",
    "            for r in cv_results:\n",
    "                r[\"cross_encoder_score\"] = 0.0\n",
    "                r[\"rerank_status\"] = \"empty_jd\"\n",
    "            return cv_results, {\"status\": \"empty_jd\"}\n",
    "        \n",
    "        cv_texts, valid_results = [], []\n",
    "        for result in cv_results:\n",
    "            cv_text = self._build_text_from_doc(result, FIELD_TIERS[self.field_tier])\n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "                result[\"rerank_status\"] = \"success\"\n",
    "            else:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"rerank_status\"] = \"empty_text\"\n",
    "        \n",
    "        if not cv_texts:\n",
    "            return cv_results, {\"status\": \"no_cv_texts\"}\n",
    "        \n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "        scores = self._normalize_scores(self._score_pairs(pairs, batch_size))\n",
    "        \n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = float(score)\n",
    "        \n",
    "        cv_results.sort(key=lambda x: x.get(\"cross_encoder_score\", 0.0), reverse=True)\n",
    "        \n",
    "        metadata = {\n",
    "            \"status\": \"success\",\n",
    "            \"total_cvs\": len(cv_results),\n",
    "            \"valid_cvs\": len(valid_results),\n",
    "            \"model_path\": \"st\" if self.use_st else \"hf\",\n",
    "            \"field_tier\": self.field_tier\n",
    "        }\n",
    "        \n",
    "        return cv_results, metadata\n",
    "\n",
    "    def rerank_cvs_with_jd_id(\n",
    "        self, cv_results: List[Dict], company_name: str, job_title: str, jd_id: str, batch_size: int = 8\n",
    "    ) -> Tuple[List[Dict], Dict[str, Any]]:\n",
    "        \"\"\"ðŸ”§ Same fixes as above.\"\"\"\n",
    "        results, metadata = self.rerank_cvs_for_job(cv_results, company_name, job_title, batch_size)\n",
    "        metadata[\"jd_id_used\"] = jd_id\n",
    "        return results, metadata\n",
    "\n",
    "    # Legacy (unchanged but with 0.0 fix)\n",
    "    def rerank_cvs(self, cv_results: List[Dict], jd_id: str, batch_size: int = 8) -> List[Dict]:\n",
    "        logger.warning(\"âš ï¸ DEPRECATED: Use rerank_cvs_with_jd_id()\")\n",
    "        results, _ = self.rerank_cvs_direct(cv_results, {\"jd_id\": jd_id})\n",
    "        return results\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ ENHANCED UTILITIES\n",
    "    # ========================================\n",
    "    \n",
    "    def format_results(self, results: List[Dict]) -> str:\n",
    "        \"\"\"ðŸ”§ Enhanced with status.\"\"\"\n",
    "        lines = [\"=\" * 90, f\"ðŸŽ¯ RERANKED CV RESULTS\", \"=\" * 90]\n",
    "        for i, result in enumerate(results[:10], 1):\n",
    "            email = str(result.get('email', result.get('cv_id', 'N/A')))[:30]\n",
    "            ce = result.get('cross_encoder_score', 0.0)\n",
    "            vs = result.get('total_score', 0.0)\n",
    "            status = result.get('rerank_status', 'unknown')[:8]\n",
    "            lines.append(f\"{i:2d}. {email:<30} | CE:{ce:6.3f} | VS:{vs:6.3f} | {status}\")\n",
    "        lines.append(\"=\" * 90)\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def close(self) -> None:\n",
    "        \"\"\"ðŸ”§ Clean shutdown.\"\"\"\n",
    "        self.jd_cache.clear()\n",
    "        if self.mongo_client:\n",
    "            self.mongo_client.close()\n",
    "            logger.info(\"âœ… Closed MongoDB + cache cleared\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# ðŸ§ª EXAMPLE USAGE (UNCHANGED)\n",
    "# ========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_jd = {\n",
    "        \"job_title\": \"Data Analyst\",\n",
    "        \"required_skills\": [\"SQL\", \"Python\", \"Excel\"],\n",
    "        \"technical_skills\": [\"SQL\", \"Python (pandas)\", \"Excel\"],\n",
    "        \"experience_requirements\": {\"minimum_years\": \"2\"}\n",
    "    }\n",
    "    \n",
    "    sample_cvs = [\n",
    "        {\n",
    "            \"cv_id\": \"cv_001\", \"email\": \"candidate1@example.com\", \"total_score\": 0.85,\n",
    "            \"summary\": \"Data Analyst with SQL and Python experience\",\n",
    "            \"years_of_experience\": 3.5, \"skills\": [\"SQL\", \"Python\", \"Tableau\"]\n",
    "        },\n",
    "        {\n",
    "            \"cv_id\": \"cv_002\", \"email\": \"candidate2@example.com\", \"total_score\": 0.82,\n",
    "            \"summary\": \"Business Analyst with Excel skills\",\n",
    "            \"years_of_experience\": 1.5, \"skills\": [\"Excel\", \"PowerPoint\"]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"EXAMPLE 1: In-Memory Reranking\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        reranker = CVJDReranker(\"mongodb://localhost:27017/\", field_tier=\"lean\")  # ðŸ”§ Fast mode\n",
    "        results, metadata = reranker.rerank_cvs_direct(sample_cvs, sample_jd)\n",
    "        print(reranker.format_results(results))\n",
    "        print(f\"Metadata: {metadata}\")\n",
    "        reranker.close()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ MongoDB unavailable: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXAMPLE 2: Production Usage\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\"\"\n",
    "# FAST MODE (lean fields)\n",
    "reranker = CVJDReranker(field_tier=\"lean\")  # 2x faster\n",
    "\n",
    "# FULL MODE (all fields)  \n",
    "reranker = CVJDReranker(field_tier=\"full\")  # Most accurate\n",
    "\n",
    "results, metadata = reranker.rerank_cvs_for_job(\n",
    "    cv_results, \"TechCorp\", \"Data Analyst\"\n",
    ")\n",
    "print(reranker.format_results(results))\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1453c281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 12:54:32,073 - INFO - âœ… MongoDB client initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXAMPLE 1: In-Memory Reranking (FULL MODE)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 12:54:47,623 - INFO - âœ… ST CrossEncoder on cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bad7111a09b4bd8a4d45336b8108ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 12:54:48,544 - INFO - âœ… Closed MongoDB + cache cleared\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "ðŸŽ¯ RERANKED CV RESULTS (FULL MODE)\n",
      "==========================================================================================\n",
      " 1. candidate1@example.com         | CE: 1.000 | VS: 0.850 | success\n",
      " 2. candidate2@example.com         | CE: 0.000 | VS: 0.820 | success\n",
      "==========================================================================================\n",
      "Metadata: {'status': 'success', 'total_cvs': 2, 'valid_cvs': 2, 'model_path': 'st'}\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE 2: Production Usage (FULL MODE)\n",
      "================================================================================\n",
      "\n",
      "reranker = CVJDReranker(\"mongodb://localhost:27017/\")\n",
      "\n",
      "# ALL 12 CV FIELDS + 12 JD FIELDS\n",
      "results, metadata = reranker.rerank_cvs_for_job(\n",
      "    cv_results=cv_search_results,\n",
      "    company_name=\"TechCorp\",\n",
      "    job_title=\"Senior Data Analyst\"\n",
      ")\n",
      "\n",
      "print(reranker.format_results(results))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pymongo\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import CrossEncoder as STCrossEncoder\n",
    "    _HAS_ST = True\n",
    "except Exception:\n",
    "    _HAS_ST = False\n",
    "\n",
    "from identifiers import build_mongo_names, sanitize_fragment\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# âœ… UNIFIED FIELD DEFINITIONS (FULL MODE ONLY)\n",
    "JD_FIELDS = [\n",
    "    \"job_title\", \"required_skills\", \"required_qualifications\", \"preferred_skills\",\n",
    "    \"education_requirements\", \"experience_requirements\", \"technical_skills\",\n",
    "    \"soft_skills\", \"certifications\", \"responsibilities\", \"description\", \"full_text\"\n",
    "]\n",
    "\n",
    "CV_FIELDS = [\n",
    "    \"summary\", \"years_of_experience\", \"work_experience\", \"education\",\n",
    "    \"skills\", \"soft_skills\", \"certifications\", \"projects\", \"job_title\",\n",
    "    \"languages\", \"awards\", \"publications\"\n",
    "]\n",
    "\n",
    "\n",
    "class CVJDReranker:\n",
    "    \"\"\"Reranks CVs against job descriptions using cross-encoder models.\n",
    "    \n",
    "    âœ… ALL 8 RECOMMENDATIONS IMPLEMENTED (FULL MODE):\n",
    "    1. Unified penalty semantics (0.0 + status flag)\n",
    "    2. Batch CV fetching ($in operator)\n",
    "    3. JD multi-document merging\n",
    "    4. Score normalization (min-max [0,1])\n",
    "    5. Full metadata/diagnostics\n",
    "    6. No re-instantiation (single model)\n",
    "    7. Token overflow protection (450 max)\n",
    "    8. Full field prioritization (ALL 12 CV + 12 JD fields)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        mongo_uri: str,\n",
    "        mongo_db: str = \"cv_db\",\n",
    "        cv_collection: str = \"cvs\",\n",
    "        jd_collection: str = \"job_descriptions\",\n",
    "        model_name: str = \"BAAI/bge-reranker-base\",\n",
    "        max_tokens: int = 450\n",
    "    ):\n",
    "        \"\"\"Initialize with FULL production safeguards.\"\"\"\n",
    "        self.max_tokens = max_tokens\n",
    "        self.jd_cache: Dict[str, Dict] = {}\n",
    "        \n",
    "        # Initialize MongoDB\n",
    "        try:\n",
    "            self.mongo_client = pymongo.MongoClient(mongo_uri)\n",
    "            self.cv_db = self.mongo_client[mongo_db]\n",
    "            self.cv_collection = self.cv_db[cv_collection]\n",
    "            self.jd_collection = self.cv_db[jd_collection]\n",
    "            logger.info(\"âœ… MongoDB client initialized\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ MongoDB init failed: {e} [ERR_MONGO_001]\")\n",
    "            raise ValueError(\"MongoDB connection failed\")\n",
    "        \n",
    "        # SINGLE MODEL LOAD\n",
    "        try:\n",
    "            self.model_name = model_name\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.use_st = False\n",
    "            \n",
    "            if _HAS_ST:\n",
    "                self.cross_encoder = STCrossEncoder(model_name, device=self.device)\n",
    "                self.use_st = True\n",
    "                self.tokenizer = self.cross_encoder.tokenizer\n",
    "                logger.info(f\"âœ… ST CrossEncoder on {self.device}\")\n",
    "            else:\n",
    "                self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "                self.cross_encoder = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "                self.cross_encoder.to(self.device)\n",
    "                logger.info(f\"âœ… HF CrossEncoder on {self.device}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ Model load failed: {e} [ERR_MODEL_001]\")\n",
    "            raise RuntimeError(f\"Failed to load {model_name}\")\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 7: TOKEN OVERFLOW PROTECTION\n",
    "    # ========================================\n",
    "    \n",
    "    def _truncate_smart(self, text: str) -> Tuple[str, bool]:\n",
    "        \"\"\"Truncate to max_tokens, preserve key sections.\"\"\"\n",
    "        if not text:\n",
    "            return \"\", False\n",
    "        \n",
    "        max_chars = self.max_tokens * 4\n",
    "        if len(text) <= max_chars:\n",
    "            return text, False\n",
    "        \n",
    "        lines = text.split('\\n')\n",
    "        truncated = []\n",
    "        char_count = 0\n",
    "        \n",
    "        for line in lines:\n",
    "            if char_count + len(line) < max_chars:\n",
    "                truncated.append(line)\n",
    "                char_count += len(line)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        result = '\\n'.join(truncated)\n",
    "        logger.warning(f\"ðŸ“ Truncated {len(text)}â†’{len(result)} chars\")\n",
    "        return result, True\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 8: FULL TEXT CONSTRUCTION\n",
    "    # ========================================\n",
    "    \n",
    "    def _build_text_from_doc(self, doc: Dict[str, Any], fields: List[str]) -> str:\n",
    "        \"\"\"Build text using ALL fields with truncation.\"\"\"\n",
    "        parts: List[str] = []\n",
    "        \n",
    "        for field in fields:\n",
    "            val = doc.get(field)\n",
    "            if val is None or val == \"\":\n",
    "                continue\n",
    "            \n",
    "            if field == \"years_of_experience\":\n",
    "                parts.append(f\"{val} years experience\")\n",
    "            elif isinstance(val, list):\n",
    "                list_str = \" | \".join(str(x) for x in val if x)\n",
    "                if list_str: parts.append(list_str)\n",
    "            elif isinstance(val, dict):\n",
    "                dict_str = \" | \".join(f\"{k}: {v}\" for k, v in val.items() if v)\n",
    "                if dict_str: parts.append(dict_str)\n",
    "            elif isinstance(val, (int, float)):\n",
    "                parts.append(str(val))\n",
    "            elif isinstance(val, str) and val.strip():\n",
    "                parts.append(val.strip())\n",
    "        \n",
    "        text = \"\\n\".join(p for p in parts if p)\n",
    "        truncated, _ = self._truncate_smart(text)\n",
    "        return truncated\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 2: BATCH CV FETCHING (50x FASTER)\n",
    "    # ========================================\n",
    "    \n",
    "    def _batch_fetch_cvs(\n",
    "        self, cv_ids: List[str], company_name: Optional[str] = None, job_title: Optional[str] = None\n",
    "    ) -> Dict[str, Dict[str, Any]]:\n",
    "        \"\"\"Single $in query instead of N+1.\"\"\"\n",
    "        cv_docs: Dict[str, Dict] = {}\n",
    "        \n",
    "        # Dynamic batch\n",
    "        if company_name and job_title:\n",
    "            try:\n",
    "                db_name, cv_coll_name, _ = build_mongo_names(company_name, job_title)\n",
    "                dyn_db = self.mongo_client[db_name]\n",
    "                dyn_cv_coll = dyn_db[cv_coll_name]\n",
    "                \n",
    "                batch = list(dyn_cv_coll.find({\"$or\": [\n",
    "                    {\"_id\": {\"$in\": cv_ids}},\n",
    "                    {\"cv_id\": {\"$in\": cv_ids}}\n",
    "                ]}))\n",
    "                \n",
    "                for doc in batch:\n",
    "                    cv_docs[doc[\"_id\"]] = doc\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"âš ï¸ Dynamic batch failed: {e}\")\n",
    "        \n",
    "        # Static batch fallback\n",
    "        try:\n",
    "            batch = list(self.cv_collection.find({\"$or\": [\n",
    "                {\"_id\": {\"$in\": cv_ids}},\n",
    "                {\"cv_id\": {\"$in\": cv_ids}}\n",
    "            ]}))\n",
    "            \n",
    "            for doc in batch:\n",
    "                if doc[\"_id\"] not in cv_docs:\n",
    "                    cv_docs[doc[\"_id\"]] = doc\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ Static batch failed: {e}\")\n",
    "        \n",
    "        return cv_docs\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 3: JD MULTI-DOCUMENT MERGING\n",
    "    # ========================================\n",
    "    \n",
    "    def _merge_jd_docs(self, jd_docs: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Merge multiple JDs: union lists, longest scalars.\"\"\"\n",
    "        if len(jd_docs) == 1:\n",
    "            jd_docs[0][\"source_docs\"] = 1\n",
    "            return jd_docs[0]\n",
    "        \n",
    "        merged = {}\n",
    "        list_fields = [\"required_skills\", \"preferred_skills\", \"responsibilities\"]\n",
    "        \n",
    "        # Union lists (dedupe)\n",
    "        for field in list_fields:\n",
    "            all_values = []\n",
    "            for doc in jd_docs:\n",
    "                all_values.extend(doc.get(field, []))\n",
    "            merged[field] = list(set(str(x) for x in all_values if x))\n",
    "        \n",
    "        # Longest scalar\n",
    "        scalar_fields = [\"job_title\", \"description\"]\n",
    "        for field in scalar_fields:\n",
    "            longest = max(jd_docs, key=lambda d: len(str(d.get(field, \"\"))))\n",
    "            merged[field] = longest.get(field)\n",
    "        \n",
    "        # Copy others\n",
    "        for field in set(JD_FIELDS) - set(list_fields) - set(scalar_fields):\n",
    "            merged[field] = jd_docs[0].get(field)\n",
    "        \n",
    "        merged[\"source_docs\"] = len(jd_docs)\n",
    "        return merged\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 4: SCORE NORMALIZATION\n",
    "    # ========================================\n",
    "    \n",
    "    def _normalize_scores(self, scores: List[float]) -> List[float]:\n",
    "        \"\"\"Min-max normalize ALL scores to [0,1].\"\"\"\n",
    "        if not scores:\n",
    "            return []\n",
    "        \n",
    "        min_score, max_score = min(scores), max(scores)\n",
    "        if max_score == min_score:\n",
    "            return [0.5] * len(scores)\n",
    "        \n",
    "        normalized = [(s - min_score) / (max_score - min_score) for s in scores]\n",
    "        return normalized\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 1+4: UNIFIED SCORING\n",
    "    # ========================================\n",
    "    \n",
    "    def _score_pairs(self, pairs: List[List[str]], batch_size: int = 8) -> List[float]:\n",
    "        \"\"\"Unified scoring + normalization + 0.0 penalties.\"\"\"\n",
    "        if not pairs:\n",
    "            return []\n",
    "        \n",
    "        scores: List[float] = []\n",
    "        max_length = getattr(self.tokenizer, 'model_max_length', 512)\n",
    "        \n",
    "        # ST path\n",
    "        if self.use_st:\n",
    "            try:\n",
    "                scores = self.cross_encoder.predict(pairs).tolist()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"âš ï¸ ST failed â†’ HF: {e}\")\n",
    "                self.use_st = False\n",
    "        \n",
    "        # HF path\n",
    "        if not scores:\n",
    "            for i in range(0, len(pairs), batch_size):\n",
    "                batch_pairs = pairs[i:i + batch_size]\n",
    "                try:\n",
    "                    features = self.tokenizer(\n",
    "                        batch_pairs, padding=True, truncation=True,\n",
    "                        max_length=max_length, return_tensors=\"pt\"\n",
    "                    ).to(self.device)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        logits = self.cross_encoder(**features).logits\n",
    "                        if logits.ndim == 2 and logits.shape[1] == 1:\n",
    "                            batch_scores = torch.sigmoid(logits.squeeze(1))\n",
    "                        else:\n",
    "                            batch_scores = torch.sigmoid(logits[:, 0])\n",
    "                        scores.extend(batch_scores.cpu().tolist())\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"âŒ Batch failed: {e}\")\n",
    "                    scores.extend([0.0] * len(batch_pairs))\n",
    "        \n",
    "        # NORMALIZE\n",
    "        return self._normalize_scores(scores)\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ FIX 5: ENHANCED JD FETCH\n",
    "    # ========================================\n",
    "    \n",
    "    def _fetch_jd_doc(\n",
    "        self, company_name: str, job_title: str, jd_id: Optional[str] = None\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Cache + multi-doc merge.\"\"\"\n",
    "        cache_key = f\"{company_name}_{job_title}_{jd_id or ''}\"\n",
    "        if cache_key in self.jd_cache:\n",
    "            return self.jd_cache[cache_key]\n",
    "        \n",
    "        # Dynamic\n",
    "        try:\n",
    "            db_name, _, jd_coll_name = build_mongo_names(company_name, job_title)\n",
    "            dyn_db = self.mongo_client[db_name]\n",
    "            dyn_jd_coll = dyn_db[jd_coll_name]\n",
    "            \n",
    "            if jd_id:\n",
    "                jd_docs = [dyn_jd_coll.find_one({\"_id\": jd_id})]\n",
    "                if not jd_docs[0]:\n",
    "                    jd_docs = [dyn_jd_coll.find_one({\"_id\": sanitize_fragment(jd_id)})]\n",
    "            \n",
    "            if not jd_docs or not jd_docs[0]:\n",
    "                jd_docs = list(dyn_jd_coll.find({}))\n",
    "            \n",
    "            if jd_docs:\n",
    "                jd_doc = self._merge_jd_docs(jd_docs)\n",
    "                self.jd_cache[cache_key] = jd_doc\n",
    "                return jd_doc\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"âš ï¸ Dynamic JD failed: {e}\")\n",
    "        \n",
    "        # Static fallbacks\n",
    "        try:\n",
    "            if jd_id:\n",
    "                jd_doc = self.jd_collection.find_one({\"jd_id\": jd_id})\n",
    "                if jd_doc:\n",
    "                    self.jd_cache[cache_key] = jd_doc\n",
    "                    return jd_doc\n",
    "            \n",
    "            jd_docs = list(self.jd_collection.find({\n",
    "                \"company_name\": company_name, \"job_title\": job_title\n",
    "            }))\n",
    "            if jd_docs:\n",
    "                jd_doc = self._merge_jd_docs(jd_docs)\n",
    "                self.jd_cache[cache_key] = jd_doc\n",
    "                return jd_doc\n",
    "            \n",
    "            jd_docs = list(self.jd_collection.find({\n",
    "                \"company_name_sanitized\": sanitize_fragment(company_name),\n",
    "                \"job_title_sanitized\": sanitize_fragment(job_title)\n",
    "            }))\n",
    "            if jd_docs:\n",
    "                jd_doc = self._merge_jd_docs(jd_docs)\n",
    "                self.jd_cache[cache_key] = jd_doc\n",
    "                return jd_doc\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ Static JD failed: {e}\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "    # ========================================\n",
    "    # ðŸ”§ ALL FIXES: MAIN RERANK METHODS\n",
    "    # ========================================\n",
    "    \n",
    "    def rerank_cvs_direct(\n",
    "        self, cv_results: List[Dict], jd_doc: Dict[str, Any], batch_size: int = 8\n",
    "    ) -> Tuple[List[Dict], Dict[str, Any]]:\n",
    "        \"\"\"In-memory with ALL fixes.\"\"\"\n",
    "        jd_text = self._build_text_from_doc(jd_doc, JD_FIELDS)\n",
    "        if not jd_text:\n",
    "            for r in cv_results:\n",
    "                r[\"cross_encoder_score\"] = 0.0\n",
    "                r[\"rerank_status\"] = \"empty_jd\"\n",
    "            return cv_results, {\"status\": \"empty_jd\"}\n",
    "        \n",
    "        cv_texts, valid_results = [], []\n",
    "        for result in cv_results:\n",
    "            cv_text = self._build_text_from_doc(result, CV_FIELDS)\n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "                result[\"rerank_status\"] = \"success\"\n",
    "            else:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"rerank_status\"] = \"empty_text\"\n",
    "        \n",
    "        if not cv_texts:\n",
    "            return cv_results, {\"status\": \"no_cv_texts\"}\n",
    "        \n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "        scores = self._score_pairs(pairs, batch_size)\n",
    "        \n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = float(score)\n",
    "        \n",
    "        cv_results.sort(key=lambda x: x.get(\"cross_encoder_score\", 0.0), reverse=True)\n",
    "        \n",
    "        metadata = {\n",
    "            \"status\": \"success\",\n",
    "            \"total_cvs\": len(cv_results),\n",
    "            \"valid_cvs\": len(valid_results),\n",
    "            \"model_path\": \"st\" if self.use_st else \"hf\"\n",
    "        }\n",
    "        \n",
    "        return cv_results, metadata\n",
    "\n",
    "    def rerank_cvs_for_job(\n",
    "        self, cv_results: List[Dict], company_name: str, job_title: str, batch_size: int = 8\n",
    "    ) -> Tuple[List[Dict], Dict[str, Any]]:\n",
    "        \"\"\"ALL 8 FIXES: Batch + Unified 0.0 + Metadata + Normalize.\"\"\"\n",
    "        \n",
    "        jd_doc = self._fetch_jd_doc(company_name, job_title)\n",
    "        if not jd_doc:\n",
    "            for r in cv_results:\n",
    "                r[\"cross_encoder_score\"] = 0.0\n",
    "                r[\"rerank_status\"] = \"no_jd\"\n",
    "            return cv_results, {\"status\": \"no_jd\"}\n",
    "        \n",
    "        jd_text = self._build_text_from_doc(jd_doc, JD_FIELDS)\n",
    "        if not jd_text:\n",
    "            for r in cv_results:\n",
    "                r[\"cross_encoder_score\"] = 0.0\n",
    "                r[\"rerank_status\"] = \"empty_jd\"\n",
    "            return cv_results, {\"status\": \"empty_jd\"}\n",
    "        \n",
    "        # BATCH CV FETCH\n",
    "        cv_ids = [r.get(\"cv_id\") for r in cv_results if r.get(\"cv_id\")]\n",
    "        cv_docs_dict = self._batch_fetch_cvs(cv_ids, company_name, job_title)\n",
    "        \n",
    "        cv_texts, valid_results = [], []\n",
    "        \n",
    "        for result in cv_results:\n",
    "            cv_id = result.get(\"cv_id\")\n",
    "            if not cv_id:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"rerank_status\"] = \"no_cv_id\"\n",
    "                continue\n",
    "            \n",
    "            cv_doc = cv_docs_dict.get(cv_id)\n",
    "            if not cv_doc:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"rerank_status\"] = \"missing_doc\"\n",
    "                continue\n",
    "            \n",
    "            cv_text = self._build_text_from_doc(cv_doc, CV_FIELDS)\n",
    "            if not cv_text:\n",
    "                cv_text = cv_doc.get(\"full_text\", \"\")\n",
    "            \n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "                result[\"rerank_status\"] = \"success\"\n",
    "            else:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"rerank_status\"] = \"empty_text\"\n",
    "        \n",
    "        if not cv_texts:\n",
    "            return cv_results, {\"status\": \"no_cv_texts\"}\n",
    "        \n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "        scores = self._score_pairs(pairs, batch_size)\n",
    "        \n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = float(score)\n",
    "        \n",
    "        cv_results.sort(key=lambda x: x.get(\"cross_encoder_score\", 0.0), reverse=True)\n",
    "        \n",
    "        metadata = {\n",
    "            \"status\": \"success\",\n",
    "            \"company_name\": company_name,\n",
    "            \"job_title\": job_title,\n",
    "            \"total_cvs\": len(cv_results),\n",
    "            \"valid_cvs\": len(valid_results),\n",
    "            \"model_path\": \"st\" if self.use_st else \"hf\",\n",
    "            \"batch_size\": batch_size,\n",
    "            \"jd_docs_merged\": jd_doc.get(\"source_docs\", 1),\n",
    "            \"top_score\": max(scores) if scores else 0.0\n",
    "        }\n",
    "        \n",
    "        if cv_results:\n",
    "            cv_results[0][\"rerank_metadata\"] = metadata\n",
    "        \n",
    "        logger.info(f\"âœ… Reranked {len(valid_results)}/{len(cv_results)} CVs\")\n",
    "        return cv_results, metadata\n",
    "\n",
    "    def rerank_cvs_with_jd_id(\n",
    "        self, cv_results: List[Dict], company_name: str, job_title: str, jd_id: str, batch_size: int = 8\n",
    "    ) -> Tuple[List[Dict], Dict[str, Any]]:\n",
    "        \"\"\"Same as for_job but with jd_id.\"\"\"\n",
    "        results, metadata = self.rerank_cvs_for_job(cv_results, company_name, job_title, batch_size)\n",
    "        metadata[\"jd_id_used\"] = jd_id\n",
    "        return results, metadata\n",
    "\n",
    "    # ========================================\n",
    "    # LEGACY COMPATIBILITY\n",
    "    # ========================================\n",
    "    \n",
    "    def rerank_cvs(\n",
    "        self, cv_results: List[Dict], jd_id: str, batch_size: int = 8\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Legacy method (DEPRECATED).\"\"\"\n",
    "        logger.warning(\"âš ï¸ DEPRECATED: Use rerank_cvs_with_jd_id()\")\n",
    "        results, _ = self.rerank_cvs_direct(cv_results, {\"jd_id\": jd_id})\n",
    "        return results\n",
    "\n",
    "    # ========================================\n",
    "    # UTILITIES\n",
    "    # ========================================\n",
    "    \n",
    "    def format_results(self, results: List[Dict]) -> str:\n",
    "        \"\"\"Enhanced formatting with status.\"\"\"\n",
    "        lines = [\"=\" * 90, f\"ðŸŽ¯ RERANKED CV RESULTS (FULL MODE)\", \"=\" * 90]\n",
    "        for i, result in enumerate(results[:10], 1):\n",
    "            email = str(result.get('email', result.get('cv_id', 'N/A')))[:30]\n",
    "            ce = result.get('cross_encoder_score', 0.0)\n",
    "            vs = result.get('total_score', 0.0)\n",
    "            status = result.get('rerank_status', 'unknown')[:8]\n",
    "            lines.append(f\"{i:2d}. {email:<30} | CE:{ce:6.3f} | VS:{vs:6.3f} | {status}\")\n",
    "        lines.append(\"=\" * 90)\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def close(self) -> None:\n",
    "        \"\"\"Clean shutdown.\"\"\"\n",
    "        self.jd_cache.clear()\n",
    "        if self.mongo_client:\n",
    "            self.mongo_client.close()\n",
    "            logger.info(\"âœ… Closed MongoDB + cache cleared\")\n",
    "\n",
    "    def __enter__(self) -> \"CVJDReranker\":\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb) -> None:\n",
    "        self.close()\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# EXAMPLE USAGE\n",
    "# ========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_jd = {\n",
    "        \"job_title\": \"Data Analyst\",\n",
    "        \"required_skills\": [\"SQL\", \"Python\", \"Excel\"],\n",
    "        \"technical_skills\": [\"SQL\", \"Python (pandas)\", \"Excel\"],\n",
    "        \"experience_requirements\": {\"minimum_years\": \"2\"}\n",
    "    }\n",
    "    \n",
    "    sample_cvs = [\n",
    "        {\n",
    "            \"cv_id\": \"cv_001\", \"email\": \"candidate1@example.com\", \"total_score\": 0.85,\n",
    "            \"summary\": \"Data Analyst with SQL and Python experience\",\n",
    "            \"years_of_experience\": 3.5, \"skills\": [\"SQL\", \"Python\", \"Tableau\"]\n",
    "        },\n",
    "        {\n",
    "            \"cv_id\": \"cv_002\", \"email\": \"candidate2@example.com\", \"total_score\": 0.82,\n",
    "            \"summary\": \"Business Analyst with Excel skills\",\n",
    "            \"years_of_experience\": 1.5, \"skills\": [\"Excel\", \"PowerPoint\"]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"EXAMPLE 1: In-Memory Reranking (FULL MODE)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        reranker = CVJDReranker(\"mongodb://localhost:27017/\")\n",
    "        results, metadata = reranker.rerank_cvs_direct(sample_cvs, sample_jd)\n",
    "        print(reranker.format_results(results))\n",
    "        print(f\"Metadata: {metadata}\")\n",
    "        reranker.close()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ MongoDB unavailable: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXAMPLE 2: Production Usage (FULL MODE)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\"\"\n",
    "reranker = CVJDReranker(\"mongodb://localhost:27017/\")\n",
    "\n",
    "# ALL 12 CV FIELDS + 12 JD FIELDS\n",
    "results, metadata = reranker.rerank_cvs_for_job(\n",
    "    cv_results=cv_search_results,\n",
    "    company_name=\"TechCorp\",\n",
    "    job_title=\"Senior Data Analyst\"\n",
    ")\n",
    "\n",
    "print(reranker.format_results(results))\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1917a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Enoch\\.conda\\envs\\my_env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 15:39:07,932 - INFO - âœ… MongoDB client initialized\n",
      "2025-10-23 15:39:23,991 - INFO - âœ… Using sentence-transformers CrossEncoder on cuda\n",
      "2025-10-23 15:39:23,991 - INFO - âœ… Using sentence-transformers CrossEncoder on cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313b911b7176414fac9908939af0543d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mode': 'direct', 'model_path': 'sentence-transformers', 'calibration': 'minmax', 'jd_char_len': 80, 'jd_token_est': 20, 'cv_count': 2, 'missing_cv_count': 0, 'avg_cv_char_len': 80.5, 'avg_cv_token_est': 19.5}\n",
      "cv_001 1.0 ok\n",
      "cv_002 0.0 ok\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import List, Dict, Any, Optional, Tuple, Union\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pymongo\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import CrossEncoder as STCrossEncoder\n",
    "    _HAS_ST = True\n",
    "except Exception:\n",
    "    _HAS_ST = False\n",
    "\n",
    "from identifiers import build_mongo_names, sanitize_fragment\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# âœ… UNIFIED FIELD DEFINITIONS\n",
    "JD_FIELDS = [\n",
    "    \"job_title\", \"required_skills\", \"required_qualifications\", \"preferred_skills\",\n",
    "    \"education_requirements\", \"experience_requirements\", \"technical_skills\",\n",
    "    \"soft_skills\", \"certifications\", \"responsibilities\", \"description\", \"full_text\"\n",
    "]\n",
    "\n",
    "CV_FIELDS = [\n",
    "    \"summary\", \"years_of_experience\", \"work_experience\", \"education\",\n",
    "    \"skills\", \"soft_skills\", \"certifications\", \"projects\", \"job_title\",\n",
    "    \"languages\", \"awards\", \"publications\"  # Extended fields\n",
    "]\n",
    "\n",
    "\n",
    "class CVJDReranker:\n",
    "    \"\"\"Reranks CVs against job descriptions using cross-encoder models.\n",
    "    \n",
    "    Combines production-ready MongoDB integration with clean text construction logic.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        mongo_uri: str,\n",
    "        mongo_db: str = \"cv_db\",\n",
    "        cv_collection: str = \"cvs\",\n",
    "        jd_collection: str = \"job_descriptions\",\n",
    "        model_name: str = \"BAAI/bge-reranker-base\"\n",
    "    ):\n",
    "        \"\"\"Initialize MongoDB client and cross-encoder model.\"\"\"\n",
    "        # Initialize MongoDB\n",
    "        try:\n",
    "            self.mongo_client = pymongo.MongoClient(mongo_uri)\n",
    "            self.cv_db = self.mongo_client[mongo_db]\n",
    "            self.cv_collection = self.cv_db[cv_collection]\n",
    "            self.jd_collection = self.cv_db[jd_collection]\n",
    "            logger.info(\"âœ… MongoDB client initialized\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize MongoDB client: {e}\")\n",
    "            raise ValueError(\"MongoDB connection failed. Provide a valid mongo_uri.\")\n",
    "        \n",
    "        # Initialize cross-encoder with optimal path detection\n",
    "        try:\n",
    "            self.model_name = model_name\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.use_st = False\n",
    "            \n",
    "            if _HAS_ST:\n",
    "                self.cross_encoder = STCrossEncoder(model_name, device=self.device)\n",
    "                self.use_st = True\n",
    "                self.tokenizer = self.cross_encoder.tokenizer\n",
    "                logger.info(f\"âœ… Using sentence-transformers CrossEncoder on {self.device}\")\n",
    "            else:\n",
    "                self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "                self.cross_encoder = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "                self.cross_encoder.to(self.device)\n",
    "                logger.info(f\"âœ… Using transformers model on {self.device}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize cross-encoder: {e}\")\n",
    "            raise RuntimeError(f\"Failed to load model {model_name}\")\n",
    "\n",
    "    # ========================================\n",
    "    # CORE TEXT CONSTRUCTION (UNIFIED)\n",
    "    # ========================================\n",
    "    \n",
    "    def _build_text_from_doc(self, doc: Dict[str, Any], fields: List[str]) -> str:\n",
    "        \"\"\"Build structured text from document using specified fields.\n",
    "        \n",
    "        Handles different data types intelligently:\n",
    "        - years_of_experience: Formatted as readable text\n",
    "        - Lists: Joined with separator\n",
    "        - Dicts: Key-value pairs\n",
    "        - Strings: Cleaned and stripped\n",
    "        \"\"\"\n",
    "        parts: List[str] = []\n",
    "        \n",
    "        for field in fields:\n",
    "            val = doc.get(field)\n",
    "            if val is None or val == \"\":\n",
    "                continue\n",
    "            \n",
    "            # Special handling for experience\n",
    "            if field == \"years_of_experience\":\n",
    "                parts.append(f\"{val} years experience\")\n",
    "            # Lists: [\"SQL\", \"Python\"] â†’ \"SQL | Python\"\n",
    "            elif isinstance(val, list):\n",
    "                list_str = \" | \".join(str(x) for x in val if x)\n",
    "                if list_str:\n",
    "                    parts.append(list_str)\n",
    "            # Dicts: {\"minimum_years\": \"2\"} â†’ \"minimum_years: 2\"\n",
    "            elif isinstance(val, dict):\n",
    "                dict_str = \" | \".join(f\"{k}: {v}\" for k, v in val.items() if v)\n",
    "                if dict_str:\n",
    "                    parts.append(dict_str)\n",
    "            # Numbers (except years_of_experience already handled)\n",
    "            elif isinstance(val, (int, float)) and field != \"years_of_experience\":\n",
    "                parts.append(str(val))\n",
    "            # Strings\n",
    "            elif isinstance(val, str) and val.strip():\n",
    "                parts.append(val.strip())\n",
    "        \n",
    "        return \"\\n\".join(p for p in parts if p)\n",
    "\n",
    "    # ========================================\n",
    "    # CORE SCORING (UNIFIED)\n",
    "    # ========================================\n",
    "    \n",
    "    def _score_pairs(self, pairs: List[List[str]], batch_size: int = 8) -> List[float]:\n",
    "        \"\"\"Score CV-JD pairs using cross-encoder with optimal batching.\n",
    "        \n",
    "        Args:\n",
    "            pairs: List of [jd_text, cv_text] pairs\n",
    "            batch_size: Batch size for processing\n",
    "            \n",
    "        Returns:\n",
    "            List of relevance scores (higher = more relevant)\n",
    "        \"\"\"\n",
    "        if not pairs:\n",
    "            return []\n",
    "        \n",
    "        max_length = getattr(self.tokenizer, 'model_max_length', 512)\n",
    "        scores: List[float] = []\n",
    "        \n",
    "        # Optimal path: sentence-transformers CrossEncoder\n",
    "        if self.use_st:\n",
    "            try:\n",
    "                scores = self.cross_encoder.predict(pairs).tolist()\n",
    "                return scores\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Sentence-transformers path failed, falling back to raw transformers: {e}\")\n",
    "                self.use_st = False  # Disable for future calls\n",
    "        \n",
    "        # Fallback: Raw transformers with batching\n",
    "        for i in range(0, len(pairs), batch_size):\n",
    "            batch_pairs = pairs[i:i + batch_size]\n",
    "            try:\n",
    "                features = self.tokenizer(\n",
    "                    batch_pairs,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=max_length,\n",
    "                    return_tensors=\"pt\"\n",
    "                ).to(self.device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    logits = self.cross_encoder(**features).logits\n",
    "                    \n",
    "                    # Apply sigmoid normalization for better score distribution\n",
    "                    if logits.ndim == 2 and logits.shape[1] == 1:\n",
    "                        batch_scores = torch.sigmoid(logits.squeeze(1))\n",
    "                    else:\n",
    "                        batch_scores = torch.sigmoid(logits[:, 0])\n",
    "                    \n",
    "                    scores.extend(batch_scores.cpu().tolist())\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Scoring batch {i//batch_size + 1} failed: {e}\")\n",
    "                scores.extend([0.0] * len(batch_pairs))\n",
    "        \n",
    "        return scores\n",
    "\n",
    "    # ========================================\n",
    "    # SCORE CALIBRATION & TOKEN ESTIMATION\n",
    "    # ========================================\n",
    "\n",
    "    @staticmethod\n",
    "    def _calibrate_scores(scores: List[float], mode: Optional[str]) -> List[float]:\n",
    "        if not scores or mode is None:\n",
    "            return scores\n",
    "        if mode == 'minmax':\n",
    "            mn = min(scores); mx = max(scores)\n",
    "            if mx > mn:\n",
    "                return [(s - mn)/(mx-mn) for s in scores]\n",
    "            return [0.0 for _ in scores]\n",
    "        if mode == 'zscore':\n",
    "            import math\n",
    "            mean = sum(scores)/len(scores)\n",
    "            var = sum((s-mean)**2 for s in scores)/len(scores)\n",
    "            if var <= 0:\n",
    "                return [0.0 for _ in scores]\n",
    "            std = math.sqrt(var)\n",
    "            return [(s-mean)/std for s in scores]\n",
    "        return scores\n",
    "\n",
    "    @staticmethod\n",
    "    def _estimate_tokens(text: str) -> int:\n",
    "        return len(text)//4\n",
    "\n",
    "    # ========================================\n",
    "    # DOCUMENT FETCHING (IMPROVED)\n",
    "    # ========================================\n",
    "    \n",
    "    def _fetch_jd_doc(\n",
    "        self,\n",
    "        company_name: str,\n",
    "        job_title: str,\n",
    "        jd_id: Optional[str] = None\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Fetch JD document with comprehensive fallback logic.\n",
    "        \n",
    "        Priority:\n",
    "        1. Dynamic collection (company-specific)\n",
    "        2. Static collection with exact match\n",
    "        3. Sanitized field match\n",
    "        4. Case-insensitive regex match\n",
    "        \"\"\"\n",
    "        # Try dynamic collection first\n",
    "        try:\n",
    "            db_name_dyn, _, jd_coll_dyn_name = build_mongo_names(company_name, job_title)\n",
    "            dyn_db = self.mongo_client[db_name_dyn]\n",
    "            dyn_jd_coll = dyn_db[jd_coll_dyn_name]\n",
    "            \n",
    "            # If jd_id provided, try exact match first\n",
    "            if jd_id:\n",
    "                jd_doc = dyn_jd_coll.find_one({\"_id\": jd_id})\n",
    "                if jd_doc:\n",
    "                    return jd_doc\n",
    "                # Try sanitized jd_id\n",
    "                jd_doc = dyn_jd_coll.find_one({\"_id\": sanitize_fragment(jd_id)})\n",
    "                if jd_doc:\n",
    "                    return jd_doc\n",
    "            \n",
    "            # Load all docs from job-specific collection (simplified approach)\n",
    "            jd_docs = list(dyn_jd_coll.find({}))\n",
    "            if jd_docs:\n",
    "                return jd_docs[0]\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Dynamic JD fetch failed: {e}\")\n",
    "        \n",
    "        # Fallback to static collection\n",
    "        try:\n",
    "            jd_doc = self.jd_collection.find_one({\n",
    "                \"company_name\": company_name,\n",
    "                \"job_title\": job_title\n",
    "            })\n",
    "            if jd_doc:\n",
    "                return jd_doc\n",
    "            jd_doc = self.jd_collection.find_one({\n",
    "                \"company_name_sanitized\": sanitize_fragment(company_name),\n",
    "                \"job_title_sanitized\": sanitize_fragment(job_title)\n",
    "            })\n",
    "            if jd_doc:\n",
    "                return jd_doc\n",
    "            jd_doc = self.jd_collection.find_one({\n",
    "                \"company_name\": {\"$regex\": f\"^{company_name}$\", \"$options\": \"i\"},\n",
    "                \"job_title\": {\"$regex\": f\"^{job_title}$\", \"$options\": \"i\"}\n",
    "            })\n",
    "            return jd_doc\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Static JD fallback failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _fetch_cv_doc(\n",
    "        self,\n",
    "        cv_id: str,\n",
    "        company_name: Optional[str] = None,\n",
    "        job_title: Optional[str] = None\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Fetch CV document from dynamic or static collection.\"\"\"\n",
    "        if company_name and job_title:\n",
    "            try:\n",
    "                db_name_dyn, cv_coll_dyn_name, _ = build_mongo_names(company_name, job_title)\n",
    "                dyn_db = self.mongo_client[db_name_dyn]\n",
    "                dyn_cv_coll = dyn_db[cv_coll_dyn_name]\n",
    "                cv_doc = dyn_cv_coll.find_one({\"_id\": cv_id})\n",
    "                if cv_doc:\n",
    "                    return cv_doc\n",
    "                cv_doc = dyn_cv_coll.find_one({\"cv_id\": cv_id})\n",
    "                if cv_doc:\n",
    "                    return cv_doc\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Dynamic CV fetch failed for {cv_id}: {e}\")\n",
    "        try:\n",
    "            cv_doc = self.cv_collection.find_one({\"_id\": cv_id})\n",
    "            if cv_doc:\n",
    "                return cv_doc\n",
    "            return self.cv_collection.find_one({\"cv_id\": cv_id})\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Static CV fallback failed for {cv_id}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def rerank_cvs_direct(\n",
    "        self,\n",
    "        cv_results: List[Dict],\n",
    "        jd_doc: Dict[str, Any],\n",
    "        batch_size: int = 8,\n",
    "        calibrate: Optional[str] = None,\n",
    "        with_meta: bool = False\n",
    "    ) -> Union[List[Dict], Tuple[List[Dict], Dict[str, Any]]]:\n",
    "        jd_text = self._build_text_from_doc(jd_doc, JD_FIELDS)\n",
    "        meta: Dict[str, Any] = {\n",
    "            \"mode\": \"direct\",\n",
    "            \"model_path\": \"sentence-transformers\" if self.use_st else \"hf\",\n",
    "            \"calibration\": calibrate,\n",
    "            \"jd_char_len\": len(jd_text),\n",
    "            \"jd_token_est\": self._estimate_tokens(jd_text),\n",
    "            \"cv_count\": len(cv_results),\n",
    "            \"missing_cv_count\": 0\n",
    "        }\n",
    "        if not jd_text:\n",
    "            logger.warning(\"JD text empty; skipping rerank\")\n",
    "            for r in cv_results:\n",
    "                r[\"cross_encoder_score\"] = 0.0\n",
    "                r[\"ce_status\"] = \"missing_jd\"\n",
    "            return (cv_results, meta) if with_meta else cv_results\n",
    "        cv_texts, valid_results = [], []\n",
    "        for result in cv_results:\n",
    "            cv_text = self._build_text_from_doc(result, CV_FIELDS)\n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "                result[\"ce_status\"] = \"ok\"\n",
    "            else:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"ce_status\"] = \"no_text\"\n",
    "                meta[\"missing_cv_count\"] += 1\n",
    "        if not cv_texts:\n",
    "            logger.warning(\"No CV texts built; returning original order\")\n",
    "            return (cv_results, meta) if with_meta else cv_results\n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "        scores = self._score_pairs(pairs, batch_size)\n",
    "        scores = self._calibrate_scores(scores, calibrate)\n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = float(score)\n",
    "        sorted_results = sorted(cv_results, key=lambda x: x.get(\"cross_encoder_score\", 0.0), reverse=True)\n",
    "        if with_meta:\n",
    "            if cv_texts:\n",
    "                meta[\"avg_cv_char_len\"] = sum(len(t) for t in cv_texts)/len(cv_texts)\n",
    "                meta[\"avg_cv_token_est\"] = sum(self._estimate_tokens(t) for t in cv_texts)/len(cv_texts)\n",
    "            return sorted_results, meta\n",
    "        return sorted_results\n",
    "\n",
    "    def rerank_cvs_for_job(\n",
    "        self,\n",
    "        cv_results: List[Dict],\n",
    "        company_name: str,\n",
    "        job_title: str,\n",
    "        batch_size: int = 8,\n",
    "        calibrate: Optional[str] = None,\n",
    "        with_meta: bool = False\n",
    "    ) -> Union[List[Dict], Tuple[List[Dict], Dict[str, Any]]]:\n",
    "        jd_doc = self._fetch_jd_doc(company_name, job_title)\n",
    "        meta: Dict[str, Any] = {\n",
    "            \"mode\": \"for_job\",\n",
    "            \"company\": company_name,\n",
    "            \"job_title\": job_title,\n",
    "            \"model_path\": \"sentence-transformers\" if self.use_st else \"hf\",\n",
    "            \"calibration\": calibrate,\n",
    "            \"cv_count\": len(cv_results),\n",
    "            \"missing_cv_count\": 0\n",
    "        }\n",
    "        if not jd_doc:\n",
    "            logger.warning(f\"No JD found for {company_name}/{job_title}; skipping rerank\")\n",
    "            for r in cv_results:\n",
    "                r[\"cross_encoder_score\"] = 0.0\n",
    "                r[\"ce_status\"] = \"missing_jd\"\n",
    "            return (cv_results, meta) if with_meta else cv_results\n",
    "        jd_text = self._build_text_from_doc(jd_doc, JD_FIELDS)\n",
    "        meta[\"jd_char_len\"] = len(jd_text)\n",
    "        meta[\"jd_token_est\"] = self._estimate_tokens(jd_text)\n",
    "        if not jd_text:\n",
    "            logger.warning(\"JD text empty after construction; skipping rerank\")\n",
    "            for r in cv_results:\n",
    "                r[\"cross_encoder_score\"] = 0.0\n",
    "                r[\"ce_status\"] = \"missing_jd\"\n",
    "            return (cv_results, meta) if with_meta else cv_results\n",
    "        cv_id_list = [r.get(\"cv_id\") for r in cv_results if r.get(\"cv_id\")]\n",
    "        cv_docs_map: Dict[str, Dict[str, Any]] = {}\n",
    "        if cv_id_list:\n",
    "            try:\n",
    "                db_name_dyn, cv_coll_dyn_name, _ = build_mongo_names(company_name, job_title)\n",
    "                dyn_db = self.mongo_client[db_name_dyn]\n",
    "                dyn_cv_coll = dyn_db[cv_coll_dyn_name]\n",
    "                dyn_docs = list(dyn_cv_coll.find({\"$or\": [\n",
    "                    {\"_id\": {\"$in\": cv_id_list}},\n",
    "                    {\"cv_id\": {\"$in\": cv_id_list}}\n",
    "                ]}))\n",
    "                for d in dyn_docs:\n",
    "                    key = d.get(\"_id\") or d.get(\"cv_id\")\n",
    "                    if key:\n",
    "                        cv_docs_map[key] = d\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Batch dynamic CV fetch failed: {e}\")\n",
    "            if not cv_docs_map:\n",
    "                try:\n",
    "                    static_docs = list(self.cv_collection.find({\"$or\": [\n",
    "                        {\"_id\": {\"$in\": cv_id_list}},\n",
    "                        {\"cv_id\": {\"$in\": cv_id_list}}\n",
    "                    ]}))\n",
    "                    for d in static_docs:\n",
    "                        key = d.get(\"_id\") or d.get(\"cv_id\")\n",
    "                        if key:\n",
    "                            cv_docs_map[key] = d\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Static batch CV fetch failed: {e}\")\n",
    "        cv_texts: List[str] = []\n",
    "        valid_results: List[Dict] = []\n",
    "        for result in cv_results:\n",
    "            cv_id = result.get(\"cv_id\")\n",
    "            if not cv_id:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"ce_status\"] = \"missing_cv\"\n",
    "                meta[\"missing_cv_count\"] += 1\n",
    "                continue\n",
    "            cv_doc = cv_docs_map.get(cv_id)\n",
    "            if not cv_doc:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"ce_status\"] = \"missing_cv\"\n",
    "                meta[\"missing_cv_count\"] += 1\n",
    "                continue\n",
    "            cv_text = self._build_text_from_doc(cv_doc, CV_FIELDS)\n",
    "            if not cv_text:\n",
    "                cv_text = cv_doc.get(\"full_text\", \"\")\n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "                result[\"ce_status\"] = \"ok\"\n",
    "            else:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"ce_status\"] = \"no_text\"\n",
    "                meta[\"missing_cv_count\"] += 1\n",
    "        if not cv_texts:\n",
    "            logger.warning(\"No CV texts available for reranking\")\n",
    "            return (cv_results, meta) if with_meta else cv_results\n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "        scores = self._score_pairs(pairs, batch_size)\n",
    "        scores = self._calibrate_scores(scores, calibrate)\n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = float(score)\n",
    "        cv_results.sort(key=lambda x: x.get(\"cross_encoder_score\", 0.0), reverse=True)\n",
    "        if cv_texts:\n",
    "            meta[\"avg_cv_char_len\"] = sum(len(t) for t in cv_texts)/len(cv_texts)\n",
    "            meta[\"avg_cv_token_est\"] = sum(self._estimate_tokens(t) for t in cv_texts)/len(cv_texts)\n",
    "        if with_meta:\n",
    "            return cv_results, meta\n",
    "        logger.info(f\"âœ… Reranked {len(cv_results)} CVs for company='{company_name}' job='{job_title}'\")\n",
    "        return cv_results\n",
    "\n",
    "    def rerank_cvs_with_jd_id(\n",
    "        self,\n",
    "        cv_results: List[Dict],\n",
    "        company_name: str,\n",
    "        job_title: str,\n",
    "        jd_id: str,\n",
    "        batch_size: int = 8,\n",
    "        calibrate: Optional[str] = None,\n",
    "        with_meta: bool = False\n",
    "    ) -> Union[List[Dict], Tuple[List[Dict], Dict[str, Any]]]:\n",
    "        jd_doc = self._fetch_jd_doc(company_name, job_title, jd_id)\n",
    "        meta: Dict[str, Any] = {\n",
    "            \"mode\": \"with_jd_id\",\n",
    "            \"company\": company_name,\n",
    "            \"job_title\": job_title,\n",
    "            \"jd_id\": jd_id,\n",
    "            \"model_path\": \"sentence-transformers\" if self.use_st else \"hf\",\n",
    "            \"calibration\": calibrate,\n",
    "            \"cv_count\": len(cv_results),\n",
    "            \"missing_cv_count\": 0\n",
    "        }\n",
    "        if not jd_doc:\n",
    "            logger.warning(f\"JD id '{jd_id}' not found; skipping rerank\")\n",
    "            for r in cv_results:\n",
    "                r[\"cross_encoder_score\"] = 0.0\n",
    "                r[\"ce_status\"] = \"missing_jd\"\n",
    "            return (cv_results, meta) if with_meta else cv_results\n",
    "        jd_text = self._build_text_from_doc(jd_doc, JD_FIELDS)\n",
    "        meta[\"jd_char_len\"] = len(jd_text)\n",
    "        meta[\"jd_token_est\"] = self._estimate_tokens(jd_text)\n",
    "        if not jd_text:\n",
    "            logger.warning(f\"JD id '{jd_id}' produced empty text; skipping rerank\")\n",
    "            for r in cv_results:\n",
    "                r[\"cross_encoder_score\"] = 0.0\n",
    "                r[\"ce_status\"] = \"missing_jd\"\n",
    "            return (cv_results, meta) if with_meta else cv_results\n",
    "        cv_id_list = [r.get(\"cv_id\") for r in cv_results if r.get(\"cv_id\")]\n",
    "        cv_docs_map: Dict[str, Dict[str, Any]] = {}\n",
    "        if cv_id_list:\n",
    "            try:\n",
    "                db_name_dyn, cv_coll_dyn_name, _ = build_mongo_names(company_name, job_title)\n",
    "                dyn_db = self.mongo_client[db_name_dyn]\n",
    "                dyn_cv_coll = dyn_db[cv_coll_dyn_name]\n",
    "                dyn_docs = list(dyn_cv_coll.find({\"$or\": [\n",
    "                    {\"_id\": {\"$in\": cv_id_list}},\n",
    "                    {\"cv_id\": {\"$in\": cv_id_list}}\n",
    "                ]}))\n",
    "                for d in dyn_docs:\n",
    "                    key = d.get(\"_id\") or d.get(\"cv_id\")\n",
    "                    if key:\n",
    "                        cv_docs_map[key] = d\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Batch dynamic CV fetch failed: {e}\")\n",
    "            if not cv_docs_map:\n",
    "                try:\n",
    "                    static_docs = list(self.cv_collection.find({\"$or\": [\n",
    "                        {\"_id\": {\"$in\": cv_id_list}},\n",
    "                        {\"cv_id\": {\"$in\": cv_id_list}}\n",
    "                    ]}))\n",
    "                    for d in static_docs:\n",
    "                        key = d.get(\"_id\") or d.get(\"cv_id\")\n",
    "                        if key:\n",
    "                            cv_docs_map[key] = d\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Static batch CV fetch failed: {e}\")\n",
    "        cv_texts: List[str] = []\n",
    "        valid_results: List[Dict] = []\n",
    "        for result in cv_results:\n",
    "            cv_id = result.get(\"cv_id\")\n",
    "            if not cv_id:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"ce_status\"] = \"missing_cv\"\n",
    "                meta[\"missing_cv_count\"] += 1\n",
    "                continue\n",
    "            cv_doc = cv_docs_map.get(cv_id)\n",
    "            if not cv_doc:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"ce_status\"] = \"missing_cv\"\n",
    "                meta[\"missing_cv_count\"] += 1\n",
    "                continue\n",
    "            cv_text = self._build_text_from_doc(cv_doc, CV_FIELDS)\n",
    "            if not cv_text:\n",
    "                cv_text = cv_doc.get(\"full_text\", \"\")\n",
    "            if cv_text:\n",
    "                cv_texts.append(cv_text)\n",
    "                valid_results.append(result)\n",
    "                result[\"ce_status\"] = \"ok\"\n",
    "            else:\n",
    "                result[\"cross_encoder_score\"] = 0.0\n",
    "                result[\"ce_status\"] = \"no_text\"\n",
    "                meta[\"missing_cv_count\"] += 1\n",
    "        if not cv_texts:\n",
    "            logger.warning(\"No CV texts available for reranking with jd_id\")\n",
    "            return (cv_results, meta) if with_meta else cv_results\n",
    "        pairs = [[jd_text, cv_text] for cv_text in cv_texts]\n",
    "        scores = self._score_pairs(pairs, batch_size)\n",
    "        scores = self._calibrate_scores(scores, calibrate)\n",
    "        for result, score in zip(valid_results, scores):\n",
    "            result[\"cross_encoder_score\"] = float(score)\n",
    "        cv_results.sort(key=lambda x: x.get(\"cross_encoder_score\", 0.0), reverse=True)\n",
    "        if cv_texts:\n",
    "            meta[\"avg_cv_char_len\"] = sum(len(t) for t in cv_texts)/len(cv_texts)\n",
    "            meta[\"avg_cv_token_est\"] = sum(self._estimate_tokens(t) for t in cv_texts)/len(cv_texts)\n",
    "        if with_meta:\n",
    "            return cv_results, meta\n",
    "        logger.info(f\"âœ… Reranked {len(cv_results)} CVs using jd_id='{jd_id}' company='{company_name}' job='{job_title}'\")\n",
    "        return cv_results\n",
    "\n",
    "\n",
    "sample_jd = {\n",
    "    \"job_title\": \"Data Analyst\",\"required_skills\": [\"SQL\", \"Python\", \"Excel\"],\"technical_skills\": [\"SQL\", \"Python (pandas)\", \"Excel\"],\"experience_requirements\": {\"minimum_years\": \"2\"}\n",
    "}\n",
    "sample_cvs = [\n",
    "    {\n",
    "        \"cv_id\": \"cv_001\",\"email\": \"candidate1@example.com\",\"total_score\": 0.85,\"summary\": \"Data Analyst with SQL and Python experience\",\"years_of_experience\": 3.5,\"skills\": [\"SQL\", \"Python\", \"Tableau\"],\n",
    "    },\n",
    "    {\n",
    "        \"cv_id\": \"cv_002\",\"email\": \"candidate2@example.com\",\"total_score\": 0.82,\"summary\": \"Business Analyst with Excel skills\",\"years_of_experience\": 1.5,\"skills\": [\"Excel\", \"PowerPoint\"],\n",
    "    }\n",
    "]\n",
    "try:\n",
    "    reranker = CVJDReranker(mongo_uri=\"mongodb://localhost:27017/\", mongo_db=\"cv_db\")\n",
    "    results, meta = reranker.rerank_cvs_direct(sample_cvs, sample_jd, with_meta=True, calibrate='minmax')\n",
    "    print(meta)\n",
    "    for r in results:\n",
    "        print(r['cv_id'], r['cross_encoder_score'], r['ce_status'])\n",
    "except Exception as e:\n",
    "    print('Error initializing reranker (likely no MongoDB running):', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f48a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
